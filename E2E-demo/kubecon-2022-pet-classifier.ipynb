{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7091d97e-22d2-4ae2-a006-b41f7f48f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.ray.io/en/latest/train/examples/train_fashion_mnist_example.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19004e51-c772-453f-9344-004a5ad3425e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Minimal\n"
     ]
    }
   ],
   "source": [
    "%xmode Minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f462ad35-dfca-45c5-850a-41971da6574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.modules.utils import consume_prefix_in_state_dict_if_present\n",
    "#import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Resize,Compose, ToPILImage\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import ray\n",
    "from ray import train\n",
    "from ray.air import session, Checkpoint\n",
    "from ray.air.config import ScalingConfig\n",
    "from ray.train.torch import TorchCheckpoint, TorchTrainer\n",
    "\n",
    "from ray.data.datasource import SimpleTorchDatasource\n",
    "from ray.data.preprocessors import Concatenator, Chain, StandardScaler\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune .tuner import Tuner, TuneConfig\n",
    "from ray.air.config import RunConfig\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ray_cluster_control import start_ray_cluster, stop_ray_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a964830-20ac-495d-bde2-7789058b40e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RayCluster \"kubecon-2022\" has started\n",
      "Access your cluster dashboard at http://ray-dashboard-kubecon-2022-open-data-hub.apps.et-gpu.zfq7.p1.openshiftapps.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kubecon-2022'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_ray_cluster(\"kubecon-2022\")\n",
    "os.getenv(\"RAY_CLUSTER_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12c98cef-f712-460a-a012-e49c07c9bff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.12</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://10.131.2.243:8265\" target=\"_blank\">http://10.131.2.243:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "ClientContext(dashboard_url='10.131.2.243:8265', python_version='3.8.12', ray_version='2.0.0', ray_commit='cba26cc83f6b5b8a2ff166594a65cb74c0ec8740', protocol_version='2022-07-24', _num_clients=2, _context_to_restore=<ray.util.client._ClientContext object at 0x7fd85abc1fa0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init('ray://{ray_head}-ray-head:10001'.format(ray_head=os.environ['RAY_CLUSTER_NAME']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bc51cd1-8164-4ffb-ab5b-95ba6ce5fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([Resize((64,64)),ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e87c2b0-65b2-4826-8f33-372cd777589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_data = torchvision.datasets.OxfordIIITPet(\"data/\",\n",
    "                                              download = True,\n",
    "                                              target_types = \"category\",\n",
    "                                              transform = transforms,\n",
    "                                              split = \"trainval\")\n",
    "data_loader = torch.utils.data.DataLoader(pet_data, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d38dc-8c47-4bad-914a-848d7253e278",
   "metadata": {},
   "source": [
    "This data set is only 3K and not the full 7k since we read in dataset with the `split` parameters that pulls in the files based on the corresponding txt file in `data/data/oxford-iiit-pet/annotations`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46b71da9-eee0-4d73-a66f-627ea21ff703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3680"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d6556aa-a289-4362-b1f3-cd6b475bed86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# for this demo we are letting Ray handle all the GPU work external\n",
    "# to this notebook\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fca7583-31d4-4810-b7eb-ae9e950aa069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([4, 3, 64, 64])\n",
      "Labels batch shape: torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:11\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(data_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "make = ToPILImage()\n",
    "make(train_features[0]).show()\n",
    "print(f'label:{train_labels[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33f50fc-8a15-41b8-a7c9-668d0fbb5aca",
   "metadata": {},
   "source": [
    "### Pet Data is courtesy of Community Data License Agreement (CDLA) via Linux Foundation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edcbd5f0-f556-4ef2-a32f-51a8710cef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvNet():\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, 16, 3, 1),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        nn.Conv2d(16, 32, 3,1 ),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(6272 , 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 37)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ab90031-d1d3-4b6f-8196-e6b763e12a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (4): Flatten(start_dim=1, end_dim=-1)\n",
       "  (5): Linear(in_features=6272, out_features=128, bias=True)\n",
       "  (6): ReLU()\n",
       "  (7): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Linear(in_features=64, out_features=37, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15475bd5-e2f1-4a9b-894e-f7e238a72928",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_factory = lambda: torchvision.datasets.OxfordIIITPet(\"data/\", download = True, target_types = \"category\", transform = transforms, split = \"trainval\")\n",
    "dataset = ray.data.read_datasource(\n",
    "    SimpleTorchDatasource(), parallelism=1, dataset_factory=dataset_factory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cf435f6-d9b2-487b-8e23-1af3e3259610",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shuffle Map: 100%|██████████| 1/1 [00:14<00:00, 14.33s/it]\n",
      "Shuffle Reduce: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n"
     ]
    }
   ],
   "source": [
    "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f6c5c42-ece5-4198-8eb3-970d2d0e0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, loss_fn, optim):\n",
    "    model.train()\n",
    "    model.to(\"cuda\")\n",
    "    for batch_idx, data in enumerate(dataloader.iter_batches()):\n",
    "        X = [x[0] for x in data]\n",
    "        X = torch.stack(X)\n",
    "        X = X.to(\"cuda\")\n",
    "        y = [torch.tensor(x[1]) for x in data]\n",
    "        y = torch.stack(y)\n",
    "        y = y.to(\"cuda\") \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        #backprop\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def validate_epoch(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader.iter_batches():\n",
    "            X = [x[0] for x in data]\n",
    "            X = torch.stack(X)\n",
    "            X = X.to(\"cuda\")\n",
    "            y = [torch.tensor(x[1]) for x in data]\n",
    "            y = torch.stack(y)\n",
    "            y = y.to(\"cuda\")\n",
    "            pred = model(X)\n",
    "            test_loss = loss_fn(pred, y).item()  \n",
    "    \n",
    "    return test_loss\n",
    "\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    lr = config[\"lr\"]\n",
    "    epochs = config[\"epochs\"]\n",
    "    momentum = config[\"momentum\"]\n",
    "    tune_run = config[\"tune_run\"]\n",
    "\n",
    "    train_dataloader = train.get_dataset_shard(\"train\")\n",
    "    test_dataloader = train.get_dataset_shard(\"test\")\n",
    "    model = ConvNet()\n",
    "    model = train.torch.prepare_model(model).to(\"cuda\")\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr,  momentum=momentum)\n",
    "\n",
    "    loss_results = []\n",
    "    eval_results = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss = train_epoch(train_dataloader, model, loss_fn, optimizer)\n",
    "        val_loss = validate_epoch(test_dataloader, model, loss_fn)\n",
    "        loss_results.append(loss)\n",
    "        eval_results.append(val_loss)\n",
    "        session.report({\"loss\":loss},)\n",
    "\n",
    "    session.report({\"loss\":loss, \"model\": model,\n",
    "                   \"training_loss\": loss_results,\"eval_loss\": eval_results},\n",
    "                   checkpoint=Checkpoint.from_dict(dict(epoch=epoch, model=model.state_dict())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d99d05b2-7ea7-4cbb-985b-375f60881955",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config = {\n",
    "        \"batch_size\": 4,\n",
    "        \"epochs\": 100,\n",
    "        \"momentum\": 0.9,\n",
    "        \"lr\": 0.001,\n",
    "        \"tune_run\": False\n",
    "    },\n",
    "    scaling_config = ScalingConfig(num_workers = 1,\n",
    "                                   use_gpu = True,\n",
    "                                   trainer_resources = {\"CPU\":1}),\n",
    "    run_config = RunConfig(name = \"test_run\",\n",
    "                           local_dir = \"./\",\n",
    "                           sync_config = tune.SyncConfig(syncer=None)),\n",
    "    datasets = {\n",
    "        \"train\": train_dataset,\n",
    "        \"test\": valid_dataset\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "331c4ae1-d3b3-4652-8aa6-5981be8c07d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tuning search space.\n",
    "search_space = {\n",
    "    \"train_loop_config\": {\n",
    "        \"lr\": tune.grid_search([0.001, 0.01]),\n",
    "        \"momentum\": tune.grid_search([0.5, 0.9]),\n",
    "        \"batch_size\": tune.grid_search([4]), \n",
    "        \"epochs\": tune.grid_search([100]),\n",
    "        \"tune_run\": tune.grid_search([True])\n",
    "    }\n",
    "}\n",
    "\n",
    "metric = \"loss\"\n",
    "mode = \"min\"\n",
    "\n",
    "tuner = Tuner(trainer,\n",
    "              param_space=search_space,\n",
    "              tune_config=TuneConfig(num_samples=1, metric=metric, mode=mode),\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ee5ab36-d3f3-434b-9b94-20e3e043b975",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:15:26 (running for 00:00:03.44)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 6.6/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 1.0/2 CPUs, 1.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (3 PENDING, 1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | RUNNING  | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | PENDING  |                   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5255)\u001b[0m 2022-10-21 22:15:29,716\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5255)\u001b[0m 2022-10-21 22:15:29,911\tINFO train_loop_utils.py:300 -- Moving model to device: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:15:31 (running for 00:00:08.45)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 7.9/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 1.0/2 CPUs, 1.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (3 PENDING, 1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | RUNNING  | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | PENDING  |                   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 4.240850925445557\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390534\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-15-34\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: 2eced6db495d47e3884ccd2881ed51d8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-kubecon-2022-head-fdbbh\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.6007702350616455\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.131.2.243\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 5222\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 7.151232957839966\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 7.151232957839966\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 7.151232957839966\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390534\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.003857851028442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:15:37 (running for 00:00:14.02)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 8.8/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 1.0/2 CPUs, 1.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00000 with loss=3.5997543334960938 and parameters={'train_loop_config': {'lr': 0.001, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (3 PENDING, 1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | RUNNING  | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |      5 |          10.5768 | 3.59975 |   1666390537 |            0.820079 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | PENDING  |                   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 1.017277479171753\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390540\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-15-40\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: 2eced6db495d47e3884ccd2881ed51d8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-kubecon-2022-head-fdbbh\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.5990259647369385\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.131.2.243\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 5222\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 13.162342071533203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 1.0172204971313477\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 13.162342071533203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390540\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.003857851028442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:15:42 (running for 00:00:19.10)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 8.9/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 3.0/2 CPUs, 3.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00000 with loss=3.5983259677886963 and parameters={'train_loop_config': {'lr': 0.001, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 PENDING, 3 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | RUNNING  | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |     11 |          15.6512 | 3.59833 |   1666390542 |            0.867167 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | RUNNING  | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | RUNNING  | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=234, ip=10.128.2.79)\u001b[0m 2022-10-21 22:15:45,732\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=234, ip=10.128.4.75)\u001b[0m 2022-10-21 22:15:45,699\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=234, ip=10.128.4.75)\u001b[0m 2022-10-21 22:15:45,871\tINFO train_loop_utils.py:300 -- Moving model to device: cuda:0\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=234, ip=10.128.2.79)\u001b[0m 2022-10-21 22:15:45,924\tINFO train_loop_utils.py:300 -- Moving model to device: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 1.0058681964874268\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390545\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 15\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-15-45\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: 2eced6db495d47e3884ccd2881ed51d8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-kubecon-2022-head-fdbbh\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 15\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.597440719604492\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.131.2.243\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 5222\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 18.995596885681152\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 1.0057284832000732\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 18.995596885681152\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390545\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 15\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.003857851028442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:15:48 (running for 00:00:24.93)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 8.8/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 3.0/4 CPUs, 3.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00000 with loss=3.5968821048736572 and parameters={'train_loop_config': {'lr': 0.001, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 PENDING, 3 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | RUNNING  | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |     18 |          21.4887 | 3.59688 |   1666390548 |            0.895945 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | RUNNING  | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | RUNNING  | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 4.279574155807495\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390550\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-15-50\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: f21dc51fc8b2460db5f142df235a6505\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-v7c2t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.6293420791625977\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.4.75\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 6.709670305252075\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 6.709670305252075\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 6.709670305252075\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390550\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.00398564338684082\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 4.358139753341675\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390550\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-15-50\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: dd304bcdf1c045e9b83b37b12b9b1462\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.6189706325531006\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 6.737364292144775\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 6.737364292144775\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 6.737364292144775\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390550\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037353038787841797\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.9335751533508301\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390551\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 21\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-15-51\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: 2eced6db495d47e3884ccd2881ed51d8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-kubecon-2022-head-fdbbh\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 21\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.5963973999023438\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.131.2.243\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 5222\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 24.631705284118652\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.9464333057403564\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 24.631705284118652\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390551\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 21\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.003857851028442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:15:53 (running for 00:00:30.20)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 9.0/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 3.0/4 CPUs, 3.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00000 with loss=3.5960798263549805 and parameters={'train_loop_config': {'lr': 0.001, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 PENDING, 3 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | RUNNING  | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |     23 |         26.1459  | 3.59608 |   1666390553 |            0.749549 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | RUNNING  | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |      5 |          9.57692 | 3.61925 |   1666390553 |            0.668916 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | RUNNING  | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |      7 |         10.1893  | 3.61568 |   1666390553 |            0.543399 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.7682280540466309\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390555\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-15-55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: f21dc51fc8b2460db5f142df235a6505\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-v7c2t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.612687110900879\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.4.75\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 11.813819646835327\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.7681581974029541\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 11.813819646835327\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390555\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.00398564338684082\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5791523456573486\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390555\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 10\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-15-55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: dd304bcdf1c045e9b83b37b12b9b1462\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 10\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.6140613555908203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 11.927902698516846\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5796582698822021\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 11.927902698516846\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390555\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 10\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037353038787841797\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.8331501483917236\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390557\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 28\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-15-57\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: 2eced6db495d47e3884ccd2881ed51d8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-kubecon-2022-head-fdbbh\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 28\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.595313310623169\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.131.2.243\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 5222\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 30.39713978767395\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.8332798480987549\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 30.39713978767395\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390557\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 28\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.003857851028442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:15:58 (running for 00:00:35.39)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 8.9/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 3.0/4 CPUs, 3.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00000 with loss=3.595163106918335 and parameters={'train_loop_config': {'lr': 0.001, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 PENDING, 3 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | RUNNING  | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |     29 |          31.0819 | 3.59516 |   1666390558 |            0.684653 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | RUNNING  | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |     13 |          15.2759 | 3.60368 |   1666390558 |            0.627372 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | RUNNING  | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |     16 |          15.3793 | 3.61088 |   1666390558 |            0.588006 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5839378833770752\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390560\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 19\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-00\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: dd304bcdf1c045e9b83b37b12b9b1462\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 19\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.6093273162841797\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 17.076661825180054\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5837745666503906\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 17.076661825180054\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390560\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 19\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037353038787841797\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.6086411476135254\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390560\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 16\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-00\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: f21dc51fc8b2460db5f142df235a6505\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-v7c2t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 16\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.598264455795288\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.4.75\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 17.37421464920044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.6088545322418213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 17.37421464920044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390560\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 16\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.00398564338684082\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.8225307464599609\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390562\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 34\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-02\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: 2eced6db495d47e3884ccd2881ed51d8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-kubecon-2022-head-fdbbh\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 34\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.5944554805755615\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.131.2.243\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 5222\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 35.517937421798706\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.8221251964569092\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 35.517937421798706\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390562\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 34\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.003857851028442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:16:04 (running for 00:00:40.47)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 9.0/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 3.0/4 CPUs, 3.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00001 with loss=3.5904428958892822 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 PENDING, 3 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | RUNNING  | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |     36 |          37.0197 | 3.59417 |   1666390563 |            0.797383 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | RUNNING  | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |     20 |          20.0137 | 3.59044 |   1666390563 |            0.667123 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | RUNNING  | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |     24 |          19.8767 | 3.60687 |   1666390563 |            0.532141 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5976126194000244\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390565\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 28\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: dd304bcdf1c045e9b83b37b12b9b1462\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 28\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.604771614074707\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 22.152228116989136\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5988156795501709\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 22.152228116989136\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390565\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 28\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037353038787841797\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.6792423725128174\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390566\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 24\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-06\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: f21dc51fc8b2460db5f142df235a6505\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-v7c2t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 24\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.5818679332733154\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.4.75\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 22.789714097976685\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.6789798736572266\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 22.789714097976685\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390566\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 24\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.00398564338684082\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.85154128074646\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390568\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 41\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-08\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: 2eced6db495d47e3884ccd2881ed51d8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-kubecon-2022-head-fdbbh\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 41\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.593451738357544\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.131.2.243\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 5222\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 41.15199303627014\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.8514673709869385\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 41.15199303627014\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390568\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 41\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.003857851028442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:16:09 (running for 00:00:45.58)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 8.9/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 3.0/4 CPUs, 3.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00001 with loss=3.5723555088043213 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 PENDING, 3 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | RUNNING  | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |     42 |          41.9657 | 3.5933  |   1666390568 |            0.813418 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | RUNNING  | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |     28 |          25.4147 | 3.57236 |   1666390568 |            0.681005 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | RUNNING  | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |     34 |          25.5705 | 3.60126 |   1666390569 |            0.584347 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5906720161437988\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390570\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 37\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-10\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: dd304bcdf1c045e9b83b37b12b9b1462\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 37\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.599261999130249\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 27.30320405960083\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5904743671417236\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 27.30320405960083\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390570\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 37\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037353038787841797\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.6697993278503418\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390571\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 32\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-11\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: f21dc51fc8b2460db5f142df235a6505\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-v7c2t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 32\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.561063051223755\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.4.75\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 28.046014070510864\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.6701064109802246\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 28.046014070510864\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390571\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 32\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.00398564338684082\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.6359117031097412\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390573\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 48\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-13\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: 2eced6db495d47e3884ccd2881ed51d8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-kubecon-2022-head-fdbbh\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 48\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.5924112796783447\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.131.2.243\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 5222\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 46.47490382194519\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.6358680725097656\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 46.47490382194519\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390573\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 48\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.003857851028442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:16:14 (running for 00:00:50.59)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 8.9/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 3.0/4 CPUs, 3.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00001 with loss=3.5510337352752686 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 PENDING, 3 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | RUNNING  | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |     49 |          47.146  | 3.59227 |   1666390574 |            0.665382 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | RUNNING  | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |     35 |          30.2261 | 3.55103 |   1666390573 |            0.750967 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | RUNNING  | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |     42 |          30.1569 | 3.59564 |   1666390573 |            0.546777 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.577669620513916\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390575\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-15\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: dd304bcdf1c045e9b83b37b12b9b1462\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.593005418777466\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 32.44445514678955\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5776100158691406\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 32.44445514678955\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390575\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037353038787841797\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.7354011535644531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390576\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 39\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-16\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: f21dc51fc8b2460db5f142df235a6505\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-v7c2t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 39\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.5350751876831055\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.4.75\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 33.08727669715881\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.7386007308959961\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 33.08727669715881\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390576\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 39\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.00398564338684082\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.7698132991790771\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390579\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-19\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: 2eced6db495d47e3884ccd2881ed51d8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-kubecon-2022-head-fdbbh\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.5914437770843506\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.131.2.243\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 5222\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 52.14613747596741\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.7699830532073975\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 52.14613747596741\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390579\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.003857851028442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:16:19 (running for 00:00:55.59)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 8.8/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 3.0/4 CPUs, 3.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00001 with loss=3.5208961963653564 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 PENDING, 3 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | RUNNING  | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |     55 |          52.1461 | 3.59144 |   1666390579 |            0.769813 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | RUNNING  | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |     42 |          35.1575 | 3.5209  |   1666390578 |            0.668635 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | RUNNING  | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |     51 |          35.2912 | 3.58949 |   1666390578 |            0.581102 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5786716938018799\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390581\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-21\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: dd304bcdf1c045e9b83b37b12b9b1462\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.5861003398895264\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 37.60634756088257\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5782427787780762\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 37.60634756088257\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390581\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037353038787841797\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.7570669651031494\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390582\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 47\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-22\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: f21dc51fc8b2460db5f142df235a6505\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-v7c2t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 47\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.4905271530151367\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.4.75\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 38.78206276893616\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.7565464973449707\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 38.78206276893616\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390582\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 47\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.00398564338684082\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.9442892074584961\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390584\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 61\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-24\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: 2eced6db495d47e3884ccd2881ed51d8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-kubecon-2022-head-fdbbh\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 61\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.5905768871307373\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.131.2.243\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 5222\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 57.181931495666504\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.9445765018463135\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 57.181931495666504\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390584\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 61\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.003857851028442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:16:24 (running for 00:01:00.63)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 9.0/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 3.0/4 CPUs, 3.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00001 with loss=3.47436785697937 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 PENDING, 3 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | RUNNING  | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |     61 |          57.1819 | 3.59058 |   1666390584 |            0.944289 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | RUNNING  | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |     49 |          40.0022 | 3.47437 |   1666390583 |            0.616997 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | RUNNING  | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |     60 |          40.4709 | 3.58165 |   1666390584 |            0.602886 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5209722518920898\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390586\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 64\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-26\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: dd304bcdf1c045e9b83b37b12b9b1462\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 64\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.5778849124908447\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 42.68573331832886\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5207691192626953\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 42.68573331832886\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390586\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 64\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037353038787841797\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.686042308807373\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390587\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-27\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: f21dc51fc8b2460db5f142df235a6505\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-v7c2t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.4079959392547607\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.4.75\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 44.210219383239746\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.6861426830291748\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 44.210219383239746\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390587\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.00398564338684082\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:16:29 (running for 00:01:05.65)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 8.9/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 3.0/4 CPUs, 3.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00001 with loss=3.3778982162475586 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 PENDING, 3 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | RUNNING  | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |     66 |          61.5579 | 3.58991 |   1666390588 |            0.865691 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | RUNNING  | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |     57 |          45.718  | 3.3779  |   1666390589 |            0.747793 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | RUNNING  | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |     69 |          45.6381 | 3.57257 |   1666390589 |            0.602813 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.9871957302093506\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390589\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 67\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-29\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: 2eced6db495d47e3884ccd2881ed51d8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-kubecon-2022-head-fdbbh\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 67\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.589784622192383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.131.2.243\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 5222\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 62.54532241821289\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.9874362945556641\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 62.54532241821289\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390589\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 67\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.003857851028442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.58235764503479\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390591\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 73\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-31\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: dd304bcdf1c045e9b83b37b12b9b1462\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 73\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.567805290222168\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 47.875088930130005\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5822780132293701\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 47.875088930130005\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390591\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 73\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037353038787841797\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.7146041393280029\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390592\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 62\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-32\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: f21dc51fc8b2460db5f142df235a6505\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-v7c2t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 62\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.282693862915039\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.4.75\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 49.27360486984253\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.7140653133392334\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 49.27360486984253\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390592\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 62\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.00398564338684082\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:16:34 (running for 00:01:10.75)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 9.0/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 3.0/4 CPUs, 3.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00001 with loss=3.236078977584839 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 PENDING, 3 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | RUNNING  | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |     72 |          66.951  | 3.58913 |   1666390593 |            0.875944 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | RUNNING  | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |     64 |          50.6825 | 3.23608 |   1666390594 |            0.67104  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | RUNNING  | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |     78 |          50.7433 | 3.56067 |   1666390594 |            0.613164 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.8438677787780762\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390594\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 73\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-34\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: 2eced6db495d47e3884ccd2881ed51d8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-kubecon-2022-head-fdbbh\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 73\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.589003324508667\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.131.2.243\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 5222\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 67.79489779472351\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.8439168930053711\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 67.79489779472351\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390594\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 73\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.003857851028442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5800983905792236\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390596\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 82\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-36\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: dd304bcdf1c045e9b83b37b12b9b1462\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 82\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.553889274597168\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 52.99636125564575\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5797531604766846\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 52.99636125564575\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390596\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 82\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037353038787841797\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.7402667999267578\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390597\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 69\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-37\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: f21dc51fc8b2460db5f142df235a6505\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-v7c2t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 69\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.1141269207000732\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.4.75\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 54.41801953315735\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.7402904033660889\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 54.41801953315735\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390597\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 69\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.00398564338684082\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:16:39 (running for 00:01:15.82)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 8.9/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 3.0/4 CPUs, 3.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00001 with loss=3.0669963359832764 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 PENDING, 3 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | RUNNING  | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |     78 |          72.166  | 3.5884  |   1666390599 |            0.829734 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | RUNNING  | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |     71 |          55.917  | 3.067   |   1666390599 |            0.793    |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | RUNNING  | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |     86 |          55.3066 | 3.54607 |   1666390598 |            0.593851 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.9248001575469971\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390600\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-40\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: 2eced6db495d47e3884ccd2881ed51d8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-kubecon-2022-head-fdbbh\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.588287353515625\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.131.2.243\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 5222\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 73.09124684333801\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.9252924919128418\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 73.09124684333801\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390600\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.003857851028442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5304286479949951\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390601\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 91\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-41\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: dd304bcdf1c045e9b83b37b12b9b1462\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 91\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.5346333980560303\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 58.19764709472656\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5303115844726562\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 58.19764709472656\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390601\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 91\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037353038787841797\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5326282978057861\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390603\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 77\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: f21dc51fc8b2460db5f142df235a6505\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-v7c2t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 77\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 2.931403875350952\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.4.75\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 59.69579291343689\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5325851440429688\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 59.69579291343689\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390603\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 77\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.00398564338684082\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:16:44 (running for 00:01:21.05)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 8.9/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 3.0/4 CPUs, 3.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00001 with loss=2.883390426635742 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 PENDING, 3 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | RUNNING  | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |     84 |          77.0914 | 3.58771 |   1666390604 |            0.808979 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | RUNNING  | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |     79 |          60.8254 | 2.88339 |   1666390604 |            0.534844 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | RUNNING  | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |     96 |          61.0437 | 3.52122 |   1666390604 |            0.579567 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | PENDING  |                   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.9002120494842529\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390605\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 86\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-45\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: 2eced6db495d47e3884ccd2881ed51d8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-kubecon-2022-head-fdbbh\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 86\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.587474822998047\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.131.2.243\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 5222\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 78.84013271331787\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.9001662731170654\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 78.84013271331787\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390605\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 86\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.003857851028442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5768289566040039\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390606\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 100\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: dd304bcdf1c045e9b83b37b12b9b1462\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 100\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.5074374675750732\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 63.31861853599548\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5767760276794434\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 63.31861853599548\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390606\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 100\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037353038787841797\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.0074503421783447266\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390606\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 101\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   eval_loss: [3.6115200519561768, 3.6115567684173584, 3.6116087436676025, 3.611680746078491,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6117217540740967, 3.61177134513855, 3.611811399459839, 3.611851453781128, 3.611927032470703,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.612025260925293, 3.6121251583099365, 3.6122026443481445, 3.612255096435547, 3.612298011779785,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6123275756835938, 3.612358808517456, 3.6123855113983154, 3.6124136447906494, 3.61242413520813,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.612410545349121, 3.6124181747436523, 3.6124107837677, 3.612370729446411, 3.6123106479644775,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6122379302978516, 3.6121695041656494, 3.6120941638946533, 3.6120107173919678,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6119301319122314, 3.61185359954834, 3.6117677688598633, 3.6116631031036377, 3.611525297164917,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.611372947692871, 3.6111974716186523, 3.6109817028045654, 3.610715866088867, 3.6104557514190674,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6102216243743896, 3.6099584102630615, 3.6096699237823486, 3.609377145767212, 3.6091182231903076,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.608894109725952, 3.60868763923645, 3.6084814071655273, 3.6082820892333984, 3.6080551147460938,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.607781410217285, 3.607499361038208, 3.6072256565093994, 3.6069695949554443, 3.606654405593872,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.606340169906616, 3.606058120727539, 3.6057703495025635, 3.605494499206543, 3.605199098587036,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.604869842529297, 3.604543924331665, 3.6042118072509766, 3.6039116382598877, 3.60359787940979,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.603290557861328, 3.6029770374298096, 3.602644681930542, 3.6023099422454834, 3.6019537448883057,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6015889644622803, 3.601191759109497, 3.600715398788452, 3.6002111434936523, 3.5996906757354736,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.599217653274536, 3.5987141132354736, 3.598196029663086, 3.5976345539093018, 3.597095489501953,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5964622497558594, 3.5958240032196045, 3.5951669216156006, 3.594432830810547, 3.593662977218628,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.592848539352417, 3.592010259628296, 3.591078042984009, 3.590139389038086, 3.589169502258301,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5881173610687256, 3.586989641189575, 3.585761308670044, 3.5844297409057617, 3.5831077098846436,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5818538665771484, 3.580521821975708, 3.579225778579712, 3.5777928829193115, 3.5763022899627686,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5746476650238037, 3.5727341175079346]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: dd304bcdf1c045e9b83b37b12b9b1462\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_tag: 2_batch_size=4,epochs=100,lr=0.0010,momentum=0.9000,tune_run=True\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 101\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.5074374675750732\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   model: \"Sequential(\\n  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\\n  (1):\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\\n \\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\\n  (3): MaxPool2d(kernel_size=2,\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ stride=2, padding=0, dilation=1, ceil_mode=False)\\n  (4): Flatten(start_dim=1,\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ end_dim=-1)\\n  (5): Linear(in_features=6272, out_features=128, bias=True)\\n  (6):\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ ReLU()\\n  (7): Linear(in_features=128, out_features=64, bias=True)\\n  (8): ReLU()\\n\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\  (9): Linear(in_features=64, out_features=37, bias=True)\\n)\"\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 63.41196060180664\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.09334206581115723\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 63.41196060180664\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390606\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 101\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_loss: [3.6189706325531006, 3.6186025142669678, 3.6180784702301025, 3.617459297180176,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.616859197616577, 3.6162517070770264, 3.615682601928711, 3.615140199661255, 3.6146087646484375,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6140613555908203, 3.6135036945343018, 3.6129887104034424, 3.612494468688965, 3.6119461059570312,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.611422538757324, 3.610884666442871, 3.610337257385254, 3.6098079681396484, 3.6093273162841797,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6088554859161377, 3.608365774154663, 3.6078779697418213, 3.607370615005493, 3.6068665981292725,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6063520908355713, 3.605841875076294, 3.6053221225738525, 3.604771614074707, 3.6042282581329346,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6036911010742188, 3.603107452392578, 3.602497100830078, 3.6018784046173096, 3.6012585163116455,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6006181240081787, 3.599968910217285, 3.599261999130249, 3.598548173904419, 3.597839593887329,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5971038341522217, 3.596372604370117, 3.5956389904022217, 3.594937324523926, 3.5942718982696533,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.593637466430664, 3.593005418777466, 3.5923378467559814, 3.59165096282959, 3.5909459590911865,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5902299880981445, 3.5894882678985596, 3.588697671890259, 3.5878355503082275, 3.5869674682617188,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5861003398895264, 3.5852108001708984, 3.5843393802642822, 3.5834665298461914,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.582566976547241, 3.5816543102264404, 3.5807247161865234, 3.5797996520996094, 3.578852891921997,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5778849124908447, 3.576896905899048, 3.5758588314056396, 3.574816942214966, 3.5737085342407227,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5725719928741455, 3.571453809738159, 3.570314407348633, 3.569103479385376, 3.567805290222168,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.566495656967163, 3.5651443004608154, 3.563694715499878, 3.562185287475586, 3.5606677532196045,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.559117078781128, 3.5574605464935303, 3.5556697845458984, 3.553889274597168, 3.5520718097686768,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.550152540206909, 3.5481698513031006, 3.546070098876953, 3.543915033340454, 3.541688919067383,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5393829345703125, 3.5370588302612305, 3.5346333980560303, 3.5321576595306396,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5295441150665283, 3.5269429683685303, 3.5241641998291016, 3.521221876144409, 3.518057107925415,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.514760732650757, 3.511164665222168, 3.5074374675750732]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037353038787841797\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.6405527591705322\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390608\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 86\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-48\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: f21dc51fc8b2460db5f142df235a6505\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-v7c2t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 86\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 2.7026703357696533\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.4.75\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 64.96955966949463\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.6407465934753418\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 64.96955966949463\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390608\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 86\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.00398564338684082\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:16:50 (running for 00:01:26.54)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 8.9/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 3.0/4 CPUs, 3.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00001 with loss=2.6149775981903076 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (3 RUNNING, 1 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | RUNNING    | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |     90 |          82.5376 | 3.58698 |   1666390609 |          0.822655   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | RUNNING    | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |     89 |          66.6342 | 2.61498 |   1666390610 |          0.595227   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | RUNNING    | 10.128.2.79:294   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | TERMINATED | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |    101 |          63.412  | 3.50744 |   1666390606 |          0.00745034 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.8331136703491211\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390610\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 91\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-50\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: 2eced6db495d47e3884ccd2881ed51d8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-kubecon-2022-head-fdbbh\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 91\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.5868570804595947\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.131.2.243\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 5222\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 83.37094354629517\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.8333885669708252\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 83.37094354629517\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390610\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 91\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.003857851028442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=327, ip=10.128.2.79)\u001b[0m 2022-10-21 22:16:53,625\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=327, ip=10.128.2.79)\u001b[0m 2022-10-21 22:16:53,804\tINFO train_loop_utils.py:300 -- Moving model to device: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.6152818202972412\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390613\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 95\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-53\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: f21dc51fc8b2460db5f142df235a6505\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-v7c2t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 95\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 2.404608726501465\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.4.75\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 70.26891946792603\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.6150951385498047\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 70.26891946792603\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390613\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 95\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.00398564338684082\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:16:55 (running for 00:01:31.88)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 9.0/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 3.0/4 CPUs, 3.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00001 with loss=2.2888357639312744 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (3 RUNNING, 1 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | RUNNING    | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |     96 |          87.6682 | 3.58623 |   1666390614 |          0.826985   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | RUNNING    | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |     98 |          71.9332 | 2.28884 |   1666390615 |          0.536936   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | RUNNING    | 10.128.2.79:294   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | TERMINATED | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |    101 |          63.412  | 3.50744 |   1666390606 |          0.00745034 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 1.0299155712127686\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390616\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 98\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-56\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: 2eced6db495d47e3884ccd2881ed51d8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-kubecon-2022-head-fdbbh\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 98\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.5859673023223877\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.131.2.243\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 5222\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 89.5055820941925\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 1.0299861431121826\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 89.5055820941925\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390616\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 98\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.003857851028442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 3.764050245285034\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390617\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-57\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: a62c7f1435df4707bea722517510ac43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.6174614429473877\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 294\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 6.229147911071777\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 6.229147911071777\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 6.229147911071777\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390617\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037839412689208984\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.006142854690551758\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390616\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 101\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-56\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   eval_loss: [3.613758087158203, 3.612929582595825, 3.612309455871582, 3.6118335723876953,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6114275455474854, 3.611022710800171, 3.610628128051758, 3.6102635860443115, 3.609941244125366,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.609760284423828, 3.609565019607544, 3.6093356609344482, 3.6090476512908936, 3.6088407039642334,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6086463928222656, 3.6084718704223633, 3.6083080768585205, 3.608159065246582, 3.6079092025756836,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.607755422592163, 3.6076271533966064, 3.607452154159546, 3.6072330474853516, 3.606992483139038,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6067941188812256, 3.606559991836548, 3.606219530105591, 3.6059017181396484, 3.6055819988250732,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6052322387695312, 3.604950189590454, 3.604527711868286, 3.6041688919067383, 3.6037416458129883,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.603285074234009, 3.602658987045288, 3.602069139480591, 3.6014811992645264, 3.600919723510742,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.600276231765747, 3.5994746685028076, 3.5984785556793213, 3.5975217819213867, 3.596445322036743,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5951931476593018, 3.5938847064971924, 3.592313051223755, 3.5906145572662354, 3.588454008102417,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.586148262023926, 3.583723306655884, 3.580906629562378, 3.5775604248046875, 3.573678731918335,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.569777488708496, 3.56549072265625, 3.5604963302612305, 3.5542421340942383, 3.547184944152832,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5391979217529297, 3.5301554203033447, 3.5206422805786133, 3.5092384815216064,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.4980533123016357, 3.4857637882232666, 3.4740703105926514, 3.4600086212158203,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.4496467113494873, 3.43652606010437, 3.429997444152832, 3.419745445251465, 3.41467547416687,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.4086496829986572, 3.4027910232543945, 3.3992526531219482, 3.3949391841888428,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.3913185596466064, 3.3892295360565186, 3.386204957962036, 3.381986618041992, 3.3813228607177734,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.3800582885742188, 3.3745365142822266, 3.372967004776001, 3.3656527996063232, 3.365973472595215,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.3614561557769775, 3.357853889465332, 3.3558127880096436, 3.3518946170806885, 3.353417158126831,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.3489372730255127, 3.348250389099121, 3.3529083728790283, 3.3519630432128906, 3.3589704036712646,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.363926887512207, 3.362109899520874, 3.3731253147125244, 3.3702144622802734]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: f21dc51fc8b2460db5f142df235a6505\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_tag: 1_batch_size=4,epochs=100,lr=0.0100,momentum=0.5000,tune_run=True\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-v7c2t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 101\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 2.209505319595337\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   model: \"Sequential(\\n  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\\n  (1):\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\\n \\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\\n  (3): MaxPool2d(kernel_size=2,\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ stride=2, padding=0, dilation=1, ceil_mode=False)\\n  (4): Flatten(start_dim=1,\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ end_dim=-1)\\n  (5): Linear(in_features=6272, out_features=128, bias=True)\\n  (6):\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ ReLU()\\n  (7): Linear(in_features=128, out_features=64, bias=True)\\n  (8): ReLU()\\n\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\  (9): Linear(in_features=64, out_features=37, bias=True)\\n)\"\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.4.75\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 73.23564577102661\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.11359453201293945\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 73.23564577102661\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390616\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 101\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_loss: [3.6293420791625977, 3.626624822616577, 3.6241114139556885, 3.621652364730835,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6192493438720703, 3.617079973220825, 3.6148722171783447, 3.612687110900879, 3.6107559204101562,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6089096069335938, 3.607182502746582, 3.6054439544677734, 3.603684425354004, 3.601872205734253,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6000945568084717, 3.598264455795288, 3.596324920654297, 3.5943546295166016, 3.5923712253570557,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5904428958892822, 3.588331937789917, 3.5861263275146484, 3.584047317504883, 3.5818679332733154,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5796144008636475, 3.5772688388824463, 3.5748798847198486, 3.5723555088043213,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.569784164428711, 3.5670061111450195, 3.5641205310821533, 3.561063051223755, 3.557907819747925,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5545427799224854, 3.5510337352752686, 3.547388792037964, 3.5434865951538086, 3.5394551753997803,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5350751876831055, 3.530607223510742, 3.5258848667144775, 3.5208961963653564, 3.5154876708984375,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5098190307617188, 3.503854751586914, 3.4973232746124268, 3.4905271530151367, 3.4827470779418945,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.47436785697937, 3.4654712677001953, 3.4561691284179688, 3.4459075927734375, 3.434255361557007,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.4217891693115234, 3.4079959392547607, 3.3946592807769775, 3.3778982162475586,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.360689401626587, 3.3429315090179443, 3.3231499195098877, 3.303039789199829, 3.282693862915039,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.261220693588257, 3.236078977584839, 3.2114856243133545, 3.1865766048431396, 3.1621792316436768,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.137751340866089, 3.1141269207000732, 3.09023380279541, 3.0669963359832764, 3.0435791015625,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.020426034927368, 2.9976463317871094, 2.9753806591033936, 2.9517641067504883, 2.931403875350952,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     2.906294822692871, 2.883390426635742, 2.861156702041626, 2.8361518383026123, 2.810187578201294,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     2.7850341796875, 2.755862236022949, 2.729016065597534, 2.7026703357696533, 2.6724259853363037,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     2.6418440341949463, 2.6149775981903076, 2.5828821659088135, 2.5489284992218018,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     2.516855239868164, 2.4779770374298096, 2.4436657428741455, 2.404608726501465, 2.368291139602661,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     2.32757568359375, 2.2888357639312744, 2.247570276260376, 2.209505319595337]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.00398564338684082\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.023852109909057617\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390618\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 101\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-16-58\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   eval_loss: [3.6113245487213135, 3.611272096633911, 3.6112239360809326, 3.6111795902252197,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.61114501953125, 3.611098527908325, 3.6110446453094482, 3.61098575592041, 3.6109249591827393,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6108579635620117, 3.610788345336914, 3.610715866088867, 3.610640287399292, 3.610563278198242,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6104917526245117, 3.6104233264923096, 3.610353469848633, 3.6102778911590576, 3.61020565032959,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6101391315460205, 3.610074996948242, 3.6100056171417236, 3.6099369525909424, 3.6098735332489014,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6098079681396484, 3.6097404956817627, 3.6096715927124023, 3.609600305557251, 3.6095235347747803,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.609445810317993, 3.6093759536743164, 3.609304189682007, 3.609238862991333, 3.609177350997925,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6091148853302, 3.6090481281280518, 3.6089887619018555, 3.6089344024658203, 3.6088809967041016,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.60882306098938, 3.608764410018921, 3.608703851699829, 3.6086456775665283, 3.608591079711914,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.608535051345825, 3.608474016189575, 3.608412027359009, 3.6083505153656006, 3.608290672302246,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.608234405517578, 3.6081759929656982, 3.608119010925293, 3.6080615520477295, 3.6079978942871094,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.607930898666382, 3.6078646183013916, 3.6077983379364014, 3.6077308654785156, 3.607666015625,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.60760235786438, 3.6075332164764404, 3.6074647903442383, 3.6073997020721436, 3.607340097427368,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6072819232940674, 3.607226610183716, 3.6071717739105225, 3.607114553451538, 3.6070568561553955,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6069984436035156, 3.606940507888794, 3.60688853263855, 3.6068403720855713, 3.6067988872528076,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6067590713500977, 3.606717824935913, 3.606677770614624, 3.606638193130493, 3.6065988540649414,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.606555938720703, 3.6065123081207275, 3.6064682006835938, 3.606424331665039, 3.606379508972168,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6063432693481445, 3.6063077449798584, 3.606268882751465, 3.6062259674072266, 3.6061789989471436,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6061289310455322, 3.606083631515503, 3.6060428619384766, 3.6059987545013428, 3.6059486865997314,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6058976650238037, 3.6058435440063477, 3.6057846546173096, 3.6057310104370117,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6056766510009766, 3.6056182384490967]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: 2eced6db495d47e3884ccd2881ed51d8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_tag: 0_batch_size=4,epochs=100,lr=0.0010,momentum=0.5000,tune_run=True\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-kubecon-2022-head-fdbbh\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 101\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.585704803466797\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   model: \"Sequential(\\n  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\\n  (1):\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\\n \\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\\n  (3): MaxPool2d(kernel_size=2,\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ stride=2, padding=0, dilation=1, ceil_mode=False)\\n  (4): Flatten(start_dim=1,\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ end_dim=-1)\\n  (5): Linear(in_features=6272, out_features=128, bias=True)\\n  (6):\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ ReLU()\\n  (7): Linear(in_features=128, out_features=64, bias=True)\\n  (8): ReLU()\\n\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\  (9): Linear(in_features=64, out_features=37, bias=True)\\n)\"\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.131.2.243\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 5222\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 91.63402128219604\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.1230316162109375\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 91.63402128219604\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390618\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 101\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_loss: [3.6007702350616455, 3.600510597229004, 3.6002509593963623, 3.6000006198883057,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5997543334960938, 3.5995044708251953, 3.5992634296417236, 3.5990259647369385,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5987846851348877, 3.5985515117645264, 3.5983259677886963, 3.598098039627075, 3.5978739261627197,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.597651720046997, 3.597440719604492, 3.597242593765259, 3.5970561504364014, 3.5968821048736572,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.596715211868286, 3.596554756164551, 3.5963973999023438, 3.5962374210357666, 3.5960798263549805,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5959243774414062, 3.595768928527832, 3.595614194869995, 3.595461130142212, 3.595313310623169,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.595163106918335, 3.595018148422241, 3.5948753356933594, 3.5947301387786865, 3.594594717025757,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5944554805755615, 3.5943164825439453, 3.59417462348938, 3.59403133392334, 3.5938873291015625,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5937411785125732, 3.593595504760742, 3.593451738357544, 3.5933027267456055, 3.5931556224823,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.593006134033203, 3.59285831451416, 3.5927069187164307, 3.5925567150115967, 3.5924112796783447,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5922718048095703, 3.592132806777954, 3.5919981002807617, 3.5918664932250977, 3.5917317867279053,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5915908813476562, 3.5914437770843506, 3.591294288635254, 3.59114933013916, 3.5910022258758545,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5908563137054443, 3.5907156467437744, 3.5905768871307373, 3.590430498123169, 3.590294122695923,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.590162515640259, 3.5900354385375977, 3.5899131298065186, 3.589784622192383, 3.589653253555298,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.589519739151001, 3.5893867015838623, 3.5892598628997803, 3.5891292095184326, 3.589003324508667,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.588881254196167, 3.5887556076049805, 3.5886361598968506, 3.588519811630249, 3.588402509689331,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.588287353515625, 3.5881741046905518, 3.5880613327026367, 3.5879504680633545, 3.587829828262329,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.587712287902832, 3.5875959396362305, 3.587474822998047, 3.5873565673828125, 3.587231397628784,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.587106943130493, 3.5869786739349365, 3.5868570804595947, 3.5867350101470947, 3.5866153240203857,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.586484670639038, 3.5863516330718994, 3.5862255096435547, 3.5860936641693115, 3.5859673023223877,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5858352184295654, 3.585704803466797]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.003857851028442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:17:00 (running for 00:01:36.92)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 6.5/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 1.0/4 CPUs, 1.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00001 with loss=2.209505319595337 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 RUNNING, 3 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | RUNNING    | 10.128.2.79:294   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |      6 |          9.12065 | 3.58629 |   1666390620 |          0.614419   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | TERMINATED | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |    101 |         91.634   | 3.5857  |   1666390618 |          0.0238521  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | TERMINATED | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |    101 |         73.2356  | 2.20951 |   1666390616 |          0.00614285 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | TERMINATED | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |    101 |         63.412   | 3.50744 |   1666390606 |          0.00745034 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.6353378295898438\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390622\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 10\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-17-02\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: a62c7f1435df4707bea722517510ac43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 10\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.5463924407958984\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 294\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 11.470601081848145\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.6352267265319824\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 11.470601081848145\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390622\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 10\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037839412689208984\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:17:05 (running for 00:01:42.11)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 6.5/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 1.0/4 CPUs, 1.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00001 with loss=2.209505319595337 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 RUNNING, 3 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | RUNNING    | 10.128.2.79:294   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |     15 |          14.3086 | 3.45321 |   1666390625 |          0.525262   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | TERMINATED | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |    101 |          91.634  | 3.5857  |   1666390618 |          0.0238521  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | TERMINATED | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |    101 |          73.2356 | 2.20951 |   1666390616 |          0.00614285 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | TERMINATED | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |    101 |          63.412  | 3.50744 |   1666390606 |          0.00745034 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5924718379974365\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390627\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 19\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-17-07\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: a62c7f1435df4707bea722517510ac43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 19\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 3.206730604171753\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 294\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 16.600897789001465\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5929081439971924\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 16.600897789001465\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390627\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 19\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037839412689208984\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:17:11 (running for 00:01:47.70)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 6.5/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 1.0/4 CPUs, 1.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00001 with loss=2.209505319595337 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.5, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 RUNNING, 3 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | RUNNING    | 10.128.2.79:294   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |     24 |          19.5354 | 2.74628 |   1666390630 |          0.532801   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | TERMINATED | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |    101 |          91.634  | 3.5857  |   1666390618 |          0.0238521  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | TERMINATED | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |    101 |          73.2356 | 2.20951 |   1666390616 |          0.00614285 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | TERMINATED | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |    101 |          63.412  | 3.50744 |   1666390606 |          0.00745034 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5834736824035645\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390633\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 28\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-17-13\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: a62c7f1435df4707bea722517510ac43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 28\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 2.71319580078125\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 294\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 21.87427020072937\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5835676193237305\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 21.87427020072937\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390633\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 28\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037839412689208984\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:17:16 (running for 00:01:53.07)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 6.5/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 1.0/4 CPUs, 1.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00003 with loss=1.9371891021728516 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.9, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 RUNNING, 3 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | RUNNING    | 10.128.2.79:294   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |     34 |          25.2706 | 1.93719 |   1666390636 |          0.580536   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | TERMINATED | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |    101 |          91.634  | 3.5857  |   1666390618 |          0.0238521  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | TERMINATED | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |    101 |          73.2356 | 2.20951 |   1666390616 |          0.00614285 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | TERMINATED | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |    101 |          63.412  | 3.50744 |   1666390606 |          0.00745034 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5671133995056152\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390638\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 37\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-17-18\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: a62c7f1435df4707bea722517510ac43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 37\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 1.4725300073623657\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 294\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 27.03122854232788\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5672476291656494\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 27.03122854232788\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390638\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 37\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037839412689208984\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:17:21 (running for 00:01:58.31)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 6.5/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 1.0/4 CPUs, 1.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00003 with loss=0.8762888312339783 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.9, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 RUNNING, 3 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+----------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |     loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+----------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | RUNNING    | 10.128.2.79:294   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |     43 |          30.5063 | 0.876289 |   1666390641 |          0.593277   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | TERMINATED | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |    101 |          91.634  | 3.5857   |   1666390618 |          0.0238521  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | TERMINATED | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |    101 |          73.2356 | 2.20951  |   1666390616 |          0.00614285 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | TERMINATED | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |    101 |          63.412  | 3.50744  |   1666390606 |          0.00745034 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+----------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5335602760314941\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390643\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-17-23\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: a62c7f1435df4707bea722517510ac43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 0.5584753155708313\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 294\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 32.22073841094971\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5334069728851318\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 32.22073841094971\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390643\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037839412689208984\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:17:26 (running for 00:02:03.42)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 6.5/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 1.0/4 CPUs, 1.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00003 with loss=0.35809481143951416 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.9, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 RUNNING, 3 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+----------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |     loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+----------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | RUNNING    | 10.128.2.79:294   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |     52 |          35.6209 | 0.358095 |   1666390646 |          0.58903    |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | TERMINATED | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |    101 |          91.634  | 3.5857   |   1666390618 |          0.0238521  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | TERMINATED | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |    101 |          73.2356 | 2.20951  |   1666390616 |          0.00614285 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | TERMINATED | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |    101 |          63.412  | 3.50744  |   1666390606 |          0.00745034 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+----------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5665688514709473\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390648\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-17-28\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: a62c7f1435df4707bea722517510ac43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 0.2284517139196396\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 294\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 37.386462450027466\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5664570331573486\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 37.386462450027466\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390648\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037839412689208984\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:17:32 (running for 00:02:08.63)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 6.5/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 1.0/4 CPUs, 1.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00003 with loss=0.2353070229291916 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.9, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 RUNNING, 3 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+----------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |     loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+----------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | RUNNING    | 10.128.2.79:294   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |     61 |          40.8247 | 0.235307 |   1666390652 |          0.590184   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | TERMINATED | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |    101 |          91.634  | 3.5857   |   1666390618 |          0.0238521  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | TERMINATED | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |    101 |          73.2356 | 2.20951  |   1666390616 |          0.00614285 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | TERMINATED | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |    101 |          63.412  | 3.50744  |   1666390606 |          0.00745034 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+----------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5374696254730225\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390653\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 64\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-17-33\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: a62c7f1435df4707bea722517510ac43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 64\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 0.061762068420648575\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 294\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 42.545968770980835\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5374925136566162\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 42.545968770980835\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390653\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 64\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037839412689208984\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:17:37 (running for 00:02:13.78)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 6.5/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 1.0/4 CPUs, 1.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00003 with loss=0.037356022745370865 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.9, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 RUNNING, 3 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+----------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |     loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+----------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | RUNNING    | 10.128.2.79:294   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |     70 |          45.9778 | 0.037356 |   1666390657 |          0.601412   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | TERMINATED | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |    101 |          91.634  | 3.5857   |   1666390618 |          0.0238521  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | TERMINATED | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |    101 |          73.2356 | 2.20951  |   1666390616 |          0.00614285 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | TERMINATED | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |    101 |          63.412  | 3.50744  |   1666390606 |          0.00745034 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+----------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5737812519073486\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390659\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 73\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-17-39\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: a62c7f1435df4707bea722517510ac43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 73\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 0.05510299280285835\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 294\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 47.685630559921265\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5738375186920166\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 47.685630559921265\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390659\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 73\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037839412689208984\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:17:42 (running for 00:02:19.07)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 6.5/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 1.0/4 CPUs, 1.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00003 with loss=0.01771652139723301 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.9, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 RUNNING, 3 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+-----------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |      loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+-----------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | RUNNING    | 10.128.2.79:294   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |     79 |          51.2644 | 0.0177165 |   1666390662 |          0.576455   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | TERMINATED | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |    101 |          91.634  | 3.5857    |   1666390618 |          0.0238521  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | TERMINATED | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |    101 |          73.2356 | 2.20951   |   1666390616 |          0.00614285 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | TERMINATED | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |    101 |          63.412  | 3.50744   |   1666390606 |          0.00745034 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+-----------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5848500728607178\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390664\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 82\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-17-44\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: a62c7f1435df4707bea722517510ac43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 82\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 0.00443514296784997\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 294\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 52.98906326293945\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5844881534576416\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 52.98906326293945\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390664\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 82\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037839412689208984\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:17:47 (running for 00:02:24.22)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 6.5/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 1.0/4 CPUs, 1.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00003 with loss=0.006076833698898554 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.9, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 RUNNING, 3 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |       loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | RUNNING    | 10.128.2.79:294   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |     88 |          56.4168 | 0.00607683 |   1666390667 |          0.547568   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | TERMINATED | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |    101 |          91.634  | 3.5857     |   1666390618 |          0.0238521  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | TERMINATED | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |    101 |          73.2356 | 2.20951    |   1666390616 |          0.00614285 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | TERMINATED | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |    101 |          63.412  | 3.50744    |   1666390606 |          0.00745034 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.5782608985900879\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390669\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 91\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-17-49\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: a62c7f1435df4707bea722517510ac43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 91\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 0.0008311334531754255\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 294\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 58.16775560379028\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.5781023502349854\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 58.16775560379028\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390669\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 91\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037839412689208984\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:17:52 (running for 00:02:29.46)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 6.5/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 1.0/4 CPUs, 1.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00003 with loss=0.00036853845813311636 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.9, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (1 RUNNING, 3 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+-------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |        loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+-------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | RUNNING    | 10.128.2.79:294   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |     97 |          61.6541 | 0.000368538 |   1666390672 |          0.53011    |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | TERMINATED | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |    101 |          91.634  | 3.5857      |   1666390618 |          0.0238521  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | TERMINATED | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |    101 |          73.2356 | 2.20951     |   1666390616 |          0.00614285 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | TERMINATED | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |    101 |          63.412  | 3.50744     |   1666390606 |          0.00745034 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+-------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.6326522827148438\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390674\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 100\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-17-54\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: a62c7f1435df4707bea722517510ac43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 100\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 0.0002932526112999767\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 294\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 63.414057970047\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.6323745250701904\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 63.414057970047\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390674\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 100\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037839412689208984\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result for TorchTrainer_db9da_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _time_this_iter_s: 0.007708311080932617\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _timestamp: 1666390674\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   _training_iteration: 101\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   date: 2022-10-21_22-17-54\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   eval_loss: [3.613969087600708, 3.613375663757324, 3.613206624984741, 3.6130340099334717,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.612619400024414, 3.611487627029419, 3.610504388809204, 3.608902931213379, 3.6073853969573975,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.6050052642822266, 3.6019716262817383, 3.5989573001861572, 3.5940282344818115,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5846035480499268, 3.5691680908203125, 3.54766845703125, 3.5095112323760986, 3.473094940185547,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.415469169616699, 3.3827836513519287, 3.346529722213745, 3.3193881511688232, 3.3245742321014404,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.3746249675750732, 3.3898918628692627, 3.3902456760406494, 3.458481550216675, 3.354508399963379,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.3545522689819336, 3.3304312229156494, 3.3399293422698975, 3.3378236293792725,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.3261890411376953, 3.390244722366333, 3.434865951538086, 3.4922056198120117, 3.4452056884765625,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.3410606384277344, 3.358011484146118, 3.5328543186187744, 3.531095266342163, 3.4713096618652344,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.546412229537964, 3.6323254108428955, 3.796156167984009, 3.7325541973114014, 3.8653762340545654,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.9163436889648438, 3.852057695388794, 4.011738300323486, 3.706192970275879, 3.707599639892578,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     4.013861656188965, 3.8137121200561523, 4.2068562507629395, 4.292819499969482, 4.358762264251709,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     4.7068190574646, 4.462944507598877, 4.799404144287109, 5.231234550476074, 5.11565637588501,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     5.262171268463135, 5.594545841217041, 5.423770427703857, 5.797830104827881, 5.36781120300293,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     5.860170364379883, 5.579789638519287, 5.292063236236572, 6.602382659912109, 6.301362991333008,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     6.203094959259033, 7.135826110839844, 7.0654168128967285, 6.394852161407471, 7.461556911468506,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     7.320976257324219, 6.710764408111572, 7.782897472381592, 7.460832595825195, 7.327220439910889,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     8.05113697052002, 8.483859062194824, 8.564351081848145, 8.014134407043457, 9.222065925598145,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     8.795266151428223, 8.881244659423828, 9.259117126464844, 9.150469779968262, 9.260231971740723,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     9.30009651184082, 9.407071113586426, 9.578225135803223, 9.678736686706543, 9.774715423583984,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     9.850866317749023, 9.905367851257324, 9.964245796203613]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_id: a62c7f1435df4707bea722517510ac43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   experiment_tag: 3_batch_size=4,epochs=100,lr=0.0100,momentum=0.9000,tune_run=True\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   hostname: kubecon-2022-ray-cluster-example-worker-262g7\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   iterations_since_restore: 101\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   loss: 0.0002932526112999767\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   model: \"Sequential(\\n  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\\n  (1):\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\\n \\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\\n  (3): MaxPool2d(kernel_size=2,\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ stride=2, padding=0, dilation=1, ceil_mode=False)\\n  (4): Flatten(start_dim=1,\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ end_dim=-1)\\n  (5): Linear(in_features=6272, out_features=128, bias=True)\\n  (6):\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\ ReLU()\\n  (7): Linear(in_features=128, out_features=64, bias=True)\\n  (8): ReLU()\\n\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     \\  (9): Linear(in_features=64, out_features=37, bias=True)\\n)\"\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   node_ip: 10.128.2.79\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   pid: 294\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_since_restore: 63.51276707649231\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_this_iter_s: 0.0987091064453125\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   time_total_s: 63.51276707649231\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timestamp: 1666390674\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_iteration: 101\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   training_loss: [3.6174614429473877, 3.611246109008789, 3.605708360671997, 3.599907875061035,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5936663150787354, 3.586290121078491, 3.577397108078003, 3.5674774646759033, 3.557121992111206,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.5463924407958984, 3.534247398376465, 3.5213117599487305, 3.505648612976074, 3.489624261856079,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.45320725440979, 3.4147675037384033, 3.3506534099578857, 3.2886111736297607, 3.206730604171753,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     3.1447315216064453, 3.056403160095215, 2.9678447246551514, 2.8401119709014893, 2.7462785243988037,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     2.692950487136841, 2.763019561767578, 2.758016586303711, 2.71319580078125, 2.475550651550293,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     2.3640356063842773, 2.2325854301452637, 2.1261165142059326, 1.9612598419189453,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     1.9371891021728516, 1.8174322843551636, 1.6582401990890503, 1.4725300073623657,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     1.4211589097976685, 1.2830982208251953, 1.1764250993728638, 1.2080451250076294,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     1.114373803138733, 0.8762888312339783, 0.7918219566345215, 0.615712583065033, 0.5584753155708313,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     0.5660806894302368, 0.46407628059387207, 0.6291016936302185, 0.6836504936218262,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     0.5073274374008179, 0.35809481143951416, 0.2533627152442932, 0.32716700434684753,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     0.2284517139196396, 0.14100168645381927, 0.1308508962392807, 0.13232563436031342,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     0.17261089384555817, 0.25922468304634094, 0.2353070229291916, 0.1352940797805786,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     0.13622669875621796, 0.061762068420648575, 0.06941290944814682, 0.058999959379434586,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     0.10105868428945541, 0.0540330708026886, 0.067345529794693, 0.037356022745370865,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     0.05847100913524628, 0.023942872881889343, 0.05510299280285835, 0.05514292046427727,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     0.031230926513671875, 0.053268443793058395, 0.040882617235183716, 0.03488774970173836,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     0.01771652139723301, 0.019771751016378403, 0.011033982038497925, 0.00443514296784997,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     0.004853437654674053, 0.0032862043008208275, 0.0044065616093575954, 0.0023893078323453665,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     0.0011602513259276748, 0.006076833698898554, 0.0008908319869078696, 0.0008999915444292128,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     0.0008311334531754255, 0.0005780895589850843, 0.0005493806092999876, 0.0005296498420648277,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     0.0004390711837913841, 0.0004059200582560152, 0.00036853845813311636, 0.00033272881410084665,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m     0.00031025466159917414, 0.0002932526112999767]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   trial_id: db9da_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   warmup_time: 0.0037839412689208984\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current time: 2022-10-21 22:17:55 (running for 00:02:32.33)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Memory usage on this node: 6.5/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Resources requested: 0/4 CPUs, 0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Current best trial: db9da_00003 with loss=0.0002932526112999767 and parameters={'train_loop_config': {'lr': 0.01, 'momentum': 0.9, 'batch_size': 4, 'epochs': 100, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m Number of trials: 4/4 (4 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+-------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |        loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+-------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00000 | TERMINATED | 10.131.2.243:5222 |                      4 |                    100 |                  0.001 |                    0.5 | True                   |    101 |          91.634  | 3.5857      |   1666390618 |          0.0238521  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00001 | TERMINATED | 10.128.4.75:203   |                      4 |                    100 |                  0.01  |                    0.5 | True                   |    101 |          73.2356 | 2.20951     |   1666390616 |          0.00614285 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00002 | TERMINATED | 10.128.2.79:203   |                      4 |                    100 |                  0.001 |                    0.9 | True                   |    101 |          63.412  | 3.50744     |   1666390606 |          0.00745034 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m | TorchTrainer_db9da_00003 | TERMINATED | 10.128.2.79:294   |                      4 |                    100 |                  0.01  |                    0.9 | True                   |    101 |          63.5128 | 0.000293253 |   1666390674 |          0.00770831 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+-------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=5159)\u001b[0m 2022-10-21 22:17:55,958\tINFO tune.py:758 -- Total run time: 152.45 seconds (151.96 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 497 ms, sys: 362 ms, total: 859 ms\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_grid = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa6e0ef6-0e23-4e95-b382-8eec8e995c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.01, 'momentum': 0.9, 'batch_size': 4, 'epochs': 100, 'tune_run': True}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result = result_grid.get_best_result()\n",
    "best_model = best_result.metrics[\"model\"]\n",
    "model_scripted = torch.jit.script(best_model)\n",
    "model_scripted.save('models/best_model_scripted.pt')\n",
    "best_result.config['train_loop_config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff6893b8-d5ed-4822-a175-baca00e4defc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(best_result.metrics[\"training_loss\"])\n",
    "plt.plot(best_result.metrics[\"eval_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c79cdfe-76ec-4353-acb2-63f26146fc6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=Sequential\n",
       "  (0): RecursiveScriptModule(original_name=Conv2d)\n",
       "  (1): RecursiveScriptModule(original_name=MaxPool2d)\n",
       "  (2): RecursiveScriptModule(original_name=Conv2d)\n",
       "  (3): RecursiveScriptModule(original_name=MaxPool2d)\n",
       "  (4): RecursiveScriptModule(original_name=Flatten)\n",
       "  (5): RecursiveScriptModule(original_name=Linear)\n",
       "  (6): RecursiveScriptModule(original_name=ReLU)\n",
       "  (7): RecursiveScriptModule(original_name=Linear)\n",
       "  (8): RecursiveScriptModule(original_name=ReLU)\n",
       "  (9): RecursiveScriptModule(original_name=Linear)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.jit.load(\"models/best_model_scripted.pt\") \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c587d6b-2c52-4e7b-b1f5-71ab89c74cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:13\n",
      "prediction: 13\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(data_loader))\n",
    "make = ToPILImage()\n",
    "make(train_features[0]).show()\n",
    "print(f'label:{train_labels[0]}')\n",
    "logits = model(train_features[0].reshape(1,3,64,64).to(device))\n",
    "print(f\"prediction: {torch.argmax(logits).item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2e9df11-84a1-4600-a2fb-e3c614629706",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "y_pred = []\n",
    "\n",
    "for data in valid_dataset.iter_rows():\n",
    "    X.append(data[0])\n",
    "    y.append(data[1])\n",
    "    logit = model(data[0].reshape(1,3,64,64))\n",
    "    y_pred.append(torch.argmax(logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9035450-5092-420b-aa05-7bfab8b4e0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 10.1%\n",
      "Random guess would yield 7.6%\n",
      "Model outperforms Random chance by a factor of 1.32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "acc = accuracy_score(y_pred, y)\n",
    "kap = cohen_kappa_score(y_pred, y)\n",
    "print(f\"Accuracy: {acc*100:.1f}%\")\n",
    "print(f\"Random guess would yield {kap*100:.1f}%\")\n",
    "print(f\"Model outperforms Random chance by a factor of {(acc/kap):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a89e32c3-4e21-411a-9ded-ff04be4aa456",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(confusion_matrix(y_pred,y), cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48739528-a5a4-4ba1-b3fa-c8e7ad669bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubecon-2022\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"RAY_CLUSTER_NAME\"))\n",
    "# can keep this if you want to run serving\n",
    "#stop_ray_cluster()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
