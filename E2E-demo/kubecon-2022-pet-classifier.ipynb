{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7091d97e-22d2-4ae2-a006-b41f7f48f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.ray.io/en/latest/train/examples/train_fashion_mnist_example.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19004e51-c772-453f-9344-004a5ad3425e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Minimal\n"
     ]
    }
   ],
   "source": [
    "%xmode Minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f462ad35-dfca-45c5-850a-41971da6574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.modules.utils import consume_prefix_in_state_dict_if_present\n",
    "#import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Resize,Compose, ToPILImage\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import ray\n",
    "from ray import train\n",
    "from ray.air import session, Checkpoint\n",
    "from ray.air.config import ScalingConfig\n",
    "from ray.train.torch import TorchCheckpoint, TorchTrainer\n",
    "\n",
    "from ray.data.datasource import SimpleTorchDatasource\n",
    "from ray.data.preprocessors import Concatenator, Chain, StandardScaler\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune .tuner import Tuner, TuneConfig\n",
    "from ray.air.config import RunConfig\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ray_cluster_control import start_ray_cluster, stop_ray_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a964830-20ac-495d-bde2-7789058b40e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RayCluster \"octo-next-eje\" has started\n",
      "Access your cluster dashboard at http://ray-dashboard-octo-next-eje-open-data-hub.apps.et-gpu.zfq7.p1.openshiftapps.com\n"
     ]
    }
   ],
   "source": [
    "start_ray_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12c98cef-f712-460a-a012-e49c07c9bff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.12</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://10.131.2.239:8265\" target=\"_blank\">http://10.131.2.239:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "ClientContext(dashboard_url='10.131.2.239:8265', python_version='3.8.12', ray_version='2.0.0', ray_commit='cba26cc83f6b5b8a2ff166594a65cb74c0ec8740', protocol_version='2022-07-24', _num_clients=1, _context_to_restore=<ray.util.client._ClientContext object at 0x7f1a2cf2d340>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init('ray://{ray_head}-ray-head:10001'.format(ray_head=os.environ['RAY_CLUSTER_NAME']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bc51cd1-8164-4ffb-ab5b-95ba6ce5fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([Resize((64,64)),ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e87c2b0-65b2-4826-8f33-372cd777589f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz to data/oxford-iiit-pet/images.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0c924c8820419297d97632ea317dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/791918971 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/oxford-iiit-pet/images.tar.gz to data/oxford-iiit-pet\n",
      "Downloading https://thor.robots.ox.ac.uk/~vgg/data/pets/annotations.tar.gz to data/oxford-iiit-pet/annotations.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1a9ba950bc46999804d090663d6f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19173078 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/oxford-iiit-pet/annotations.tar.gz to data/oxford-iiit-pet\n"
     ]
    }
   ],
   "source": [
    "pet_data = torchvision.datasets.OxfordIIITPet(\"data/\",download = True ,  target_types = \"category\", transform = transforms, split = \"trainval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b594110-b434-4fb9-af1f-eec6a72bc8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(pet_data, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d38dc-8c47-4bad-914a-848d7253e278",
   "metadata": {},
   "source": [
    "This data set is only 3K and not the full 7k since we read in dataset with the `split` parameters that pulls in the files based on the corresponding txt file in `data/data/oxford-iiit-pet/annotations`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46b71da9-eee0-4d73-a66f-627ea21ff703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3680"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d6556aa-a289-4362-b1f3-cd6b475bed86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fca7583-31d4-4810-b7eb-ae9e950aa069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([4, 3, 64, 64])\n",
      "Labels batch shape: torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:6\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(data_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "make = ToPILImage()\n",
    "make(train_features[0]).show()\n",
    "print(f'label:{train_labels[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edcbd5f0-f556-4ef2-a32f-51a8710cef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvNet():\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, 16, 3, 1),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        nn.Conv2d(16, 32, 3,1 ),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(6272 , 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 37)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ab90031-d1d3-4b6f-8196-e6b763e12a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (4): Flatten(start_dim=1, end_dim=-1)\n",
       "  (5): Linear(in_features=6272, out_features=128, bias=True)\n",
       "  (6): ReLU()\n",
       "  (7): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Linear(in_features=64, out_features=37, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a087b70-4b2e-45c3-8bb6-30f1724b3f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f342828-9af0-4be7-ad81-a2cbc833f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_x(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c984e60-6867-4155-afbf-e1532f8ba71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 5.96 µs\n",
      "Train Epoch: 0 [0/3680 (0%)]\tLoss: 3.655046\n",
      "Train Epoch: 1 [0/3680 (0%)]\tLoss: 3.604965\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "for epoch in range(2):\n",
    "    train_x(net,device,data_loader, optimizer, epoch) \n",
    "    \n",
    "state_dict = net.state_dict()\n",
    "consume_prefix_in_state_dict_if_present(state_dict, \"module.\")        \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9e48146-7dea-4e47-93ca-4436bcdb1167",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scripted = torch.jit.script(net)\n",
    "model_scripted.save('model_scripted.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14e90ff7-b3f0-4bcc-8488-e09e7839f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now with Ray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15475bd5-e2f1-4a9b-894e-f7e238a72928",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_execute_read_task pid=334)\u001b[0m Downloading https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz to data/oxford-iiit-pet/images.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/791918971 [00:00<?, ?it/s]\n",
      "  0%|          | 98304/791918971 [00:00<21:44, 606979.40it/s]\n",
      "  0%|          | 393216/791918971 [00:00<10:02, 1314633.97it/s]\n",
      "  0%|          | 1605632/791918971 [00:00<03:12, 4109025.54it/s]\n",
      "  1%|          | 4751360/791918971 [00:00<01:17, 10092573.42it/s]\n",
      "  1%|          | 7864320/791918971 [00:00<00:53, 14558695.88it/s]\n",
      "  1%|          | 9437184/791918971 [00:00<00:55, 14131803.55it/s]\n",
      "  2%|▏         | 12517376/791918971 [00:01<00:45, 17315213.54it/s]\n",
      "  2%|▏         | 14319616/791918971 [00:01<00:46, 16595545.36it/s]\n",
      "  2%|▏         | 17235968/791918971 [00:01<00:41, 18677712.75it/s]\n",
      "  2%|▏         | 19136512/791918971 [00:01<00:43, 17763177.44it/s]\n",
      "  3%|▎         | 21921792/791918971 [00:01<00:40, 19214514.55it/s]\n",
      "  3%|▎         | 23887872/791918971 [00:01<00:42, 18267017.78it/s]\n",
      "  3%|▎         | 26640384/791918971 [00:01<00:42, 17838516.54it/s]\n",
      "  4%|▍         | 29720576/791918971 [00:01<00:36, 20933930.35it/s]\n",
      "  4%|▍         | 31916032/791918971 [00:02<00:40, 18874491.28it/s]\n",
      "  4%|▍         | 34439168/791918971 [00:02<00:39, 19407534.96it/s]\n",
      "  5%|▍         | 36470784/791918971 [00:02<00:40, 18540914.95it/s]\n",
      "  5%|▍         | 39124992/791918971 [00:02<00:38, 19489103.11it/s]\n",
      "  5%|▌         | 41123840/791918971 [00:02<00:40, 18505719.15it/s]\n",
      "  6%|▌         | 43810816/791918971 [00:02<00:36, 20302148.68it/s]\n",
      "  6%|▌         | 45907968/791918971 [00:02<00:40, 18561139.44it/s]\n",
      "  6%|▌         | 48496640/791918971 [00:02<00:36, 20114952.19it/s]\n",
      "  6%|▋         | 50561024/791918971 [00:03<00:40, 18345290.21it/s]\n",
      "  7%|▋         | 53182464/791918971 [00:03<00:37, 19810150.04it/s]\n",
      "  7%|▋         | 55214080/791918971 [00:03<01:02, 11777767.52it/s]\n",
      "  7%|▋         | 57344000/791918971 [00:03<00:55, 13225454.95it/s]\n",
      "  7%|▋         | 59080704/791918971 [00:03<00:52, 13890727.35it/s]\n",
      "  8%|▊         | 60981248/791918971 [00:03<00:49, 14850714.28it/s]\n",
      "  8%|▊         | 63569920/791918971 [00:03<00:41, 17389856.54it/s]\n",
      "  8%|▊         | 65536000/791918971 [00:04<00:43, 16527634.82it/s]\n",
      "  9%|▊         | 68124672/791918971 [00:04<00:38, 18656007.79it/s]\n",
      "  9%|▉         | 70156288/791918971 [00:04<00:41, 17401359.26it/s]\n",
      "  9%|▉         | 72482816/791918971 [00:04<00:38, 18887540.23it/s]\n",
      "  9%|▉         | 74514432/791918971 [00:04<00:37, 19158605.43it/s]\n",
      " 10%|▉         | 76513280/791918971 [00:04<00:39, 17973209.60it/s]\n",
      " 10%|▉         | 79003648/791918971 [00:04<00:35, 19805503.32it/s]\n",
      " 10%|█         | 81068032/791918971 [00:04<00:39, 18025327.76it/s]\n",
      " 11%|█         | 83361792/791918971 [00:04<00:36, 19249562.85it/s]\n",
      " 11%|█         | 85458944/791918971 [00:05<00:36, 19392968.50it/s]\n",
      " 11%|█         | 87457792/791918971 [00:05<00:38, 18291061.57it/s]\n",
      " 11%|█▏        | 90013696/791918971 [00:05<00:35, 19928313.93it/s]\n",
      " 12%|█▏        | 92078080/791918971 [00:05<00:38, 18211083.45it/s]\n",
      " 12%|█▏        | 94568448/791918971 [00:05<00:34, 19959954.03it/s]\n",
      " 12%|█▏        | 96632832/791918971 [00:05<00:38, 18203624.33it/s]\n",
      " 12%|█▏        | 98795520/791918971 [00:05<00:36, 19073791.44it/s]\n",
      " 13%|█▎        | 101089280/791918971 [00:05<00:35, 19701681.99it/s]\n",
      " 13%|█▎        | 103120896/791918971 [00:06<00:37, 18533284.84it/s]\n",
      " 13%|█▎        | 105611264/791918971 [00:06<00:34, 20141149.34it/s]\n",
      " 14%|█▎        | 107675648/791918971 [00:06<00:37, 18329331.11it/s]\n",
      " 14%|█▍        | 109903872/791918971 [00:06<00:35, 19324769.67it/s]\n",
      " 14%|█▍        | 112033792/791918971 [00:06<00:34, 19614485.12it/s]\n",
      " 14%|█▍        | 114065408/791918971 [00:06<00:37, 18253616.24it/s]\n",
      " 15%|█▍        | 116555776/791918971 [00:06<00:33, 19947839.12it/s]\n",
      " 15%|█▍        | 118620160/791918971 [00:06<00:36, 18229622.51it/s]\n",
      " 15%|█▌        | 121044992/791918971 [00:06<00:33, 19798349.73it/s]\n",
      " 16%|█▌        | 123109376/791918971 [00:07<00:35, 18639146.48it/s]\n",
      " 16%|█▌        | 125042688/791918971 [00:07<00:36, 18451115.77it/s]\n",
      " 16%|█▌        | 127565824/791918971 [00:07<00:32, 20268516.45it/s]\n",
      " 16%|█▋        | 129662976/791918971 [00:07<00:35, 18469624.04it/s]\n",
      " 17%|█▋        | 132186112/791918971 [00:07<00:33, 19987403.54it/s]\n",
      " 17%|█▋        | 134250496/791918971 [00:07<00:36, 18258580.58it/s]\n",
      " 17%|█▋        | 136675328/791918971 [00:07<00:33, 19793656.58it/s]\n",
      " 18%|█▊        | 138739712/791918971 [00:07<00:35, 18567341.23it/s]\n",
      " 18%|█▊        | 140673024/791918971 [00:07<00:35, 18505156.11it/s]\n",
      " 18%|█▊        | 143163392/791918971 [00:08<00:32, 20206006.21it/s]\n",
      " 18%|█▊        | 145227776/791918971 [00:08<00:35, 18422583.02it/s]\n",
      " 19%|█▊        | 147587072/791918971 [00:08<00:32, 19768295.78it/s]\n",
      " 19%|█▉        | 149651456/791918971 [00:08<00:33, 18939195.24it/s]\n",
      " 19%|█▉        | 151617536/791918971 [00:08<00:34, 18339349.27it/s]\n",
      " 19%|█▉        | 154173440/791918971 [00:08<00:32, 19844611.13it/s]\n",
      " 20%|█▉        | 156205056/791918971 [00:08<00:34, 18527391.56it/s]\n",
      " 20%|██        | 158629888/791918971 [00:08<00:31, 20051346.02it/s]\n",
      " 20%|██        | 160694272/791918971 [00:09<00:34, 18326520.75it/s]\n",
      " 21%|██        | 162758656/791918971 [00:09<00:33, 18896174.74it/s]\n",
      " 21%|██        | 165085184/791918971 [00:09<00:31, 19886248.76it/s]\n",
      " 21%|██        | 167116800/791918971 [00:09<00:33, 18440010.54it/s]\n",
      " 21%|██▏       | 169508864/791918971 [00:09<00:31, 19907282.36it/s]\n",
      " 22%|██▏       | 171573248/791918971 [00:09<00:33, 18693605.68it/s]\n",
      " 22%|██▏       | 173506560/791918971 [00:09<00:33, 18456959.15it/s]\n",
      " 22%|██▏       | 176029696/791918971 [00:09<00:31, 19864935.95it/s]\n",
      " 22%|██▏       | 178061312/791918971 [00:09<00:33, 18517094.22it/s]\n",
      " 23%|██▎       | 180453376/791918971 [00:10<00:30, 19944337.46it/s]\n",
      " 23%|██▎       | 182517760/791918971 [00:10<00:32, 18748336.67it/s]\n",
      " 23%|██▎       | 184451072/791918971 [00:10<00:32, 18489217.61it/s]\n",
      " 24%|██▎       | 186974208/791918971 [00:10<00:30, 19900798.44it/s]\n",
      " 24%|██▍       | 189005824/791918971 [00:10<00:32, 18522906.11it/s]\n",
      " 24%|██▍       | 191397888/791918971 [00:10<00:30, 19949534.28it/s]\n",
      " 24%|██▍       | 193462272/791918971 [00:10<00:32, 18366664.56it/s]\n",
      " 25%|██▍       | 195395584/791918971 [00:10<00:32, 18619162.76it/s]\n",
      " 25%|██▍       | 197885952/791918971 [00:10<00:29, 20049370.00it/s]\n",
      " 25%|██▌       | 199950336/791918971 [00:11<00:31, 18569119.98it/s]\n",
      " 26%|██▌       | 202309632/791918971 [00:11<00:29, 19891547.10it/s]\n",
      " 26%|██▌       | 204374016/791918971 [00:11<00:31, 18752872.60it/s]\n",
      " 26%|██▌       | 206307328/791918971 [00:11<00:31, 18471547.62it/s]\n",
      " 26%|██▋       | 208830464/791918971 [00:11<00:28, 20189890.76it/s]\n",
      " 27%|██▋       | 210894848/791918971 [00:11<00:31, 18501981.43it/s]\n",
      " 27%|██▋       | 213254144/791918971 [00:11<00:29, 19839556.24it/s]\n",
      " 27%|██▋       | 215285760/791918971 [00:11<00:30, 18664210.30it/s]\n",
      " 27%|██▋       | 217219072/791918971 [00:12<00:31, 18402293.20it/s]\n",
      " 28%|██▊       | 219774976/791918971 [00:12<00:28, 19936948.71it/s]\n",
      " 28%|██▊       | 221806592/791918971 [00:12<00:30, 18507926.25it/s]\n",
      " 28%|██▊       | 224198656/791918971 [00:12<00:28, 19931266.55it/s]\n",
      " 29%|██▊       | 226263040/791918971 [00:12<00:30, 18423165.76it/s]\n",
      " 29%|██▉       | 228163584/791918971 [00:12<00:30, 18519513.62it/s]\n",
      " 29%|██▉       | 230686720/791918971 [00:12<00:27, 20285617.94it/s]\n",
      " 29%|██▉       | 232783872/791918971 [00:12<00:30, 18375484.09it/s]\n",
      " 30%|██▉       | 235241472/791918971 [00:12<00:27, 20012004.29it/s]\n",
      " 30%|██▉       | 237305856/791918971 [00:13<00:30, 18464109.99it/s]\n",
      " 30%|███       | 239304704/791918971 [00:13<00:29, 18864343.34it/s]\n",
      " 31%|███       | 241631232/791918971 [00:13<00:27, 19897619.23it/s]\n",
      " 31%|███       | 243662848/791918971 [00:13<00:29, 18435624.43it/s]\n",
      " 31%|███       | 246054912/791918971 [00:13<00:27, 19875898.73it/s]\n",
      " 31%|███▏      | 248119296/791918971 [00:13<00:28, 18810374.81it/s]\n",
      " 32%|███▏      | 250052608/791918971 [00:13<00:29, 18461293.17it/s]\n",
      " 32%|███▏      | 252575744/791918971 [00:13<00:27, 19931368.10it/s]\n",
      " 32%|███▏      | 254607360/791918971 [00:13<00:29, 18487590.85it/s]\n",
      " 32%|███▏      | 256933888/791918971 [00:14<00:27, 19753574.46it/s]\n",
      " 33%|███▎      | 258965504/791918971 [00:14<00:27, 19112425.21it/s]\n",
      " 33%|███▎      | 260931584/791918971 [00:14<00:28, 18427766.09it/s]\n",
      " 33%|███▎      | 263356416/791918971 [00:14<00:26, 19993924.39it/s]\n",
      " 34%|███▎      | 265388032/791918971 [00:14<00:28, 18358000.27it/s]\n",
      " 34%|███▍      | 267386880/791918971 [00:14<00:27, 18784167.36it/s]\n",
      " 34%|███▍      | 269746176/791918971 [00:14<00:26, 19942062.27it/s]\n",
      " 34%|███▍      | 271777792/791918971 [00:14<00:28, 18460053.59it/s]\n",
      " 35%|███▍      | 274104320/791918971 [00:14<00:26, 19747556.03it/s]\n",
      " 35%|███▍      | 276135936/791918971 [00:15<00:26, 19156282.38it/s]\n",
      " 35%|███▌      | 278102016/791918971 [00:15<00:27, 18417130.25it/s]\n",
      " 35%|███▌      | 280559616/791918971 [00:15<00:25, 20048940.45it/s]\n",
      " 36%|███▌      | 282624000/791918971 [00:15<00:27, 18330674.05it/s]\n",
      " 36%|███▌      | 284852224/791918971 [00:15<00:26, 19333335.19it/s]\n",
      " 36%|███▌      | 286982144/791918971 [00:15<00:25, 19619283.00it/s]\n",
      " 36%|███▋      | 288980992/791918971 [00:15<00:27, 18450048.31it/s]\n",
      " 37%|███▋      | 291274752/791918971 [00:15<00:25, 19654262.61it/s]\n",
      " 37%|███▋      | 293306368/791918971 [00:15<00:26, 19134756.70it/s]\n",
      " 37%|███▋      | 295272448/791918971 [00:16<00:27, 18354026.44it/s]\n",
      " 38%|███▊      | 297730048/791918971 [00:16<00:24, 20006620.51it/s]\n",
      " 38%|███▊      | 299761664/791918971 [00:16<00:26, 18393559.09it/s]\n",
      " 38%|███▊      | 301694976/791918971 [00:16<00:26, 18642565.40it/s]\n",
      " 38%|███▊      | 304119808/791918971 [00:16<00:24, 20028554.00it/s]\n",
      " 39%|███▊      | 306184192/791918971 [00:16<00:26, 18379310.61it/s]\n",
      " 39%|███▉      | 308674560/791918971 [00:16<00:24, 20046163.90it/s]\n",
      " 39%|███▉      | 310738944/791918971 [00:16<00:26, 18359148.09it/s]\n",
      " 40%|███▉      | 312901632/791918971 [00:17<00:24, 19218449.23it/s]\n",
      " 40%|███▉      | 315097088/791918971 [00:17<00:24, 19657763.67it/s]\n",
      " 40%|████      | 317128704/791918971 [00:17<00:25, 18348989.95it/s]\n",
      " 40%|████      | 319586304/791918971 [00:17<00:23, 19965658.02it/s]\n",
      " 41%|████      | 321650688/791918971 [00:17<00:25, 18463265.81it/s]\n",
      " 41%|████      | 323616768/791918971 [00:17<00:24, 18743331.89it/s]\n",
      " 41%|████      | 325976064/791918971 [00:17<00:23, 19974327.38it/s]\n",
      " 41%|████▏     | 328040448/791918971 [00:17<00:25, 18343346.80it/s]\n",
      " 42%|████▏     | 330530816/791918971 [00:17<00:23, 20012914.98it/s]\n",
      " 42%|████▏     | 332595200/791918971 [00:18<00:25, 18351232.30it/s]\n",
      " 42%|████▏     | 334725120/791918971 [00:18<00:23, 19125905.55it/s]\n",
      " 43%|████▎     | 336953344/791918971 [00:18<00:23, 19720861.54it/s]\n",
      " 43%|████▎     | 338984960/791918971 [00:18<00:24, 18360886.10it/s]\n",
      " 43%|████▎     | 341442560/791918971 [00:18<00:22, 19967881.52it/s]\n",
      " 43%|████▎     | 343506944/791918971 [00:18<00:24, 18485059.12it/s]\n",
      " 44%|████▎     | 345440256/791918971 [00:18<00:23, 18700648.57it/s]\n",
      " 44%|████▍     | 347865088/791918971 [00:18<00:22, 20095636.44it/s]\n",
      " 44%|████▍     | 349929472/791918971 [00:18<00:24, 18375951.16it/s]\n",
      " 44%|████▍     | 352387072/791918971 [00:19<00:22, 19967344.02it/s]\n",
      " 45%|████▍     | 354451456/791918971 [00:19<00:23, 18509313.11it/s]\n",
      " 45%|████▌     | 356384768/791918971 [00:19<00:23, 18700659.72it/s]\n",
      " 45%|████▌     | 358776832/791918971 [00:19<00:21, 20020198.29it/s]\n",
      " 46%|████▌     | 360841216/791918971 [00:19<00:23, 18326622.43it/s]\n",
      " 46%|████▌     | 363003904/791918971 [00:19<00:22, 18772642.47it/s]\n",
      " 46%|████▌     | 364937216/791918971 [00:19<00:23, 18043606.69it/s]\n",
      " 46%|████▋     | 367099904/791918971 [00:19<00:22, 18972717.34it/s]\n",
      " 47%|████▋     | 369262592/791918971 [00:19<00:21, 19282126.00it/s]\n",
      " 47%|████▋     | 371228672/791918971 [00:20<00:22, 18412382.49it/s]\n",
      " 47%|████▋     | 373358592/791918971 [00:20<00:21, 19190532.05it/s]\n",
      " 47%|████▋     | 375521280/791918971 [00:20<00:21, 19453991.46it/s]\n",
      " 48%|████▊     | 377487360/791918971 [00:20<00:22, 18511871.23it/s]\n",
      " 48%|████▊     | 379617280/791918971 [00:20<00:21, 19265911.88it/s]\n",
      " 48%|████▊     | 381779968/791918971 [00:20<00:21, 19504033.76it/s]\n",
      " 48%|████▊     | 383746048/791918971 [00:20<00:22, 18551772.47it/s]\n",
      " 49%|████▊     | 385843200/791918971 [00:20<00:21, 19207809.12it/s]\n",
      " 49%|████▉     | 388005888/791918971 [00:20<00:20, 19794036.61it/s]\n",
      " 49%|████▉     | 390004736/791918971 [00:21<00:21, 18496701.73it/s]\n",
      " 50%|████▉     | 392134656/791918971 [00:21<00:20, 19270476.62it/s]\n",
      " 50%|████▉     | 394231808/791918971 [00:21<00:20, 19682006.03it/s]\n",
      " 50%|█████     | 396230656/791918971 [00:21<00:21, 18410787.53it/s]\n",
      " 50%|█████     | 398327808/791918971 [00:21<00:20, 19117999.90it/s]\n",
      " 51%|█████     | 400490496/791918971 [00:21<00:19, 19753814.39it/s]\n",
      " 51%|█████     | 402489344/791918971 [00:21<00:21, 18456386.60it/s]\n",
      " 51%|█████     | 404586496/791918971 [00:21<00:20, 19141979.60it/s]\n",
      " 51%|█████▏    | 406749184/791918971 [00:21<00:19, 19568578.43it/s]\n",
      " 52%|█████▏    | 408748032/791918971 [00:22<00:20, 18527083.02it/s]\n",
      " 52%|█████▏    | 410845184/791918971 [00:22<00:19, 19189917.11it/s]\n",
      " 52%|█████▏    | 413007872/791918971 [00:22<00:19, 19527345.33it/s]\n",
      " 52%|█████▏    | 415006720/791918971 [00:22<00:20, 18572516.79it/s]\n",
      " 53%|█████▎    | 417103872/791918971 [00:22<00:19, 19227343.50it/s]\n",
      " 53%|█████▎    | 419266560/791918971 [00:22<00:19, 19562774.86it/s]\n",
      " 53%|█████▎    | 421265408/791918971 [00:22<00:19, 18585497.67it/s]\n",
      " 53%|█████▎    | 423362560/791918971 [00:22<00:19, 19243886.69it/s]\n",
      " 54%|█████▎    | 425492480/791918971 [00:22<00:18, 19499137.57it/s]\n",
      " 54%|█████▍    | 427458560/791918971 [00:23<00:19, 18442946.68it/s]\n",
      " 54%|█████▍    | 429588480/791918971 [00:23<00:18, 19226043.14it/s]\n",
      " 55%|█████▍    | 431751168/791918971 [00:23<00:18, 19582124.48it/s]\n",
      " 55%|█████▍    | 433750016/791918971 [00:23<00:19, 18571392.21it/s]\n",
      " 55%|█████▌    | 435847168/791918971 [00:23<00:18, 19230797.22it/s]\n",
      " 55%|█████▌    | 438009856/791918971 [00:23<00:18, 19532354.42it/s]\n",
      " 56%|█████▌    | 439975936/791918971 [00:23<00:19, 18512153.38it/s]\n",
      " 56%|█████▌    | 442040320/791918971 [00:23<00:18, 19094436.20it/s]\n",
      " 56%|█████▌    | 444235776/791918971 [00:23<00:17, 19835232.82it/s]\n",
      " 56%|█████▋    | 446234624/791918971 [00:24<00:18, 18511624.10it/s]\n",
      " 57%|█████▋    | 448299008/791918971 [00:24<00:18, 19085656.27it/s]\n",
      " 57%|█████▋    | 450494464/791918971 [00:24<00:17, 19781031.92it/s]\n",
      " 57%|█████▋    | 452493312/791918971 [00:24<00:18, 18488380.50it/s]\n",
      " 57%|█████▋    | 454590464/791918971 [00:24<00:17, 19070629.16it/s]\n",
      " 58%|█████▊    | 456753152/791918971 [00:24<00:17, 19570897.15it/s]\n",
      " 58%|█████▊    | 458752000/791918971 [00:24<00:17, 18543448.77it/s]\n",
      " 58%|█████▊    | 460849152/791918971 [00:24<00:17, 19131250.02it/s]\n",
      " 58%|█████▊    | 463011840/791918971 [00:24<00:16, 19632235.49it/s]\n",
      " 59%|█████▊    | 465010688/791918971 [00:24<00:17, 18573023.89it/s]\n",
      " 59%|█████▉    | 467107840/791918971 [00:25<00:16, 19153071.56it/s]\n",
      " 59%|█████▉    | 469237760/791918971 [00:25<00:16, 19584437.68it/s]\n",
      " 60%|█████▉    | 471236608/791918971 [00:25<00:17, 18538524.48it/s]\n",
      " 60%|█████▉    | 473333760/791918971 [00:25<00:16, 19098044.20it/s]\n",
      " 60%|██████    | 475496448/791918971 [00:25<00:16, 19629705.58it/s]\n",
      " 60%|██████    | 477495296/791918971 [00:25<00:16, 18559623.34it/s]\n",
      " 61%|██████    | 479592448/791918971 [00:25<00:16, 19149366.38it/s]\n",
      " 61%|██████    | 481755136/791918971 [00:25<00:15, 19657968.62it/s]\n",
      " 61%|██████    | 483753984/791918971 [00:25<00:16, 18558900.67it/s]\n",
      " 61%|██████▏   | 485851136/791918971 [00:26<00:15, 19161549.80it/s]\n",
      " 62%|██████▏   | 487981056/791918971 [00:26<00:15, 19584896.07it/s]\n",
      " 62%|██████▏   | 489979904/791918971 [00:26<00:16, 18537404.43it/s]\n",
      " 62%|██████▏   | 492077056/791918971 [00:26<00:15, 19119832.23it/s]\n",
      " 62%|██████▏   | 494239744/791918971 [00:26<00:15, 19656524.50it/s]\n",
      " 63%|██████▎   | 496238592/791918971 [00:26<00:15, 18530089.70it/s]\n",
      " 63%|██████▎   | 498335744/791918971 [00:26<00:15, 19146824.72it/s]\n",
      " 63%|██████▎   | 500498432/791918971 [00:26<00:14, 19808541.55it/s]\n",
      " 63%|██████▎   | 502497280/791918971 [00:26<00:15, 18510160.48it/s]\n",
      " 64%|██████▎   | 504561664/791918971 [00:27<00:15, 19041957.79it/s]\n",
      " 64%|██████▍   | 506724352/791918971 [00:27<00:14, 19608524.34it/s]\n",
      " 64%|██████▍   | 508723200/791918971 [00:27<00:15, 18524612.30it/s]\n",
      " 65%|██████▍   | 510820352/791918971 [00:27<00:14, 19123724.00it/s]\n",
      " 65%|██████▍   | 512983040/791918971 [00:27<00:14, 19662891.76it/s]\n",
      " 65%|██████▌   | 514981888/791918971 [00:27<00:14, 18526040.61it/s]\n",
      " 65%|██████▌   | 517079040/791918971 [00:27<00:14, 19146142.67it/s]\n",
      " 66%|██████▌   | 519208960/791918971 [00:27<00:13, 19745539.20it/s]\n",
      " 66%|██████▌   | 521207808/791918971 [00:27<00:14, 18465834.05it/s]\n",
      " 66%|██████▌   | 523304960/791918971 [00:28<00:14, 19083076.31it/s]\n",
      " 66%|██████▋   | 525467648/791918971 [00:28<00:13, 19795565.44it/s]\n",
      " 67%|██████▋   | 527499264/791918971 [00:28<00:14, 18556440.27it/s]\n",
      " 67%|██████▋   | 529563648/791918971 [00:28<00:13, 19078985.48it/s]\n",
      " 67%|██████▋   | 531726336/791918971 [00:28<00:13, 19747377.04it/s]\n",
      " 67%|██████▋   | 533725184/791918971 [00:28<00:13, 18484743.86it/s]\n",
      " 68%|██████▊   | 535822336/791918971 [00:28<00:13, 19081778.17it/s]\n",
      " 68%|██████▊   | 537985024/791918971 [00:28<00:12, 19693936.18it/s]\n",
      " 68%|██████▊   | 539983872/791918971 [00:28<00:13, 18518584.96it/s]\n",
      " 68%|██████▊   | 542048256/791918971 [00:29<00:13, 19035380.07it/s]\n",
      " 69%|██████▊   | 544210944/791918971 [00:29<00:12, 19675042.60it/s]\n",
      " 69%|██████▉   | 546209792/791918971 [00:29<00:13, 18503220.58it/s]\n",
      " 69%|██████▉   | 548306944/791918971 [00:29<00:12, 19093663.47it/s]\n",
      " 70%|██████▉   | 550469632/791918971 [00:29<00:12, 19720040.48it/s]\n",
      " 70%|██████▉   | 552468480/791918971 [00:29<00:12, 18511653.22it/s]\n",
      " 70%|███████   | 554565632/791918971 [00:29<00:12, 19119689.86it/s]\n",
      " 70%|███████   | 556728320/791918971 [00:29<00:11, 19735393.39it/s]\n",
      " 71%|███████   | 558727168/791918971 [00:29<00:12, 18523658.16it/s]\n",
      " 71%|███████   | 560791552/791918971 [00:29<00:12, 19042307.52it/s]\n",
      " 71%|███████   | 562954240/791918971 [00:30<00:11, 19689397.53it/s]\n",
      " 71%|███████▏  | 564953088/791918971 [00:30<00:12, 18489589.05it/s]\n",
      " 72%|███████▏  | 567050240/791918971 [00:30<00:11, 19098855.25it/s]\n",
      " 72%|███████▏  | 569212928/791918971 [00:30<00:11, 19741157.52it/s]\n",
      " 72%|███████▏  | 571211776/791918971 [00:30<00:11, 18520606.36it/s]\n",
      " 72%|███████▏  | 573308928/791918971 [00:30<00:11, 19117011.87it/s]\n",
      " 73%|███████▎  | 575471616/791918971 [00:30<00:10, 19761862.70it/s]\n",
      " 73%|███████▎  | 577470464/791918971 [00:30<00:11, 18513326.91it/s]\n",
      " 73%|███████▎  | 579534848/791918971 [00:30<00:11, 19040150.42it/s]\n",
      " 73%|███████▎  | 581697536/791918971 [00:31<00:10, 19721705.26it/s]\n",
      " 74%|███████▎  | 583696384/791918971 [00:31<00:11, 18471557.59it/s]\n",
      " 74%|███████▍  | 585793536/791918971 [00:31<00:10, 19092580.28it/s]\n",
      " 74%|███████▍  | 587956224/791918971 [00:31<00:10, 19763271.00it/s]\n",
      " 74%|███████▍  | 589955072/791918971 [00:31<00:10, 18495158.14it/s]\n",
      " 75%|███████▍  | 592052224/791918971 [00:31<00:10, 19104421.05it/s]\n",
      " 75%|███████▌  | 594182144/791918971 [00:31<00:10, 19698379.82it/s]\n",
      " 75%|███████▌  | 596180992/791918971 [00:31<00:10, 18462508.35it/s]\n",
      " 76%|███████▌  | 598278144/791918971 [00:31<00:10, 19055322.21it/s]\n",
      " 76%|███████▌  | 600440832/791918971 [00:32<00:09, 19733722.47it/s]\n",
      " 76%|███████▌  | 602439680/791918971 [00:32<00:10, 18469176.09it/s]\n",
      " 76%|███████▋  | 604536832/791918971 [00:32<00:09, 19102434.52it/s]\n",
      " 77%|███████▋  | 606699520/791918971 [00:32<00:09, 19764329.72it/s]\n",
      " 77%|███████▋  | 608698368/791918971 [00:32<00:09, 18496394.11it/s]\n",
      " 77%|███████▋  | 610795520/791918971 [00:32<00:09, 19118414.89it/s]\n",
      " 77%|███████▋  | 612925440/791918971 [00:32<00:09, 19699489.17it/s]\n",
      " 78%|███████▊  | 614924288/791918971 [00:32<00:09, 18473434.45it/s]\n",
      " 78%|███████▊  | 616955904/791918971 [00:32<00:09, 18980856.72it/s]\n",
      " 78%|███████▊  | 619184128/791918971 [00:33<00:08, 19760042.88it/s]\n",
      " 78%|███████▊  | 621182976/791918971 [00:33<00:09, 18500310.10it/s]\n",
      " 79%|███████▊  | 623280128/791918971 [00:33<00:08, 19096154.89it/s]\n",
      " 79%|███████▉  | 625410048/791918971 [00:33<00:08, 19689589.11it/s]\n",
      " 79%|███████▉  | 627408896/791918971 [00:33<00:08, 18493278.44it/s]\n",
      " 79%|███████▉  | 629473280/791918971 [00:33<00:08, 19062542.47it/s]\n",
      " 80%|███████▉  | 631668736/791918971 [00:33<00:08, 19734606.66it/s]\n",
      " 80%|████████  | 633667584/791918971 [00:33<00:08, 18531338.61it/s]\n",
      " 80%|████████  | 635699200/791918971 [00:33<00:08, 19013092.32it/s]\n",
      " 81%|████████  | 637927424/791918971 [00:34<00:07, 19783840.68it/s]\n",
      " 81%|████████  | 639926272/791918971 [00:34<00:08, 18530346.90it/s]\n",
      " 81%|████████  | 641957888/791918971 [00:34<00:07, 19018358.26it/s]\n",
      " 81%|████████▏ | 644153344/791918971 [00:34<00:07, 19839439.54it/s]\n",
      " 82%|████████▏ | 646184960/791918971 [00:34<00:07, 18541956.74it/s]\n",
      " 82%|████████▏ | 648216576/791918971 [00:34<00:07, 19028352.09it/s]\n",
      " 82%|████████▏ | 650412032/791918971 [00:34<00:07, 19733235.51it/s]\n",
      " 82%|████████▏ | 652410880/791918971 [00:34<00:07, 18532289.62it/s]\n",
      " 83%|████████▎ | 654376960/791918971 [00:34<00:07, 18839707.29it/s]\n",
      " 83%|████████▎ | 656670720/791918971 [00:35<00:06, 19830316.97it/s]\n",
      " 83%|████████▎ | 658702336/791918971 [00:35<00:07, 18636585.17it/s]\n",
      " 83%|████████▎ | 660701184/791918971 [00:35<00:06, 19005472.11it/s]\n",
      " 84%|████████▎ | 662896640/791918971 [00:35<00:06, 19729669.17it/s]\n",
      " 84%|████████▍ | 664895488/791918971 [00:35<00:06, 18517947.40it/s]\n",
      " 84%|████████▍ | 666894336/791918971 [00:35<00:06, 18924806.13it/s]\n",
      " 84%|████████▍ | 669155328/791918971 [00:35<00:06, 19791740.67it/s]\n",
      " 85%|████████▍ | 671154176/791918971 [00:35<00:06, 18573170.09it/s]\n",
      " 85%|████████▍ | 673120256/791918971 [00:35<00:06, 18871520.28it/s]\n",
      " 85%|████████▌ | 675414016/791918971 [00:35<00:05, 19858523.08it/s]\n",
      " 86%|████████▌ | 677445632/791918971 [00:36<00:06, 18649508.58it/s]\n",
      " 86%|████████▌ | 679510016/791918971 [00:36<00:05, 19127990.53it/s]\n",
      " 86%|████████▌ | 681672704/791918971 [00:36<00:05, 19792387.77it/s]\n",
      " 86%|████████▋ | 683671552/791918971 [00:36<00:05, 18522091.67it/s]\n",
      " 87%|████████▋ | 685670400/791918971 [00:36<00:05, 18922056.51it/s]\n",
      " 87%|████████▋ | 687898624/791918971 [00:36<00:05, 19756685.94it/s]\n",
      " 87%|████████▋ | 689897472/791918971 [00:36<00:05, 18526780.31it/s]\n",
      " 87%|████████▋ | 691929088/791918971 [00:36<00:05, 18980538.55it/s]\n",
      " 88%|████████▊ | 694157312/791918971 [00:36<00:04, 19799714.87it/s]\n",
      " 88%|████████▊ | 696156160/791918971 [00:37<00:05, 18538356.52it/s]\n",
      " 88%|████████▊ | 698187776/791918971 [00:37<00:04, 19007889.45it/s]\n",
      " 88%|████████▊ | 700416000/791918971 [00:37<00:04, 19831503.03it/s]\n",
      " 89%|████████▊ | 702447616/791918971 [00:37<00:04, 18619396.30it/s]\n",
      " 89%|████████▉ | 704413696/791918971 [00:37<00:04, 18905347.61it/s]\n",
      " 89%|████████▉ | 706641920/791918971 [00:37<00:04, 19765420.27it/s]\n",
      " 89%|████████▉ | 708640768/791918971 [00:37<00:04, 18541655.47it/s]\n",
      " 90%|████████▉ | 710606848/791918971 [00:37<00:04, 18830672.31it/s]\n",
      " 90%|█████████ | 712900608/791918971 [00:37<00:03, 19861303.64it/s]\n",
      " 90%|█████████ | 714932224/791918971 [00:38<00:04, 18622742.27it/s]\n",
      " 91%|█████████ | 716931072/791918971 [00:38<00:03, 18988197.97it/s]\n",
      " 91%|█████████ | 719126528/791918971 [00:38<00:03, 19760737.29it/s]\n",
      " 91%|█████████ | 721125376/791918971 [00:38<00:03, 18520079.16it/s]\n",
      " 91%|█████████▏| 723091456/791918971 [00:38<00:03, 18820289.81it/s]\n",
      " 92%|█████████▏| 725385216/791918971 [00:38<00:03, 19856305.26it/s]\n",
      " 92%|█████████▏| 727416832/791918971 [00:38<00:03, 18624615.20it/s]\n",
      " 92%|█████████▏| 729415680/791918971 [00:38<00:03, 18989679.57it/s]\n",
      " 92%|█████████▏| 731643904/791918971 [00:38<00:03, 19846597.61it/s]\n",
      " 93%|█████████▎| 733675520/791918971 [00:39<00:03, 18610305.96it/s]\n",
      " 93%|█████████▎| 735674368/791918971 [00:39<00:02, 18979635.12it/s]\n",
      " 93%|█████████▎| 737869824/791918971 [00:39<00:02, 19756771.17it/s]\n",
      " 94%|█████████▎| 741769216/791918971 [00:39<00:02, 18658259.63it/s]\n",
      " 94%|█████████▍| 744062976/791918971 [00:39<00:02, 19857794.72it/s]\n",
      " 94%|█████████▍| 746094592/791918971 [00:39<00:02, 18565575.87it/s]\n",
      " 94%|█████████▍| 748027904/791918971 [00:39<00:02, 18766960.72it/s]\n",
      " 95%|█████████▍| 750321664/791918971 [00:39<00:02, 19918197.70it/s]\n",
      " 95%|█████████▌| 752353280/791918971 [00:40<00:02, 18624048.64it/s]\n",
      " 95%|█████████▌| 754286592/791918971 [00:40<00:02, 18805992.12it/s]\n",
      " 96%|█████████▌| 756547584/791918971 [00:40<00:01, 19856309.34it/s]\n",
      " 96%|█████████▌| 758579200/791918971 [00:40<00:01, 18593201.58it/s]\n",
      " 96%|█████████▌| 760512512/791918971 [00:40<00:01, 18793099.81it/s]\n",
      " 96%|█████████▋| 762806272/791918971 [00:40<00:01, 19912925.29it/s]\n",
      " 97%|█████████▋| 764837888/791918971 [00:40<00:01, 18633772.52it/s]\n",
      " 97%|█████████▋| 766771200/791918971 [00:40<00:01, 18794015.75it/s]\n",
      " 97%|█████████▋| 769064960/791918971 [00:40<00:01, 19937109.80it/s]\n",
      " 97%|█████████▋| 771096576/791918971 [00:41<00:01, 18653457.58it/s]\n",
      " 98%|█████████▊| 773029888/791918971 [00:41<00:01, 18808053.98it/s]\n",
      " 98%|█████████▊| 775290880/791918971 [00:41<00:00, 19868891.33it/s]\n",
      " 98%|█████████▊| 777322496/791918971 [00:41<00:00, 18593817.38it/s]\n",
      " 98%|█████████▊| 779255808/791918971 [00:41<00:00, 18772643.63it/s]\n",
      " 99%|█████████▊| 781549568/791918971 [00:41<00:00, 19923864.27it/s]\n",
      " 99%|█████████▉| 783581184/791918971 [00:41<00:00, 18640544.16it/s]\n",
      " 99%|█████████▉| 785514496/791918971 [00:41<00:00, 18804680.36it/s]\n",
      " 99%|█████████▉| 787775488/791918971 [00:41<00:00, 19842966.41it/s]\n",
      "100%|█████████▉| 789807104/791918971 [00:41<00:00, 18594234.38it/s]\n",
      "100%|██████████| 791918971/791918971 [00:42<00:00, 18808683.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_execute_read_task pid=334)\u001b[0m Extracting data/oxford-iiit-pet/images.tar.gz to data/oxford-iiit-pet\n",
      "\u001b[2m\u001b[36m(_execute_read_task pid=334)\u001b[0m Downloading https://thor.robots.ox.ac.uk/~vgg/data/pets/annotations.tar.gz to data/oxford-iiit-pet/annotations.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19173078 [00:00<?, ?it/s]\n",
      "  1%|          | 98304/19173078 [00:00<00:31, 603616.07it/s]\n",
      "  2%|▏         | 393216/19173078 [00:00<00:12, 1535093.65it/s]\n",
      "  5%|▍         | 884736/19173078 [00:00<00:07, 2591939.27it/s]\n",
      " 17%|█▋        | 3211264/19173078 [00:00<00:01, 8775800.93it/s]\n",
      " 25%|██▌       | 4849664/19173078 [00:00<00:01, 10409518.81it/s]\n",
      " 41%|████▏     | 7929856/19173078 [00:00<00:00, 15299369.15it/s]\n",
      " 50%|████▉     | 9535488/19173078 [00:00<00:00, 14605831.22it/s]\n",
      " 66%|██████▌   | 12615680/19173078 [00:01<00:00, 17920374.49it/s]\n",
      " 75%|███████▌  | 14450688/19173078 [00:01<00:00, 17000271.00it/s]\n",
      " 90%|█████████ | 17301504/19173078 [00:01<00:00, 18934385.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_execute_read_task pid=334)\u001b[0m Extracting data/oxford-iiit-pet/annotations.tar.gz to data/oxford-iiit-pet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19173078/19173078 [00:01<00:00, 13795056.75it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_factory = lambda: torchvision.datasets.OxfordIIITPet(\"data/\", download = True, target_types = \"category\", transform = transforms, split = \"trainval\")\n",
    "dataset = ray.data.read_datasource(\n",
    "    SimpleTorchDatasource(), parallelism=1, dataset_factory=dataset_factory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cf435f6-d9b2-487b-8e23-1af3e3259610",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shuffle Map:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(map pid=178, ip=10.128.4.70)\u001b[0m Downloading https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz to data/oxford-iiit-pet/images.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/791918971 [00:00<?, ?it/s]\n",
      "  0%|          | 98304/791918971 [00:00<21:40, 608903.93it/s]\n",
      "  0%|          | 393216/791918971 [00:00<10:02, 1313240.78it/s]\n",
      "  0%|          | 1605632/791918971 [00:00<02:50, 4637085.58it/s]\n",
      "  0%|          | 3244032/791918971 [00:00<01:41, 7778826.40it/s]\n",
      "  1%|          | 5996544/791918971 [00:00<01:01, 12695662.47it/s]\n",
      "  1%|          | 8060928/791918971 [00:00<00:55, 14110791.54it/s]\n",
      "  1%|▏         | 10682368/791918971 [00:00<00:47, 16403166.96it/s]\n",
      "  2%|▏         | 12812288/791918971 [00:01<00:46, 16785103.17it/s]\n",
      "  2%|▏         | 15368192/791918971 [00:01<00:43, 17994420.49it/s]\n",
      "  2%|▏         | 17563648/791918971 [00:01<00:42, 18387623.33it/s]\n",
      "  3%|▎         | 20152320/791918971 [00:01<00:40, 18838568.41it/s]\n",
      "  3%|▎         | 22249472/791918971 [00:01<00:41, 18728156.77it/s]\n",
      "  3%|▎         | 24969216/791918971 [00:01<00:36, 20906363.72it/s]\n",
      "  3%|▎         | 27099136/791918971 [00:01<00:41, 18418947.94it/s]\n",
      "  4%|▍         | 29753344/791918971 [00:01<00:39, 19382536.95it/s]\n",
      "  4%|▍         | 31752192/791918971 [00:02<00:40, 18547068.43it/s]\n",
      "  4%|▍         | 34537472/791918971 [00:02<00:37, 20427598.68it/s]\n",
      "  5%|▍         | 36634624/791918971 [00:02<00:40, 18739392.85it/s]\n",
      "  5%|▍         | 39354368/791918971 [00:02<00:37, 19839687.42it/s]\n",
      "  5%|▌         | 41385984/791918971 [00:02<00:39, 18797701.18it/s]\n",
      "  6%|▌         | 44105728/791918971 [00:02<00:35, 20796385.41it/s]\n",
      "  6%|▌         | 46235648/791918971 [00:02<00:39, 18824664.56it/s]\n",
      "  6%|▌         | 48922624/791918971 [00:02<00:37, 20010931.77it/s]\n",
      "  6%|▋         | 50987008/791918971 [00:03<00:39, 18830275.90it/s]\n",
      "  7%|▋         | 53608448/791918971 [00:03<00:35, 20657703.59it/s]\n",
      "  7%|▋         | 55738368/791918971 [00:03<00:39, 18643975.22it/s]\n",
      "  7%|▋         | 58359808/791918971 [00:03<00:35, 20505319.00it/s]\n",
      "  8%|▊         | 60489728/791918971 [00:03<00:39, 18580435.29it/s]\n",
      "  8%|▊         | 63111168/791918971 [00:03<00:35, 20477136.29it/s]\n",
      "  8%|▊         | 65273856/791918971 [00:03<00:39, 18544944.46it/s]\n",
      "  9%|▊         | 67862528/791918971 [00:03<00:35, 20400149.08it/s]\n",
      "  9%|▉         | 70025216/791918971 [00:03<00:38, 18534577.70it/s]\n",
      "  9%|▉         | 72613888/791918971 [00:04<00:35, 20292744.74it/s]\n",
      "  9%|▉         | 74743808/791918971 [00:04<00:38, 18469341.90it/s]\n",
      " 10%|▉         | 77299712/791918971 [00:04<00:35, 20260642.55it/s]\n",
      " 10%|█         | 79429632/791918971 [00:04<00:38, 18376520.64it/s]\n",
      " 10%|█         | 81985536/791918971 [00:04<00:35, 20192521.51it/s]\n",
      " 11%|█         | 84115456/791918971 [00:04<00:38, 18464928.88it/s]\n",
      " 11%|█         | 86671360/791918971 [00:04<00:35, 20108785.32it/s]\n",
      " 11%|█         | 88768512/791918971 [00:04<00:38, 18335186.17it/s]\n",
      " 12%|█▏        | 91357184/791918971 [00:05<00:34, 20093170.24it/s]\n",
      " 12%|█▏        | 93454336/791918971 [00:05<00:37, 18737676.80it/s]\n",
      " 12%|█▏        | 95518720/791918971 [00:05<00:36, 19126707.87it/s]\n",
      " 12%|█▏        | 98009088/791918971 [00:05<00:33, 20599412.58it/s]\n",
      " 13%|█▎        | 100139008/791918971 [00:05<00:36, 18752860.14it/s]\n",
      " 13%|█▎        | 102563840/791918971 [00:05<00:34, 20173361.24it/s]\n",
      " 13%|█▎        | 104660992/791918971 [00:05<00:36, 19001632.13it/s]\n",
      " 13%|█▎        | 106627072/791918971 [00:05<00:36, 19028531.85it/s]\n",
      " 14%|█▍        | 108920832/791918971 [00:05<00:34, 20065776.71it/s]\n",
      " 14%|█▍        | 111050752/791918971 [00:06<00:33, 20125673.05it/s]\n",
      " 14%|█▍        | 113115136/791918971 [00:06<00:35, 18876586.89it/s]\n",
      " 15%|█▍        | 115507200/791918971 [00:06<00:33, 20139938.10it/s]\n",
      " 15%|█▍        | 117571584/791918971 [00:06<00:36, 18641843.63it/s]\n",
      " 15%|█▌        | 119668736/791918971 [00:06<00:34, 19255705.41it/s]\n",
      " 15%|█▌        | 121962496/791918971 [00:06<00:33, 20167947.65it/s]\n",
      " 16%|█▌        | 124026880/791918971 [00:06<00:35, 18812662.61it/s]\n",
      " 16%|█▌        | 126058496/791918971 [00:06<00:34, 19219764.80it/s]\n",
      " 16%|█▌        | 128385024/791918971 [00:06<00:32, 20308622.41it/s]\n",
      " 16%|█▋        | 130449408/791918971 [00:07<00:35, 18726376.71it/s]\n",
      " 17%|█▋        | 132743168/791918971 [00:07<00:33, 19761250.49it/s]\n",
      " 17%|█▋        | 134905856/791918971 [00:07<00:32, 19958913.76it/s]\n",
      " 17%|█▋        | 136937472/791918971 [00:07<00:35, 18680571.18it/s]\n",
      " 18%|█▊        | 139198464/791918971 [00:07<00:33, 19615367.77it/s]\n",
      " 18%|█▊        | 141328384/791918971 [00:07<00:32, 19899512.80it/s]\n",
      " 18%|█▊        | 143360000/791918971 [00:07<00:34, 18636196.07it/s]\n",
      " 18%|█▊        | 145719296/791918971 [00:07<00:32, 19828669.92it/s]\n",
      " 19%|█▊        | 147750912/791918971 [00:07<00:32, 19883698.57it/s]\n",
      " 19%|█▉        | 149782528/791918971 [00:08<00:34, 18698470.37it/s]\n",
      " 19%|█▉        | 152043520/791918971 [00:08<00:32, 19771084.78it/s]\n",
      " 19%|█▉        | 154140672/791918971 [00:08<00:31, 19950312.98it/s]\n",
      " 20%|█▉        | 156172288/791918971 [00:08<00:34, 18678813.32it/s]\n",
      " 20%|██        | 158466048/791918971 [00:08<00:31, 19837846.66it/s]\n",
      " 20%|██        | 160530432/791918971 [00:08<00:31, 19767635.12it/s]\n",
      " 21%|██        | 162529280/791918971 [00:08<00:33, 18713053.87it/s]\n",
      " 21%|██        | 164757504/791918971 [00:08<00:32, 19570406.41it/s]\n",
      " 21%|██        | 166789120/791918971 [00:08<00:31, 19645091.53it/s]\n",
      " 21%|██▏       | 168787968/791918971 [00:09<00:33, 18637045.10it/s]\n",
      " 22%|██▏       | 171016192/791918971 [00:09<00:31, 19514017.31it/s]\n",
      " 22%|██▏       | 173178880/791918971 [00:09<00:30, 20070146.97it/s]\n",
      " 22%|██▏       | 175210496/791918971 [00:09<00:32, 18738103.02it/s]\n",
      " 22%|██▏       | 177405952/791918971 [00:09<00:31, 19606420.45it/s]\n",
      " 23%|██▎       | 179470336/791918971 [00:09<00:30, 19828725.41it/s]\n",
      " 23%|██▎       | 181501952/791918971 [00:09<00:32, 18678633.83it/s]\n",
      " 23%|██▎       | 183631872/791918971 [00:09<00:31, 19383809.24it/s]\n",
      " 23%|██▎       | 185729024/791918971 [00:09<00:30, 19826493.75it/s]\n",
      " 24%|██▎       | 187760640/791918971 [00:10<00:31, 19030465.94it/s]\n",
      " 24%|██▍       | 189693952/791918971 [00:10<00:31, 18954600.72it/s]\n",
      " 24%|██▍       | 191791104/791918971 [00:10<00:30, 19486801.19it/s]\n",
      " 24%|██▍       | 193855488/791918971 [00:10<00:30, 19803949.73it/s]\n",
      " 25%|██▍       | 195854336/791918971 [00:10<00:32, 18619056.78it/s]\n",
      " 25%|██▍       | 197885952/791918971 [00:10<00:31, 19026597.60it/s]\n",
      " 25%|██▌       | 200114176/791918971 [00:10<00:29, 19893949.97it/s]\n",
      " 26%|██▌       | 202145792/791918971 [00:10<00:30, 19082451.47it/s]\n",
      " 26%|██▌       | 204144640/791918971 [00:10<00:31, 18920401.77it/s]\n",
      " 26%|██▌       | 206405632/791918971 [00:11<00:29, 19920769.92it/s]\n",
      " 26%|██▋       | 208437248/791918971 [00:11<00:29, 19457038.81it/s]\n",
      " 27%|██▋       | 210403328/791918971 [00:11<00:30, 19057489.93it/s]\n",
      " 27%|██▋       | 212598784/791918971 [00:11<00:29, 19751246.98it/s]\n",
      " 27%|██▋       | 214630400/791918971 [00:11<00:29, 19721254.66it/s]\n",
      " 27%|██▋       | 216629248/791918971 [00:11<00:30, 18719010.05it/s]\n",
      " 28%|██▊       | 218791936/791918971 [00:11<00:29, 19524360.19it/s]\n",
      " 28%|██▊       | 220921856/791918971 [00:11<00:28, 20007914.25it/s]\n",
      " 28%|██▊       | 222953472/791918971 [00:11<00:30, 18427287.83it/s]\n",
      " 28%|██▊       | 225214464/791918971 [00:11<00:29, 19371808.93it/s]\n",
      " 29%|██▊       | 227377152/791918971 [00:12<00:28, 19801858.76it/s]\n",
      " 29%|██▉       | 229408768/791918971 [00:12<00:30, 18743405.78it/s]\n",
      " 29%|██▉       | 231538688/791918971 [00:12<00:28, 19398877.72it/s]\n",
      " 30%|██▉       | 233701376/791918971 [00:12<00:28, 19777720.45it/s]\n",
      " 30%|██▉       | 235700224/791918971 [00:12<00:29, 18753751.36it/s]\n",
      " 30%|███       | 237797376/791918971 [00:12<00:28, 19298049.76it/s]\n",
      " 30%|███       | 239927296/791918971 [00:12<00:28, 19631428.18it/s]\n",
      " 31%|███       | 241958912/791918971 [00:12<00:27, 19723715.13it/s]\n",
      " 31%|███       | 243957760/791918971 [00:12<00:29, 18799605.16it/s]\n",
      " 31%|███       | 246185984/791918971 [00:13<00:28, 19471327.38it/s]\n",
      " 31%|███▏      | 248184832/791918971 [00:13<00:27, 19617073.72it/s]\n",
      " 32%|███▏      | 250183680/791918971 [00:13<00:28, 19174585.47it/s]\n",
      " 32%|███▏      | 252116992/791918971 [00:13<00:28, 18937832.41it/s]\n",
      " 32%|███▏      | 254246912/791918971 [00:13<00:27, 19244189.35it/s]\n",
      " 32%|███▏      | 256344064/791918971 [00:13<00:27, 19662547.35it/s]\n",
      " 33%|███▎      | 258342912/791918971 [00:13<00:28, 18796156.36it/s]\n",
      " 33%|███▎      | 260505600/791918971 [00:13<00:27, 19220127.42it/s]\n",
      " 33%|███▎      | 262701056/791918971 [00:13<00:26, 19902221.32it/s]\n",
      " 33%|███▎      | 264699904/791918971 [00:14<00:27, 18958776.46it/s]\n",
      " 34%|███▎      | 266797056/791918971 [00:14<00:27, 19318617.27it/s]\n",
      " 34%|███▍      | 268959744/791918971 [00:14<00:26, 19735285.00it/s]\n",
      " 34%|███▍      | 270958592/791918971 [00:14<00:27, 19227220.50it/s]\n",
      " 34%|███▍      | 273055744/791918971 [00:14<00:27, 19133536.51it/s]\n",
      " 35%|███▍      | 275218432/791918971 [00:14<00:26, 19592433.72it/s]\n",
      " 35%|███▌      | 277184512/791918971 [00:14<00:26, 19229689.53it/s]\n",
      " 35%|███▌      | 279248896/791918971 [00:14<00:26, 19525222.74it/s]\n",
      " 36%|███▌      | 281214976/791918971 [00:14<00:26, 19178237.65it/s]\n",
      " 36%|███▌      | 283279360/791918971 [00:14<00:26, 19457055.05it/s]\n",
      " 36%|███▌      | 285245440/791918971 [00:15<00:26, 19189867.32it/s]\n",
      " 36%|███▋      | 287244288/791918971 [00:15<00:25, 19412474.77it/s]\n",
      " 37%|███▋      | 289210368/791918971 [00:15<00:26, 19334040.53it/s]\n",
      " 37%|███▋      | 291176448/791918971 [00:15<00:26, 19092735.71it/s]\n",
      " 37%|███▋      | 293142528/791918971 [00:15<00:25, 19255907.87it/s]\n",
      " 37%|███▋      | 295239680/791918971 [00:15<00:25, 19439306.83it/s]\n",
      " 38%|███▊      | 297205760/791918971 [00:15<00:25, 19266827.94it/s]\n",
      " 38%|███▊      | 299139072/791918971 [00:15<00:25, 18999946.81it/s]\n",
      " 38%|███▊      | 301301760/791918971 [00:15<00:24, 19761777.91it/s]\n",
      " 38%|███▊      | 303300608/791918971 [00:16<00:25, 19185325.53it/s]\n",
      " 39%|███▊      | 305233920/791918971 [00:16<00:25, 18859260.05it/s]\n",
      " 39%|███▉      | 307298304/791918971 [00:16<00:25, 19334055.03it/s]\n",
      " 39%|███▉      | 309559296/791918971 [00:16<00:24, 19817981.13it/s]\n",
      " 39%|███▉      | 311558144/791918971 [00:16<00:25, 18818642.22it/s]\n",
      " 40%|███▉      | 313589760/791918971 [00:16<00:24, 19199766.93it/s]\n",
      " 40%|███▉      | 315883520/791918971 [00:16<00:23, 19957136.89it/s]\n",
      " 40%|████      | 317915136/791918971 [00:16<00:25, 18708927.77it/s]\n",
      " 40%|████      | 320110592/791918971 [00:16<00:24, 19462341.68it/s]\n",
      " 41%|████      | 322306048/791918971 [00:17<00:23, 19652414.88it/s]\n",
      " 41%|████      | 324304896/791918971 [00:17<00:24, 18823027.38it/s]\n",
      " 41%|████      | 326565888/791918971 [00:17<00:23, 19760518.29it/s]\n",
      " 41%|████▏     | 328630272/791918971 [00:17<00:23, 19927753.45it/s]\n",
      " 42%|████▏     | 330661888/791918971 [00:17<00:24, 18707157.66it/s]\n",
      " 42%|████▏     | 332857344/791918971 [00:17<00:23, 19545437.95it/s]\n",
      " 42%|████▏     | 334954496/791918971 [00:17<00:23, 19786013.60it/s]\n",
      " 43%|████▎     | 336953344/791918971 [00:17<00:24, 18778265.62it/s]\n",
      " 43%|████▎     | 339050496/791918971 [00:17<00:23, 19315272.86it/s]\n",
      " 43%|████▎     | 341180416/791918971 [00:17<00:22, 19627334.35it/s]\n",
      " 43%|████▎     | 343179264/791918971 [00:18<00:22, 19652172.10it/s]\n",
      " 44%|████▎     | 345178112/791918971 [00:18<00:23, 18794793.67it/s]\n",
      " 44%|████▍     | 347373568/791918971 [00:18<00:22, 19633613.60it/s]\n",
      " 44%|████▍     | 349372416/791918971 [00:18<00:22, 19435205.53it/s]\n",
      " 44%|████▍     | 351338496/791918971 [00:18<00:23, 19142031.50it/s]\n",
      " 45%|████▍     | 353370112/791918971 [00:18<00:22, 19316500.89it/s]\n",
      " 45%|████▍     | 355336192/791918971 [00:18<00:22, 19144277.05it/s]\n",
      " 45%|████▌     | 357531648/791918971 [00:18<00:21, 19857825.03it/s]\n",
      " 45%|████▌     | 359530496/791918971 [00:18<00:22, 19016106.23it/s]\n",
      " 46%|████▌     | 361562112/791918971 [00:19<00:22, 19386126.92it/s]\n",
      " 46%|████▌     | 363528192/791918971 [00:19<00:22, 19256749.64it/s]\n",
      " 46%|████▌     | 365494272/791918971 [00:19<00:22, 19371714.97it/s]\n",
      " 46%|████▋     | 367460352/791918971 [00:19<00:22, 19159990.54it/s]\n",
      " 47%|████▋     | 369426432/791918971 [00:19<00:22, 19171344.56it/s]\n",
      " 47%|████▋     | 371392512/791918971 [00:19<00:21, 19277829.83it/s]\n",
      " 47%|████▋     | 373391360/791918971 [00:19<00:21, 19330052.76it/s]\n",
      " 47%|████▋     | 375357440/791918971 [00:19<00:21, 19198093.29it/s]\n",
      " 48%|████▊     | 377323520/791918971 [00:19<00:21, 19217897.23it/s]\n",
      " 48%|████▊     | 379387904/791918971 [00:19<00:21, 19600555.92it/s]\n",
      " 48%|████▊     | 381419520/791918971 [00:20<00:20, 19666154.99it/s]\n",
      " 48%|████▊     | 383418368/791918971 [00:20<00:21, 18934764.24it/s]\n",
      " 49%|████▊     | 385384448/791918971 [00:20<00:21, 19009252.98it/s]\n",
      " 49%|████▉     | 387579904/791918971 [00:20<00:20, 19801412.92it/s]\n",
      " 49%|████▉     | 389578752/791918971 [00:20<00:21, 18718065.69it/s]\n",
      " 49%|████▉     | 391643136/791918971 [00:20<00:21, 19049679.96it/s]\n",
      " 50%|████▉     | 393838592/791918971 [00:20<00:20, 19817833.72it/s]\n",
      " 50%|████▉     | 395837440/791918971 [00:20<00:20, 19693349.22it/s]\n",
      " 50%|█████     | 397836288/791918971 [00:20<00:20, 18921154.31it/s]\n",
      " 50%|█████     | 399900672/791918971 [00:21<00:20, 19379638.13it/s]\n",
      " 51%|█████     | 402096128/791918971 [00:21<00:19, 20017066.24it/s]\n",
      " 51%|█████     | 404127744/791918971 [00:21<00:20, 18573130.48it/s]\n",
      " 51%|█████▏    | 406192128/791918971 [00:21<00:20, 19144486.55it/s]\n",
      " 52%|█████▏    | 408485888/791918971 [00:21<00:18, 20210721.17it/s]\n",
      " 52%|█████▏    | 410550272/791918971 [00:21<00:20, 18629984.98it/s]\n",
      " 52%|█████▏    | 412909568/791918971 [00:21<00:19, 19863818.44it/s]\n",
      " 52%|█████▏    | 415006720/791918971 [00:21<00:18, 20171064.89it/s]\n",
      " 53%|█████▎    | 417071104/791918971 [00:21<00:19, 18894951.12it/s]\n",
      " 53%|█████▎    | 419299328/791918971 [00:22<00:19, 19598928.37it/s]\n",
      " 53%|█████▎    | 421298176/791918971 [00:22<00:18, 19665104.59it/s]\n",
      " 53%|█████▎    | 423297024/791918971 [00:22<00:19, 18667310.73it/s]\n",
      " 54%|█████▎    | 425459712/791918971 [00:22<00:18, 19486623.64it/s]\n",
      " 54%|█████▍    | 427556864/791918971 [00:22<00:18, 19607073.02it/s]\n",
      " 54%|█████▍    | 429555712/791918971 [00:22<00:19, 18770574.27it/s]\n",
      " 55%|█████▍    | 431718400/791918971 [00:22<00:18, 19392420.34it/s]\n",
      " 55%|█████▍    | 433782784/791918971 [00:22<00:18, 19464912.49it/s]\n",
      " 55%|█████▌    | 435879936/791918971 [00:22<00:18, 19387518.25it/s]\n",
      " 55%|█████▌    | 437846016/791918971 [00:22<00:18, 19109352.77it/s]\n",
      " 56%|█████▌    | 439910400/791918971 [00:23<00:18, 19530973.28it/s]\n",
      " 56%|█████▌    | 442073088/791918971 [00:23<00:17, 20062395.83it/s]\n",
      " 56%|█████▌    | 444104704/791918971 [00:23<00:18, 18809958.96it/s]\n",
      " 56%|█████▋    | 446169088/791918971 [00:23<00:17, 19312932.68it/s]\n",
      " 57%|█████▋    | 448299008/791918971 [00:23<00:17, 19800566.11it/s]\n",
      " 57%|█████▋    | 450297856/791918971 [00:23<00:17, 19786573.62it/s]\n",
      " 57%|█████▋    | 452296704/791918971 [00:23<00:18, 18783495.15it/s]\n",
      " 57%|█████▋    | 454426624/791918971 [00:23<00:17, 19420088.90it/s]\n",
      " 58%|█████▊    | 456589312/791918971 [00:23<00:16, 19901860.10it/s]\n",
      " 58%|█████▊    | 458620928/791918971 [00:24<00:17, 18817939.60it/s]\n",
      " 58%|█████▊    | 460685312/791918971 [00:24<00:17, 19267665.64it/s]\n",
      " 58%|█████▊    | 462880768/791918971 [00:24<00:16, 19888620.08it/s]\n",
      " 59%|█████▊    | 464912384/791918971 [00:24<00:17, 18830683.99it/s]\n",
      " 59%|█████▉    | 466911232/791918971 [00:24<00:17, 19076595.84it/s]\n",
      " 59%|█████▉    | 469139456/791918971 [00:24<00:16, 19846798.14it/s]\n",
      " 59%|█████▉    | 471138304/791918971 [00:24<00:16, 19242528.05it/s]\n",
      " 60%|█████▉    | 473104384/791918971 [00:24<00:16, 18839332.47it/s]\n",
      " 60%|██████    | 475332608/791918971 [00:24<00:16, 19758715.28it/s]\n",
      " 60%|██████    | 477396992/791918971 [00:25<00:15, 19753816.53it/s]\n",
      " 61%|██████    | 479395840/791918971 [00:25<00:16, 18731482.49it/s]\n",
      " 61%|██████    | 481558528/791918971 [00:25<00:15, 19486022.55it/s]\n",
      " 61%|██████    | 483786752/791918971 [00:25<00:15, 20120949.37it/s]\n",
      " 61%|██████▏   | 485818368/791918971 [00:25<00:16, 18867451.48it/s]\n",
      " 62%|██████▏   | 487882752/791918971 [00:25<00:15, 19227456.47it/s]\n",
      " 62%|██████▏   | 490176512/791918971 [00:25<00:14, 20272246.77it/s]\n",
      " 62%|██████▏   | 492240896/791918971 [00:25<00:16, 18603276.70it/s]\n",
      " 62%|██████▏   | 494436352/791918971 [00:25<00:15, 19451757.85it/s]\n",
      " 63%|██████▎   | 496599040/791918971 [00:26<00:15, 19660869.39it/s]\n",
      " 63%|██████▎   | 498597888/791918971 [00:26<00:15, 18710884.51it/s]\n",
      " 63%|██████▎   | 500826112/791918971 [00:26<00:14, 19659565.50it/s]\n",
      " 64%|██████▎   | 503021568/791918971 [00:26<00:14, 20004913.57it/s]\n",
      " 64%|██████▍   | 505053184/791918971 [00:26<00:15, 18601122.19it/s]\n",
      " 64%|██████▍   | 507478016/791918971 [00:26<00:14, 19830939.74it/s]\n",
      " 64%|██████▍   | 509509632/791918971 [00:26<00:14, 19767821.66it/s]\n",
      " 65%|██████▍   | 511508480/791918971 [00:26<00:14, 18902747.01it/s]\n",
      " 65%|██████▍   | 513736704/791918971 [00:26<00:14, 19585800.84it/s]\n",
      " 65%|██████▌   | 515735552/791918971 [00:27<00:22, 12427907.03it/s]\n",
      " 65%|██████▌   | 518160384/791918971 [00:27<00:19, 14047610.77it/s]\n",
      " 66%|██████▌   | 520192000/791918971 [00:27<00:17, 15138387.74it/s]\n",
      " 66%|██████▌   | 522977280/791918971 [00:27<00:15, 17456286.53it/s]\n",
      " 66%|██████▋   | 524943360/791918971 [00:27<00:15, 16774255.79it/s]\n",
      " 67%|██████▋   | 527728640/791918971 [00:27<00:13, 19414990.45it/s]\n",
      " 67%|██████▋   | 529825792/791918971 [00:27<00:14, 17501545.47it/s]\n",
      " 67%|██████▋   | 532545536/791918971 [00:28<00:13, 19587655.31it/s]\n",
      " 68%|██████▊   | 534642688/791918971 [00:28<00:14, 18135059.33it/s]\n",
      " 68%|██████▊   | 537296896/791918971 [00:28<00:12, 20111061.44it/s]\n",
      " 68%|██████▊   | 539426816/791918971 [00:28<00:13, 18387871.80it/s]\n",
      " 68%|██████▊   | 542048256/791918971 [00:28<00:12, 20309990.75it/s]\n",
      " 69%|██████▊   | 544210944/791918971 [00:28<00:13, 18515843.42it/s]\n",
      " 69%|██████▉   | 546799616/791918971 [00:28<00:12, 20346604.66it/s]\n",
      " 69%|██████▉   | 548962304/791918971 [00:28<00:13, 18533405.10it/s]\n",
      " 70%|██████▉   | 551616512/791918971 [00:29<00:11, 20330105.47it/s]\n",
      " 70%|██████▉   | 553746432/791918971 [00:29<00:12, 18593988.52it/s]\n",
      " 70%|███████   | 556400640/791918971 [00:29<00:11, 20414010.90it/s]\n",
      " 71%|███████   | 558530560/791918971 [00:29<00:12, 18621823.14it/s]\n",
      " 71%|███████   | 561184768/791918971 [00:29<00:11, 19871848.96it/s]\n",
      " 71%|███████   | 563249152/791918971 [00:29<00:12, 18651989.41it/s]\n",
      " 71%|███████▏  | 565936128/791918971 [00:29<00:10, 20582717.27it/s]\n",
      " 72%|███████▏  | 568066048/791918971 [00:29<00:11, 18706696.11it/s]\n",
      " 72%|███████▏  | 570687488/791918971 [00:30<00:10, 20473552.72it/s]\n",
      " 72%|███████▏  | 572817408/791918971 [00:30<00:11, 18616998.53it/s]\n",
      " 73%|███████▎  | 575438848/791918971 [00:30<00:10, 20534268.30it/s]\n",
      " 73%|███████▎  | 577601536/791918971 [00:30<00:11, 18603401.96it/s]\n",
      " 73%|███████▎  | 580190208/791918971 [00:30<00:10, 20335172.03it/s]\n",
      " 74%|███████▎  | 582320128/791918971 [00:30<00:11, 18483943.92it/s]\n",
      " 74%|███████▍  | 584941568/791918971 [00:30<00:10, 20370630.78it/s]\n",
      " 74%|███████▍  | 587071488/791918971 [00:30<00:11, 18506063.19it/s]\n",
      " 74%|███████▍  | 589627392/791918971 [00:30<00:09, 20234826.84it/s]\n",
      " 75%|███████▍  | 591757312/791918971 [00:31<00:10, 18527071.64it/s]\n",
      " 75%|███████▌  | 594280448/791918971 [00:31<00:09, 20176620.15it/s]\n",
      " 75%|███████▌  | 596410368/791918971 [00:31<00:10, 19415581.51it/s]\n",
      " 76%|███████▌  | 598441984/791918971 [00:31<00:10, 18976915.87it/s]\n",
      " 76%|███████▌  | 600735744/791918971 [00:31<00:09, 19949601.40it/s]\n",
      " 76%|███████▌  | 602800128/791918971 [00:31<00:09, 19188304.45it/s]\n",
      " 76%|███████▋  | 604766208/791918971 [00:31<00:09, 18955696.69it/s]\n",
      " 77%|███████▋  | 606994432/791918971 [00:31<00:09, 19826326.81it/s]\n",
      " 77%|███████▋  | 609058816/791918971 [00:31<00:09, 19997463.56it/s]\n",
      " 77%|███████▋  | 611090432/791918971 [00:32<00:09, 18621544.13it/s]\n",
      " 77%|███████▋  | 613482496/791918971 [00:32<00:08, 19932220.56it/s]\n",
      " 78%|███████▊  | 615514112/791918971 [00:32<00:09, 19546619.51it/s]\n",
      " 78%|███████▊  | 617512960/791918971 [00:32<00:09, 18904302.35it/s]\n",
      " 78%|███████▊  | 619741184/791918971 [00:32<00:08, 19712898.81it/s]\n",
      " 79%|███████▊  | 621838336/791918971 [00:32<00:08, 19820966.05it/s]\n",
      " 79%|███████▉  | 623837184/791918971 [00:32<00:08, 18708953.85it/s]\n",
      " 79%|███████▉  | 626130944/791918971 [00:32<00:08, 19527289.76it/s]\n",
      " 79%|███████▉  | 628195328/791918971 [00:32<00:08, 19677238.80it/s]\n",
      " 80%|███████▉  | 630194176/791918971 [00:33<00:08, 18881660.58it/s]\n",
      " 80%|███████▉  | 632356864/791918971 [00:33<00:08, 19307111.18it/s]\n",
      " 80%|████████  | 634519552/791918971 [00:33<00:07, 19799741.70it/s]\n",
      " 80%|████████  | 636518400/791918971 [00:33<00:08, 18945276.29it/s]\n",
      " 81%|████████  | 638615552/791918971 [00:33<00:07, 19164439.45it/s]\n",
      " 81%|████████  | 640811008/791918971 [00:33<00:07, 19767813.37it/s]\n",
      " 81%|████████  | 642809856/791918971 [00:33<00:07, 19124601.04it/s]\n",
      " 81%|████████▏ | 644775936/791918971 [00:33<00:07, 19273657.87it/s]\n",
      " 82%|████████▏ | 646807552/791918971 [00:33<00:07, 19439394.83it/s]\n",
      " 82%|████████▏ | 648871936/791918971 [00:34<00:07, 19730210.72it/s]\n",
      " 82%|████████▏ | 650870784/791918971 [00:34<00:07, 18734211.27it/s]\n",
      " 82%|████████▏ | 653066240/791918971 [00:34<00:07, 19352408.11it/s]\n",
      " 83%|████████▎ | 655261696/791918971 [00:34<00:06, 20037713.42it/s]\n",
      " 83%|████████▎ | 657293312/791918971 [00:34<00:07, 18898944.51it/s]\n",
      " 83%|████████▎ | 659324928/791918971 [00:34<00:06, 19162029.87it/s]\n",
      " 84%|████████▎ | 661585920/791918971 [00:34<00:06, 20086984.64it/s]\n",
      " 84%|████████▍ | 663617536/791918971 [00:34<00:06, 18777920.02it/s]\n",
      " 84%|████████▍ | 665780224/791918971 [00:34<00:06, 19562870.92it/s]\n",
      " 84%|████████▍ | 667975680/791918971 [00:35<00:06, 20224062.24it/s]\n",
      " 85%|████████▍ | 670040064/791918971 [00:35<00:06, 18548426.97it/s]\n",
      " 85%|████████▍ | 672399360/791918971 [00:35<00:06, 19919454.29it/s]\n",
      " 85%|████████▌ | 674463744/791918971 [00:35<00:05, 19760116.69it/s]\n",
      " 85%|████████▌ | 676495360/791918971 [00:35<00:06, 18700806.79it/s]\n",
      " 86%|████████▌ | 678887424/791918971 [00:35<00:05, 19866628.29it/s]\n",
      " 86%|████████▌ | 680919040/791918971 [00:35<00:05, 19256754.99it/s]\n",
      " 86%|████████▌ | 682885120/791918971 [00:35<00:05, 18682642.50it/s]\n",
      " 87%|████████▋ | 685211648/791918971 [00:35<00:05, 19769078.47it/s]\n",
      " 87%|████████▋ | 687210496/791918971 [00:36<00:05, 19770034.79it/s]\n",
      " 87%|████████▋ | 689209344/791918971 [00:36<00:05, 18663563.05it/s]\n",
      " 87%|████████▋ | 691470336/791918971 [00:36<00:05, 19606407.90it/s]\n",
      " 88%|████████▊ | 693534720/791918971 [00:36<00:04, 19846439.63it/s]\n",
      " 88%|████████▊ | 695533568/791918971 [00:36<00:05, 18587287.17it/s]\n",
      " 88%|████████▊ | 697696256/791918971 [00:36<00:04, 19409436.26it/s]\n",
      " 88%|████████▊ | 699858944/791918971 [00:36<00:04, 19980064.96it/s]\n",
      " 89%|████████▊ | 701890560/791918971 [00:36<00:04, 18708305.30it/s]\n",
      " 89%|████████▉ | 704020480/791918971 [00:36<00:04, 19324525.05it/s]\n",
      " 89%|████████▉ | 706215936/791918971 [00:37<00:04, 19953178.14it/s]\n",
      " 89%|████████▉ | 708247552/791918971 [00:37<00:04, 18728462.28it/s]\n",
      " 90%|████████▉ | 710475776/791918971 [00:37<00:04, 19708710.60it/s]\n",
      " 90%|████████▉ | 712605696/791918971 [00:37<00:03, 20097961.09it/s]\n",
      " 90%|█████████ | 714637312/791918971 [00:37<00:04, 18790758.27it/s]\n",
      " 91%|█████████ | 716767232/791918971 [00:37<00:03, 19390019.38it/s]\n",
      " 91%|█████████ | 718995456/791918971 [00:37<00:03, 20017454.80it/s]\n",
      " 91%|█████████ | 721027072/791918971 [00:37<00:03, 18826584.18it/s]\n",
      " 91%|█████████▏| 723222528/791918971 [00:37<00:03, 19595295.91it/s]\n",
      " 92%|█████████▏| 725352448/791918971 [00:37<00:03, 19858038.81it/s]\n",
      " 92%|█████████▏| 727384064/791918971 [00:38<00:03, 18329670.41it/s]\n",
      " 92%|█████████▏| 729907200/791918971 [00:38<00:03, 20113654.17it/s]\n",
      " 92%|█████████▏| 731971584/791918971 [00:38<00:03, 19523355.94it/s]\n",
      " 93%|█████████▎| 733970432/791918971 [00:38<00:03, 18810508.83it/s]\n",
      " 93%|█████████▎| 736296960/791918971 [00:38<00:02, 20027483.97it/s]\n",
      " 93%|█████████▎| 738328576/791918971 [00:38<00:02, 19293451.43it/s]\n",
      " 93%|█████████▎| 740294656/791918971 [00:38<00:02, 18829680.88it/s]\n",
      " 94%|█████████▍| 742555648/791918971 [00:38<00:02, 19870650.80it/s]\n",
      " 94%|█████████▍| 744587264/791918971 [00:38<00:02, 19743349.85it/s]\n",
      " 94%|█████████▍| 746586112/791918971 [00:39<00:02, 18678284.32it/s]\n",
      " 95%|█████████▍| 748879872/791918971 [00:39<00:02, 19863905.04it/s]\n",
      " 95%|█████████▍| 750911488/791918971 [00:39<00:02, 19810622.25it/s]\n",
      " 95%|█████████▌| 752910336/791918971 [00:39<00:02, 18507463.92it/s]\n",
      " 95%|█████████▌| 755302400/791918971 [00:39<00:01, 19929828.09it/s]\n",
      " 96%|█████████▌| 757334016/791918971 [00:39<00:01, 19673104.90it/s]\n",
      " 96%|█████████▌| 759332864/791918971 [00:39<00:01, 18605016.94it/s]\n",
      " 96%|█████████▌| 761659392/791918971 [00:39<00:01, 19779611.11it/s]\n",
      " 96%|█████████▋| 763691008/791918971 [00:39<00:01, 19912060.61it/s]\n",
      " 97%|█████████▋| 765722624/791918971 [00:40<00:01, 18688274.75it/s]\n",
      " 97%|█████████▋| 767918080/791918971 [00:40<00:01, 19560817.69it/s]\n",
      " 97%|█████████▋| 770015232/791918971 [00:40<00:01, 19885477.57it/s]\n",
      " 97%|█████████▋| 772046848/791918971 [00:40<00:01, 18721508.67it/s]\n",
      " 98%|█████████▊| 774176768/791918971 [00:40<00:00, 19405792.83it/s]\n",
      " 98%|█████████▊| 776241152/791918971 [00:40<00:00, 19693776.96it/s]\n",
      " 98%|█████████▊| 778272768/791918971 [00:40<00:00, 19504837.00it/s]\n",
      " 99%|█████████▊| 780238848/791918971 [00:40<00:00, 18955648.90it/s]\n",
      " 99%|█████████▉| 782434304/791918971 [00:40<00:00, 19613624.20it/s]\n",
      " 99%|█████████▉| 784564224/791918971 [00:41<00:00, 20020731.49it/s]\n",
      " 99%|█████████▉| 786595840/791918971 [00:41<00:00, 18845517.72it/s]\n",
      "100%|█████████▉| 788692992/791918971 [00:41<00:00, 19368912.93it/s]\n",
      "100%|█████████▉| 790822912/791918971 [00:41<00:00, 19848824.57it/s]\n",
      "100%|██████████| 791918971/791918971 [00:41<00:00, 19112499.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(map pid=178, ip=10.128.4.70)\u001b[0m Extracting data/oxford-iiit-pet/images.tar.gz to data/oxford-iiit-pet\n",
      "\u001b[2m\u001b[36m(map pid=178, ip=10.128.4.70)\u001b[0m Downloading https://thor.robots.ox.ac.uk/~vgg/data/pets/annotations.tar.gz to data/oxford-iiit-pet/annotations.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19173078 [00:00<?, ?it/s]\n",
      "  1%|          | 98304/19173078 [00:00<00:30, 621485.14it/s]\n",
      "  2%|▏         | 425984/19173078 [00:00<00:12, 1475379.11it/s]\n",
      "  9%|▉         | 1736704/19173078 [00:00<00:03, 4584621.85it/s]\n",
      " 25%|██▌       | 4882432/19173078 [00:00<00:01, 10619992.06it/s]\n",
      " 42%|████▏     | 8028160/19173078 [00:00<00:00, 13953445.98it/s]\n",
      " 58%|█████▊    | 11108352/19173078 [00:00<00:00, 17225176.62it/s]\n",
      " 67%|██████▋   | 12910592/19173078 [00:01<00:00, 16666092.07it/s]\n",
      " 83%|████████▎ | 15826944/19173078 [00:01<00:00, 17343329.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(map pid=178, ip=10.128.4.70)\u001b[0m Extracting data/oxford-iiit-pet/annotations.tar.gz to data/oxford-iiit-pet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19173078/19173078 [00:01<00:00, 14223803.94it/s]\n",
      "Shuffle Map: 100%|██████████| 1/1 [01:09<00:00, 69.16s/it]\n",
      "Shuffle Reduce: 100%|██████████| 1/1 [00:03<00:00,  3.30s/it]\n"
     ]
    }
   ],
   "source": [
    "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f6c5c42-ece5-4198-8eb3-970d2d0e0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, loss_fn, optim):\n",
    "    model.train()\n",
    "    model.to(\"cuda\")\n",
    "    for batch_idx, data in enumerate(dataloader.iter_batches()):\n",
    "        X = [x[0] for x in data]\n",
    "        X = torch.stack(X)\n",
    "        X = X.to(\"cuda\")\n",
    "        y = [torch.tensor(x[1]) for x in data]\n",
    "        y = torch.stack(y)\n",
    "        y = y.to(\"cuda\") \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        #backprop\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3567ad82-a201-47a6-a961-a2a8b029771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader.iter_batches():\n",
    "            X = [x[0] for x in data]\n",
    "            X = torch.stack(X)\n",
    "            X = X.to(\"cuda\")\n",
    "            y = [torch.tensor(x[1]) for x in data]\n",
    "            y = torch.stack(y)\n",
    "            y = y.to(\"cuda\")\n",
    "            pred = model(X)\n",
    "            test_loss = loss_fn(pred, y).item()  \n",
    "    \n",
    "    return test_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa741303-79e6-4cfe-9813-9d58dbc5e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_per_worker(config):\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    lr = config[\"lr\"]\n",
    "    epochs = config[\"epochs\"]\n",
    "    momentum = config[\"momentum\"]\n",
    "    tune_run = config[\"tune_run\"]\n",
    "    \n",
    "    \n",
    "    train_dataloader = train.get_dataset_shard(\"train\")\n",
    "    test_dataloader = train.get_dataset_shard(\"test\")\n",
    "    model = ConvNet()\n",
    "    model = train.torch.prepare_model(model).to(\"cuda\")\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr,  momentum=momentum)\n",
    "    \n",
    "    loss_results = []\n",
    "    eval_results = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        loss = train_epoch(train_dataloader, model, loss_fn, optimizer)\n",
    "        val_loss = validate_epoch(test_dataloader, model, loss_fn)\n",
    "        loss_results.append(loss)\n",
    "        eval_results.append(val_loss)\n",
    "        session.report({\"loss\":loss},)\n",
    "    \n",
    "    session.report({\"loss\":loss, \"model\": model,\n",
    "                   \"training_loss\": loss_results,\"eval_loss\": eval_results},\n",
    "                   checkpoint=Checkpoint.from_dict(dict(epoch=epoch, model=model.state_dict())))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d99d05b2-7ea7-4cbb-985b-375f60881955",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config = {\n",
    "    \"batch_size\": 4,\n",
    "    \"epochs\": 100,\n",
    "    \"momentum\": 0.9,\n",
    "    \"lr\": 0.001,\n",
    "    \"tune_run\": False    \n",
    "        \n",
    "    },\n",
    "    scaling_config = ScalingConfig(\n",
    "    num_workers = 1,\n",
    "    use_gpu = True,\n",
    "    trainer_resources = {\"CPU\":1}),\n",
    "    run_config = RunConfig(\n",
    "        name = \"test_run\",\n",
    "        local_dir = \"./\",\n",
    "        sync_config = tune.SyncConfig(syncer=None)),\n",
    "    datasets = {\"train\": train_dataset,\n",
    "               \"test\":valid_dataset},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a6554d0-6865-4ff7-8c10-b41c6ba63715",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Current time: 2022-10-21 15:25:56 (running for 00:00:03.33)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Memory usage on this node: 5.8/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Resources requested: 1.0/2 CPUs, 1.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Number of trials: 1/1 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | Trial name               | status   | loc               |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m |--------------------------+----------+-------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | TorchTrainer_a693c_00000 | RUNNING  | 10.131.2.239:2188 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2222)\u001b[0m 2022-10-21 15:25:58,917\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2222)\u001b[0m 2022-10-21 15:25:59,144\tINFO train_loop_utils.py:300 -- Moving model to device: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Current time: 2022-10-21 15:26:01 (running for 00:00:08.33)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Memory usage on this node: 7.6/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Resources requested: 1.0/2 CPUs, 1.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Number of trials: 1/1 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | Trial name               | status   | loc               |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m |--------------------------+----------+-------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | TorchTrainer_a693c_00000 | RUNNING  | 10.131.2.239:2188 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result for TorchTrainer_a693c_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _time_this_iter_s: 4.295920372009277\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _timestamp: 1666365963\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   date: 2022-10-21_15-26-03\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   experiment_id: 36b5e89f84d543768f124755b470742d\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   loss: 3.622699499130249\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   pid: 2188\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_since_restore: 6.872178316116333\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_this_iter_s: 6.872178316116333\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_total_s: 6.872178316116333\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timestamp: 1666365963\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   trial_id: a693c_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   warmup_time: 0.0033807754516601562\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Current time: 2022-10-21 15:26:06 (running for 00:00:13.58)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Resources requested: 1.0/2 CPUs, 1.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Number of trials: 1/1 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | Trial name               | status   | loc               |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m |--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | TorchTrainer_a693c_00000 | RUNNING  | 10.131.2.239:2188 |      6 |          10.2549 | 3.61453 |   1666365966 |            0.642437 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result for TorchTrainer_a693c_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _time_this_iter_s: 0.5584971904754639\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _timestamp: 1666365968\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _training_iteration: 9\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   date: 2022-10-21_15-26-08\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   experiment_id: 36b5e89f84d543768f124755b470742d\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   iterations_since_restore: 9\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   loss: 3.609231948852539\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   pid: 2188\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_since_restore: 12.096699953079224\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_this_iter_s: 0.5579242706298828\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_total_s: 12.096699953079224\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timestamp: 1666365968\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   training_iteration: 9\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   trial_id: a693c_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   warmup_time: 0.0033807754516601562\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Current time: 2022-10-21 15:26:12 (running for 00:00:19.15)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Resources requested: 1.0/2 CPUs, 1.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Number of trials: 1/1 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | Trial name               | status   | loc               |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m |--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | TorchTrainer_a693c_00000 | RUNNING  | 10.131.2.239:2188 |     15 |           15.826 | 3.60038 |   1666365972 |            0.584987 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result for TorchTrainer_a693c_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _time_this_iter_s: 0.5543203353881836\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _timestamp: 1666365973\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _training_iteration: 17\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   date: 2022-10-21_15-26-13\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   experiment_id: 36b5e89f84d543768f124755b470742d\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   iterations_since_restore: 17\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   loss: 3.597801923751831\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   pid: 2188\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_since_restore: 17.102048873901367\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_this_iter_s: 0.5543394088745117\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_total_s: 17.102048873901367\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timestamp: 1666365973\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   training_iteration: 17\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   trial_id: a693c_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   warmup_time: 0.0033807754516601562\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Current time: 2022-10-21 15:26:17 (running for 00:00:24.23)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Resources requested: 1.0/2 CPUs, 1.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Number of trials: 1/1 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | Trial name               | status   | loc               |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m |--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | TorchTrainer_a693c_00000 | RUNNING  | 10.131.2.239:2188 |     23 |          20.9029 | 3.58926 |   1666365977 |            0.642233 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result for TorchTrainer_a693c_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _time_this_iter_s: 0.620814323425293\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _timestamp: 1666365978\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _training_iteration: 25\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   date: 2022-10-21_15-26-18\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   experiment_id: 36b5e89f84d543768f124755b470742d\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   iterations_since_restore: 25\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   loss: 3.586165428161621\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   pid: 2188\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_since_restore: 22.19070339202881\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_this_iter_s: 0.6208465099334717\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_total_s: 22.19070339202881\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timestamp: 1666365978\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   training_iteration: 25\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   trial_id: a693c_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   warmup_time: 0.0033807754516601562\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Current time: 2022-10-21 15:26:23 (running for 00:00:29.77)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Resources requested: 1.0/2 CPUs, 1.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Number of trials: 1/1 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | Trial name               | status   | loc               |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m |--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | TorchTrainer_a693c_00000 | RUNNING  | 10.131.2.239:2188 |     32 |          26.4372 | 3.57446 |   1666365982 |            0.616029 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result for TorchTrainer_a693c_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _time_this_iter_s: 0.6306781768798828\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _timestamp: 1666365984\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _training_iteration: 34\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   date: 2022-10-21_15-26-24\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   experiment_id: 36b5e89f84d543768f124755b470742d\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   iterations_since_restore: 34\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   loss: 3.57076358795166\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   pid: 2188\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_since_restore: 27.746645212173462\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_this_iter_s: 0.6356332302093506\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_total_s: 27.746645212173462\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timestamp: 1666365984\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   training_iteration: 34\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   trial_id: a693c_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   warmup_time: 0.0033807754516601562\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Current time: 2022-10-21 15:26:28 (running for 00:00:34.82)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Resources requested: 1.0/2 CPUs, 1.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Number of trials: 1/1 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | Trial name               | status   | loc               |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m |--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | TorchTrainer_a693c_00000 | RUNNING  | 10.131.2.239:2188 |     40 |          31.4861 | 3.55823 |   1666365988 |            0.583603 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result for TorchTrainer_a693c_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _time_this_iter_s: 0.6185388565063477\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _timestamp: 1666365989\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _training_iteration: 42\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   date: 2022-10-21_15-26-29\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   experiment_id: 36b5e89f84d543768f124755b470742d\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   iterations_since_restore: 42\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   loss: 3.553483009338379\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   pid: 2188\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_since_restore: 32.77288222312927\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_this_iter_s: 0.618255615234375\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_total_s: 32.77288222312927\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timestamp: 1666365989\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   training_iteration: 42\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   trial_id: a693c_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   warmup_time: 0.0033807754516601562\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Current time: 2022-10-21 15:26:33 (running for 00:00:40.38)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Resources requested: 1.0/2 CPUs, 1.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Number of trials: 1/1 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | Trial name               | status   | loc               |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m |--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | TorchTrainer_a693c_00000 | RUNNING  | 10.131.2.239:2188 |     49 |            37.05 | 3.53627 |   1666365993 |            0.576061 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result for TorchTrainer_a693c_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _time_this_iter_s: 0.5864825248718262\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _timestamp: 1666365994\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _training_iteration: 51\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   date: 2022-10-21_15-26-34\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   experiment_id: 36b5e89f84d543768f124755b470742d\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   iterations_since_restore: 51\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   loss: 3.530764579772949\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   pid: 2188\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_since_restore: 38.3214647769928\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_this_iter_s: 0.5752019882202148\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_total_s: 38.3214647769928\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timestamp: 1666365994\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   training_iteration: 51\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   trial_id: a693c_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   warmup_time: 0.0033807754516601562\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Current time: 2022-10-21 15:26:38 (running for 00:00:45.45)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Resources requested: 1.0/2 CPUs, 1.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Number of trials: 1/1 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | Trial name               | status   | loc               |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m |--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | TorchTrainer_a693c_00000 | RUNNING  | 10.131.2.239:2188 |     57 |          42.1232 | 3.51257 |   1666365998 |            0.567383 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result for TorchTrainer_a693c_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _time_this_iter_s: 0.7269918918609619\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _timestamp: 1666365999\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _training_iteration: 59\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   date: 2022-10-21_15-26-39\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   experiment_id: 36b5e89f84d543768f124755b470742d\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   iterations_since_restore: 59\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   loss: 3.506166458129883\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   pid: 2188\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_since_restore: 43.409539222717285\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_this_iter_s: 0.727400541305542\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_total_s: 43.409539222717285\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timestamp: 1666365999\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   training_iteration: 59\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   trial_id: a693c_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   warmup_time: 0.0033807754516601562\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Current time: 2022-10-21 15:26:43 (running for 00:00:50.47)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Resources requested: 1.0/2 CPUs, 1.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Number of trials: 1/1 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | Trial name               | status   | loc               |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m |--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | TorchTrainer_a693c_00000 | RUNNING  | 10.131.2.239:2188 |     65 |           47.142 | 3.48579 |   1666366003 |            0.638687 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result for TorchTrainer_a693c_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _time_this_iter_s: 0.7004294395446777\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _timestamp: 1666366005\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _training_iteration: 68\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   date: 2022-10-21_15-26-45\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   experiment_id: 36b5e89f84d543768f124755b470742d\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   iterations_since_restore: 68\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   loss: 3.4745051860809326\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   pid: 2188\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_since_restore: 49.10568928718567\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_this_iter_s: 0.7009577751159668\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_total_s: 49.10568928718567\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timestamp: 1666366005\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   training_iteration: 68\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   trial_id: a693c_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   warmup_time: 0.0033807754516601562\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Current time: 2022-10-21 15:26:48 (running for 00:00:55.57)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Resources requested: 1.0/2 CPUs, 1.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Number of trials: 1/1 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | Trial name               | status   | loc               |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m |--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | TorchTrainer_a693c_00000 | RUNNING  | 10.131.2.239:2188 |     73 |          52.2398 | 3.45355 |   1666366008 |            0.568632 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result for TorchTrainer_a693c_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _time_this_iter_s: 0.7022645473480225\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _timestamp: 1666366010\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _training_iteration: 76\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   date: 2022-10-21_15-26-50\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   experiment_id: 36b5e89f84d543768f124755b470742d\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   iterations_since_restore: 76\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   loss: 3.438722848892212\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   pid: 2188\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_since_restore: 54.192779779434204\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_this_iter_s: 0.7021229267120361\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_total_s: 54.192779779434204\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timestamp: 1666366010\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   training_iteration: 76\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   trial_id: a693c_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   warmup_time: 0.0033807754516601562\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Current time: 2022-10-21 15:26:54 (running for 00:01:01.11)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Resources requested: 1.0/2 CPUs, 1.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Number of trials: 1/1 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | Trial name               | status   | loc               |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m |--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | TorchTrainer_a693c_00000 | RUNNING  | 10.131.2.239:2188 |     82 |          57.7785 | 3.40307 |   1666366014 |            0.552132 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result for TorchTrainer_a693c_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _time_this_iter_s: 0.7375302314758301\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _timestamp: 1666366016\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _training_iteration: 85\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   date: 2022-10-21_15-26-56\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   experiment_id: 36b5e89f84d543768f124755b470742d\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   iterations_since_restore: 85\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   loss: 3.381887674331665\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   pid: 2188\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_since_restore: 59.8259060382843\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_this_iter_s: 0.737551212310791\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_total_s: 59.8259060382843\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timestamp: 1666366016\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   training_iteration: 85\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   trial_id: a693c_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   warmup_time: 0.0033807754516601562\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Current time: 2022-10-21 15:26:59 (running for 00:01:06.23)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Resources requested: 1.0/2 CPUs, 1.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Number of trials: 1/1 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+--------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | Trial name               | status   | loc               |   iter |   total time (s) |   loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m |--------------------------+----------+-------------------+--------+------------------+--------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | TorchTrainer_a693c_00000 | RUNNING  | 10.131.2.239:2188 |     90 |          62.9005 | 3.3418 |   1666366019 |            0.572588 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+--------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result for TorchTrainer_a693c_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _time_this_iter_s: 0.6670610904693604\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _timestamp: 1666366022\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _training_iteration: 94\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   date: 2022-10-21_15-27-02\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   experiment_id: 36b5e89f84d543768f124755b470742d\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   iterations_since_restore: 94\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   loss: 3.3050127029418945\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   pid: 2188\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_since_restore: 65.46780467033386\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_this_iter_s: 0.6665008068084717\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_total_s: 65.46780467033386\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timestamp: 1666366022\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   training_iteration: 94\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   trial_id: a693c_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   warmup_time: 0.0033807754516601562\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Current time: 2022-10-21 15:27:04 (running for 00:01:11.29)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Resources requested: 1.0/2 CPUs, 1.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Number of trials: 1/1 (1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | Trial name               | status   | loc               |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m |--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | TorchTrainer_a693c_00000 | RUNNING  | 10.131.2.239:2188 |     98 |          67.9655 | 3.26445 |   1666366024 |            0.679037 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+----------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result for TorchTrainer_a693c_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _time_this_iter_s: 0.005915403366088867\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _timestamp: 1666366025\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   _training_iteration: 101\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   date: 2022-10-21_15-27-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   eval_loss: [3.5967767238616943, 3.5966975688934326, 3.5963666439056396, 3.5958497524261475,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.5951757431030273, 3.594576835632324, 3.5940675735473633, 3.5935842990875244, 3.593189001083374,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.5928375720977783, 3.5924978256225586, 3.5921192169189453, 3.591736078262329, 3.591419219970703,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.5911471843719482, 3.590918779373169, 3.5907185077667236, 3.590486764907837, 3.5902185440063477,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.5899360179901123, 3.5895955562591553, 3.5892550945281982, 3.5889089107513428,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.588513135910034, 3.5881192684173584, 3.587742805480957, 3.587360382080078, 3.586941957473755,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.586534261703491, 3.586091995239258, 3.5856406688690186, 3.585167169570923, 3.5847034454345703,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.584217071533203, 3.5837154388427734, 3.5831563472747803, 3.5825653076171875, 3.5819921493530273,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.581399917602539, 3.580751657485962, 3.580033302307129, 3.579205274581909, 3.578319549560547,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.5775279998779297, 3.576798439025879, 3.5760443210601807, 3.575256586074829, 3.574457883834839,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.573589324951172, 3.572664499282837, 3.571690559387207, 3.5706946849823, 3.5696170330047607,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.568514108657837, 3.567420244216919, 3.566305160522461, 3.5651960372924805, 3.5640690326690674,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.5628535747528076, 3.5616366863250732, 3.5603692531585693, 3.5590991973876953,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.5576164722442627, 3.556030511856079, 3.554497480392456, 3.5531013011932373, 3.5518109798431396,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.55043625831604, 3.5489566326141357, 3.547480344772339, 3.5459232330322266, 3.5442206859588623,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.542429208755493, 3.5403878688812256, 3.5383434295654297, 3.5360267162323, 3.5333244800567627,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.530268907546997, 3.5268332958221436, 3.523244857788086, 3.5196714401245117, 3.515925168991089,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.51220965385437, 3.5086848735809326, 3.505033493041992, 3.5012454986572266, 3.497293472290039,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.493218421936035, 3.4892971515655518, 3.4855425357818604, 3.4814398288726807, 3.4775943756103516,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.4737813472747803, 3.469693899154663, 3.465189218521118, 3.4607927799224854, 3.4561574459075928,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.451874017715454, 3.447848320007324, 3.4435012340545654]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   experiment_id: 36b5e89f84d543768f124755b470742d\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   experiment_tag: '0'\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   iterations_since_restore: 101\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   loss: 3.2436771392822266\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   model: \"Sequential(\\n  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\\n  (1):\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     \\ MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\\n \\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     \\ (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\\n  (3): MaxPool2d(kernel_size=2,\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     \\ stride=2, padding=0, dilation=1, ceil_mode=False)\\n  (4): Flatten(start_dim=1,\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     \\ end_dim=-1)\\n  (5): Linear(in_features=6272, out_features=128, bias=True)\\n  (6):\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     \\ ReLU()\\n  (7): Linear(in_features=128, out_features=64, bias=True)\\n  (8): ReLU()\\n\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     \\  (9): Linear(in_features=64, out_features=37, bias=True)\\n)\"\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   pid: 2188\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_since_restore: 69.37709951400757\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_this_iter_s: 0.09931063652038574\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   time_total_s: 69.37709951400757\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timestamp: 1666366025\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   training_iteration: 101\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   training_loss: [3.622699499130249, 3.621736526489258, 3.6202476024627686, 3.6184284687042236,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.616499662399292, 3.6145331859588623, 3.6126346588134766, 3.6108663082122803, 3.609231948852539,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.607696294784546, 3.606182098388672, 3.6046817302703857, 3.6031806468963623, 3.601752281188965,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.6003830432891846, 3.5990688800811768, 3.597801923751831, 3.5965158939361572, 3.5951597690582275,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.593743085861206, 3.5922815799713135, 3.59076189994812, 3.58925724029541, 3.5877182483673096,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.586165428161621, 3.584599494934082, 3.5829880237579346, 3.581345796585083, 3.579702138900757,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.5780115127563477, 3.5762596130371094, 3.5744645595550537, 3.572641611099243, 3.57076358795166,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.5688552856445312, 3.566887855529785, 3.5648763179779053, 3.5627505779266357, 3.560516357421875,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.5582263469696045, 3.555875778198242, 3.553483009338379, 3.5510919094085693, 3.548720598220825,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.5463688373565674, 3.5439815521240234, 3.5415070056915283, 3.5389280319213867,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.5362651348114014, 3.533566474914551, 3.530764579772949, 3.52789568901062, 3.5249149799346924,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.5218493938446045, 3.5187766551971436, 3.515658140182495, 3.512566566467285, 3.509415864944458,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.506166458129883, 3.502880811691284, 3.499603033065796, 3.496276617050171, 3.4928271770477295,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.489382028579712, 3.4857940673828125, 3.4821338653564453, 3.478327989578247, 3.4745051860809326,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.4705238342285156, 3.466420888900757, 3.4622621536254883, 3.458035469055176, 3.453549385070801,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.4487736225128174, 3.443873643875122, 3.438722848892212, 3.4336745738983154, 3.4281184673309326,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.42240834236145, 3.416239023208618, 3.4097766876220703, 3.403066635131836, 3.3961055278778076,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.389153480529785, 3.381887674331665, 3.374427556991577, 3.3667376041412354, 3.358628988265991,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.3502895832061768, 3.3417985439300537, 3.332789182662964, 3.323974370956421, 3.3146188259124756,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.3050127029418945, 3.2951276302337646, 3.2852118015289307, 3.2748405933380127,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m     3.2644450664520264, 3.254030227661133, 3.2436771392822266]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   trial_id: a693c_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   warmup_time: 0.0033807754516601562\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Current time: 2022-10-21 15:27:07 (running for 00:01:13.90)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Memory usage on this node: 8.1/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Resources requested: 0/2 CPUs, 0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m Number of trials: 1/1 (1 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+------------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | Trial name               | status     | loc               |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m |--------------------------+------------+-------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m | TorchTrainer_a693c_00000 | TERMINATED | 10.131.2.239:2188 |    101 |          69.3771 | 3.24368 |   1666366025 |           0.0059154 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m +--------------------------+------------+-------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=2131)\u001b[0m 2022-10-21 15:27:07,236\tINFO tune.py:758 -- Total run time: 74.03 seconds (73.64 seconds for the tuning loop).\n",
      "2022-10-21 15:27:07,932\tERROR checkpoint_manager.py:133 -- The requested checkpoint is not available on this node, most likely because you are using Ray client or disabled checkpoint synchronization. To avoid this, enable checkpoint synchronization to cloud storage by specifying a `SyncConfig`. The checkpoint may be available on a different node - please check this location on worker nodes: /home/ray/test_run/TorchTrainer_a693c_00000_0_2022-10-21_15-25-53/checkpoint_000000\n"
     ]
    }
   ],
   "source": [
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "189ba8e3-b572-492b-a8fd-89a6c4fac0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result.metrics[\"training_loss\"])\n",
    "plt.plot(result.metrics[\"eval_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fb38b1d-561f-419a-b27f-207ae9971ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = result.metrics['model']\n",
    "model_scripted = torch.jit.script(model)\n",
    "model_scripted.save(\"models/trained_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95bcfcbd-4810-4960-b459-35244606ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "331c4ae1-d3b3-4652-8aa6-5981be8c07d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a search space.\n",
    "search_space = {\"train_loop_config\": \n",
    "    {\"lr\": tune.grid_search([0.001, 0.1]),\n",
    "    \"momentum\": tune.grid_search([0.1, 0.9]),\n",
    "    \"batch_size\": tune.grid_search([4]), \n",
    "    \"epochs\": tune.grid_search([300]),\n",
    "    \"tune_run\": tune.grid_search([True])}\n",
    "}\n",
    "\n",
    "metric = \"loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfa12c57-a60a-422e-b597-635eb082622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Tuner(trainer,\n",
    "              param_space=search_space,\n",
    "              tune_config=TuneConfig(num_samples=1, metric=metric, mode=\"min\"),\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ee5ab36-d3f3-434b-9b94-20e3e043b975",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:37:02 (running for 00:00:02.77)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 5.8/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 1.0/2 CPUs, 1.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (3 PENDING, 1 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-----------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc             |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-----------------+------------------------+------------------------+------------------------+------------------------+------------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213 |                      4 |                    300 |                  0.001 |                    0.1 | True                   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | PENDING  |                 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | PENDING  |                 |                      4 |                    300 |                  0.001 |                    0.9 | True                   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | PENDING  |                 |                      4 |                    300 |                  0.1   |                    0.9 | True                   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-----------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=244, ip=10.128.4.70)\u001b[0m 2022-10-21 16:37:04,879\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=244, ip=10.128.4.70)\u001b[0m 2022-10-21 16:37:05,067\tINFO train_loop_utils.py:300 -- Moving model to device: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:37:07 (running for 00:00:07.78)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 6.1/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 2.0/2 CPUs, 2.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (2 PENDING, 2 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | PENDING  |                   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | PENDING  |                   |                      4 |                    300 |                  0.1   |                    0.9 | True                   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=3336)\u001b[0m 2022-10-21 16:37:07,638\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=3336)\u001b[0m 2022-10-21 16:37:07,829\tINFO train_loop_utils.py:300 -- Moving model to device: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 3.7898480892181396\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370228\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-08\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5953614711761475\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 6.318845272064209\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 6.318845272064209\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 6.318845272064209\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370228\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 4.122133731842041\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370231\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-11\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.625131607055664\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 6.918603181838989\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 6.918603181838989\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 6.918603181838989\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370231\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:37:12 (running for 00:00:12.86)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 2.0/2 CPUs, 2.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00000 with loss=3.5944583415985107 and parameters={'train_loop_config': {'lr': 0.001, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (2 PENDING, 2 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |      6 |          9.5491  | 3.59446 |   1666370232 |            0.670162 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |      2 |          7.59677 | 3.61579 |   1666370232 |            0.678646 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | PENDING  |                   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | PENDING  |                   |                      4 |                    300 |                  0.1   |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6141660213470459\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370234\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 9\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-14\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 9\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5939557552337646\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 11.477945804595947\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6139585971832275\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 11.477945804595947\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370234\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 9\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.8090019226074219\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370237\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-17\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.570711851119995\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 11.982700824737549\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.8090794086456299\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 11.982700824737549\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370237\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:37:17 (running for 00:00:17.98)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 2.0/2 CPUs, 2.0/2 GPUs, 0.0/8.4 GiB heap, 0.0/3.47 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=3.5587093830108643 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (2 PENDING, 2 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |     14 |          14.7147 | 3.5931  |   1666370237 |            0.615628 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |      9 |          12.7154 | 3.55871 |   1666370237 |            0.732839 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | PENDING  |                   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | PENDING  |                   |                      4 |                    300 |                  0.1   |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6704082489013672\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 17\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-19\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 17\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.592597007751465\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 16.69197678565979\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6722288131713867\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 16.69197678565979\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 17\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7905359268188477\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370242\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 15\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-22\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 15\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.323641061782837\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 17.202833652496338\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7902355194091797\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 17.202833652496338\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370242\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 15\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:37:22 (running for 00:00:23.18)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=3.3771800994873047 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |     22 |          19.8889 | 3.59173 |   1666370242 |            0.60524  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |     16 |          17.9175 | 3.37718 |   1666370242 |            0.714669 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6000492572784424\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370244\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 25\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-24\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 25\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5912768840789795\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 21.814800024032593\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6000843048095703\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 21.814800024032593\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370244\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 25\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=234, ip=10.128.2.74)\u001b[0m 2022-10-21 16:37:25,600\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=234, ip=10.129.4.218)\u001b[0m 2022-10-21 16:37:25,750\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=234, ip=10.128.2.74)\u001b[0m 2022-10-21 16:37:25,773\tINFO train_loop_utils.py:300 -- Moving model to device: cuda:0\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=234, ip=10.129.4.218)\u001b[0m 2022-10-21 16:37:25,933\tINFO train_loop_utils.py:300 -- Moving model to device: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6668877601623535\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370247\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 22\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-27\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 22\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.0292367935180664\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 22.316624641418457\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6666357517242432\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 22.316624641418457\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370247\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 22\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:37:28 (running for 00:00:28.45)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=2.9036357402801514 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |     30 |          25.0968 | 3.59055 |   1666370247 |            0.650939 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |     23 |          23.1834 | 2.90364 |   1666370248 |            0.866717 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |        |                  |         |              |                     |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.8275341987609863\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370249\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 33\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-29\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 33\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.590118169784546\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 27.350919246673584\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.8270959854125977\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 27.350919246673584\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370249\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 33\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 4.2986533641815186\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370250\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-30\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.631248712539673\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 6.7945356369018555\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 6.7945356369018555\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 6.7945356369018555\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370250\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 4.264438152313232\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370250\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-30\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.633845329284668\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 6.769340515136719\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 6.769340515136719\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 6.769340515136719\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370250\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6753287315368652\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370252\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 29\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-32\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 29\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 2.4915010929107666\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 27.668728828430176\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6758832931518555\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 27.668728828430176\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370252\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 29\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:37:33 (running for 00:00:33.58)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=2.4915010929107666 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |    loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |     38 |         30.586   | 3.58943 |   1666370253 |            0.608885 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |     29 |         27.6687  | 2.4915  |   1666370252 |            0.675329 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |      6 |         10.0658  | 3.62562 |   1666370253 |            0.675238 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |      6 |          9.66597 | 3.15922 |   1666370253 |            0.608549 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6871910095214844\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370255\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 41\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-35\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 41\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.589040517807007\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 32.62143015861511\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6871621608734131\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 32.62143015861511\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370255\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 41\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6017978191375732\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370255\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 9\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-35\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 9\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.623244524002075\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 12.027815341949463\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6013493537902832\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 12.027815341949463\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370255\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 9\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.587287187576294\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370255\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 10\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-35\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 10\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 1.982420563697815\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 11.951799392700195\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5875177383422852\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 11.951799392700195\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370255\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 10\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7449836730957031\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370258\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 36\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-38\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 36\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 1.8853754997253418\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 32.997560024261475\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.74468994140625\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 32.997560024261475\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370258\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 36\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:37:38 (running for 00:00:38.77)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00003 with loss=0.6331357359886169 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.9, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+----------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |     loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+----------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |     46 |          35.8028 | 3.58844  |   1666370258 |            0.65112  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |     36 |          32.9976 | 1.88538  |   1666370258 |            0.744984 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |     14 |          15.2571 | 3.61978  |   1666370258 |            0.605396 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |     15 |          14.7978 | 0.633136 |   1666370258 |            0.627606 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+----------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6112649440765381\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370260\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 49\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-40\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 49\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5880889892578125\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 37.77621388435364\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6110727787017822\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 37.77621388435364\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370260\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 49\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5977799892425537\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370260\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 19\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-40\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 19\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.7005383968353271\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 17.09428334236145\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5976943969726562\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 17.09428334236145\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370260\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 19\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7294168472290039\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370260\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 17\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-40\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 17\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.6177194118499756\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 17.34357738494873\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7296338081359863\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 17.34357738494873\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370260\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 17\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7376258373260498\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370263\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 1.0923131704330444\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 38.25036072731018\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.737816333770752\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 38.25036072731018\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370263\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:37:43 (running for 00:00:43.79)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.4/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=1.0923131704330444 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+-----------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |      loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+-----------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |     54 |          41.0134 |   3.58749 |   1666370263 |            0.665354 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |     43 |          38.2504 |   1.09231 |   1666370263 |            0.737626 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |     21 |          20.0232 |   3.61551 |   1666370263 |            0.662729 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |     24 |          19.9281 | nan       |   1666370263 |            0.528248 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+-----------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7000682353973389\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370265\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 57\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-45\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 57\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.587125062942505\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 42.99644374847412\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6994318962097168\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 42.99644374847412\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370265\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 57\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.615302562713623\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370265\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 28\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-45\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 28\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 22.23015546798706\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6152586936950684\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 22.23015546798706\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370265\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 28\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6122565269470215\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370265\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 25\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-45\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 25\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.613576650619507\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 22.59705352783203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6236433982849121\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 22.59705352783203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370265\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 25\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7433295249938965\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370268\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 50\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-48\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 50\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.5802851319313049\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 43.514002084732056\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7432084083557129\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 43.514002084732056\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370268\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 50\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:37:48 (running for 00:00:49.03)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.4/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=0.5802851319313049 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |       loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |     62 |          46.253  |   3.5865   |   1666370268 |            0.625154 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |     50 |          43.514  |   0.580285 |   1666370268 |            0.74333  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |     29 |          25.2441 |   3.61158  |   1666370268 |            0.618833 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |     33 |          25.0467 | nan        |   1666370268 |            0.552752 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6575362682342529\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370270\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 65\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-50\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 65\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.586115598678589\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 48.20698571205139\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6576924324035645\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 48.20698571205139\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370270\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 65\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6452264785766602\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370270\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 37\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-50\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 37\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 27.328649520874023\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6454222202301025\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 27.328649520874023\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370270\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 37\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6455719470977783\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370271\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 33\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-51\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 33\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.60949444770813\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 27.935293674468994\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6454267501831055\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 27.935293674468994\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370271\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 33\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7237510681152344\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370273\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 57\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-53\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 57\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.2715679407119751\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 48.72567009925842\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7236213684082031\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 48.72567009925842\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370273\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 57\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:37:53 (running for 00:00:54.08)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=0.2715679407119751 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |       loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |     69 |          50.793  |   3.5856   |   1666370273 |            0.6506   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |     57 |          48.7257 |   0.271568 |   1666370273 |            0.723751 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |     37 |          30.565  |   3.6073   |   1666370273 |            0.665896 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |     42 |          30.1392 | nan        |   1666370273 |            0.517313 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.564629316329956\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370275\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 32.40601968765259\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5644524097442627\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 32.40601968765259\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370275\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6599485874176025\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370275\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 73\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 73\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.585078477859497\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 53.41910743713379\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6599464416503906\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 53.41910743713379\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370275\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 73\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6706509590148926\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370276\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 41\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-56\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 41\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.6049492359161377\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 33.17383646965027\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6708924770355225\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 33.17383646965027\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370276\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 41\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:37:59 (running for 00:00:59.37)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.4/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=0.14232207834720612 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |       loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |     77 |          56.0335 |   3.58457  |   1666370278 |            0.65474  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |     63 |          53.3815 |   0.142322 |   1666370278 |            0.746428 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |     45 |          35.8558 |   3.6025   |   1666370279 |            0.66813  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |     51 |          35.2345 | nan        |   1666370278 |            0.573038 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7405250072479248\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370279\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 64\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-37-59\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 64\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.27065834403038025\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 54.113622188568115\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7321183681488037\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 54.113622188568115\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370279\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 64\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5598034858703613\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370280\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-00\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 37.4789252281189\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.559697151184082\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 37.4789252281189\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370280\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7359790802001953\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 81\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-01\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 81\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.584096908569336\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 58.702136516571045\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7356588840484619\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 58.702136516571045\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 81\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6111423969268799\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 49\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-01\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 49\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.599773645401001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 38.403728008270264\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.610802173614502\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 38.403728008270264\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 49\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:38:04 (running for 00:01:04.55)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=0.0732932910323143 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+-------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |        loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+-------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |     85 |          61.3267 |   3.58363   |   1666370283 |            0.733859 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |     70 |          58.7856 |   0.0732933 |   1666370283 |            0.80167  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |     52 |          40.4566 |   3.59752   |   1666370283 |            0.733513 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |     61 |          40.8836 | nan         |   1666370284 |            0.519576 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+-------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7017059326171875\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370284\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 71\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-04\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 71\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.05147375538945198\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 59.487287759780884\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7017033100128174\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 59.487287759780884\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370284\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 71\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5263044834136963\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370285\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 64\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 64\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 42.529836654663086\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5260133743286133\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 42.529836654663086\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370285\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 64\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7288298606872559\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370286\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 89\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-06\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 89\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.583139657974243\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 63.96475172042847\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7290854454040527\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 63.96475172042847\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370286\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 89\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.607513427734375\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370286\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 57\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-06\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 57\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5931613445281982\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 43.679848432540894\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6077663898468018\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 43.679848432540894\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370286\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 57\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:38:09 (running for 00:01:09.66)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=0.07483161240816116 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+-------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |        loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+-------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |     93 |          66.5249 |   3.58265   |   1666370289 |            0.678438 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |     77 |          64.0439 |   0.0748316 |   1666370289 |            0.79795  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |     60 |          45.772  |   3.59014   |   1666370289 |            0.796756 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |     70 |          46.0004 | nan         |   1666370289 |            0.580567 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+-------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6965687274932861\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370289\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 78\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-09\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 78\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.03453889861702919\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 64.740713596344\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6967852115631104\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 64.740713596344\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370289\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 78\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5894911289215088\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370291\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 73\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-11\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 73\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 47.70524454116821\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5895109176635742\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 47.70524454116821\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370291\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 73\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6725568771362305\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370291\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 97\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-11\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 97\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.582188606262207\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 69.17509603500366\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.672666072845459\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 69.17509603500366\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370291\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 97\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6792850494384766\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370292\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 65\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-12\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 65\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5843284130096436\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 49.04237699508667\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6789875030517578\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 49.04237699508667\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370292\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 65\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:38:14 (running for 00:01:14.75)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=0.00340349436737597 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+--------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |         loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+--------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    101 |          71.7662 |   3.5817     |   1666370294 |            0.663762 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |     84 |          69.2087 |   0.00340349 |   1666370294 |            0.704511 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |     68 |          50.9809 |   3.58017    |   1666370294 |            0.66596  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |     79 |          51.0877 | nan          |   1666370294 |            0.566072 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+--------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7752118110656738\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370295\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 85\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-15\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 85\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.002408049302175641\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 69.98355078697205\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.774893045425415\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 69.98355078697205\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370295\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 85\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5857949256896973\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370296\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 82\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-16\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 82\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 52.81108593940735\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5854551792144775\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 52.81108593940735\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370296\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 82\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.633648157119751\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370296\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 105\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-16\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 105\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.581210136413574\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 74.37840437889099\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6340477466583252\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 74.37840437889099\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370296\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 105\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6955006122589111\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370297\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 73\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-17\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 73\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5717313289642334\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 54.26649069786072\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6949572563171387\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 54.26649069786072\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370297\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 73\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:38:19 (running for 00:01:19.81)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=0.0009965540375560522 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    109 |          76.9579 |   3.58073     |   1666370299 |            0.685065 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |     91 |          74.5435 |   0.000996554 |   1666370299 |            0.843059 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |     76 |          56.2368 |   3.56563     |   1666370299 |            0.716137 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |     87 |          55.6293 | nan           |   1666370299 |            0.526307 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7044847011566162\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 92\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-20\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 92\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.0008143160375766456\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 75.24852156639099\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7049984931945801\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 75.24852156639099\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 92\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5867276191711426\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370301\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 91\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-21\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 91\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 57.92304849624634\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5871350765228271\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 57.92304849624634\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370301\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 91\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7034728527069092\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370302\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 113\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-22\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 113\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5802390575408936\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 79.62434482574463\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7033157348632812\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 79.62434482574463\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370302\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 113\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.625521183013916\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370302\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 81\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-22\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 81\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.553330183029175\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 59.527323722839355\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6254136562347412\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 59.527323722839355\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370302\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 81\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:38:24 (running for 00:01:24.99)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=0.0004964990657754242 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    116 |          81.5542 |   3.57986     |   1666370304 |            0.609423 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |     98 |          79.7221 |   0.000496499 |   1666370304 |            0.795371 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |     83 |          60.8052 |   3.54765     |   1666370304 |            0.611232 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |     96 |          60.7613 | nan           |   1666370304 |            0.526218 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6948132514953613\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370305\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 99\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-25\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 99\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.00046240154188126326\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 80.41736769676208\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6952526569366455\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 80.41736769676208\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370305\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 99\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5290017127990723\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370306\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 100\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-26\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 100\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 63.058541774749756\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5285587310791016\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 63.058541774749756\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370306\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 100\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.615206241607666\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370307\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 121\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-27\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 121\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.579231023788452\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 84.77807641029358\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6152908802032471\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 84.77807641029358\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370307\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 121\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7229509353637695\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370308\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 89\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-28\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 89\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.526923179626465\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 64.85493183135986\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7234070301055908\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 64.85493183135986\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370308\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 89\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:38:29 (running for 00:01:30.15)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=0.0003548564563971013 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    124 |          86.7823 |   3.57886     |   1666370309 |            0.686511 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    104 |          84.2931 |   0.000354856 |   1666370309 |            0.805816 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |     91 |          66.1434 |   3.51886     |   1666370309 |            0.682348 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    106 |          66.4871 | nan           |   1666370309 |            0.59615  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7212250232696533\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370310\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 106\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-30\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 106\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.00032363258651457727\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 85.80541396141052\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7217864990234375\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 85.80541396141052\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370310\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 106\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5191693305969238\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370311\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 109\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-31\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 109\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 68.15928792953491\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5193312168121338\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 68.15928792953491\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370311\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 109\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6300709247589111\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370312\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 129\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-32\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 129\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5782811641693115\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 90.04593515396118\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6305463314056396\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 90.04593515396118\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370312\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 129\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7136809825897217\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370313\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 97\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-33\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 97\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.4881303310394287\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 70.12147903442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7137188911437988\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 70.12147903442383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370313\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 97\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:38:35 (running for 00:01:35.25)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=0.0002604949695523828 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    132 |          91.9892 |   3.57794     |   1666370314 |            0.595984 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    111 |          89.53   |   0.000260495 |   1666370314 |            0.719921 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |     99 |          71.4355 |   3.47413     |   1666370314 |            0.693345 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    115 |          71.5629 | nan           |   1666370314 |            0.595622 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7009968757629395\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370316\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 113\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-36\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 113\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.00024177176237571985\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 91.0651741027832\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7007696628570557\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 91.0651741027832\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370316\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 113\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5183334350585938\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370316\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 118\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-36\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 118\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 73.23276495933533\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5183677673339844\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 73.23276495933533\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370316\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 118\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6694390773773193\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370317\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 137\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-37\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 137\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5773370265960693\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 95.28758239746094\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6693141460418701\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 95.28758239746094\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370317\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 137\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6550908088684082\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370318\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 105\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-38\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 105\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.4283218383789062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 75.34712719917297\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6549804210662842\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 75.34712719917297\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370318\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 105\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:38:40 (running for 00:01:40.29)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=0.0002030619070865214 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    140 |          97.2541 |   3.57697     |   1666370319 |            0.609489 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    118 |          94.8898 |   0.000203062 |   1666370319 |            0.749557 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    107 |          76.6882 |   3.41062     |   1666370319 |            0.638028 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    124 |          76.6231 | nan           |   1666370320 |            0.526395 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7593839168548584\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370321\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 120\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-41\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 120\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.00019063579384237528\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 96.40763688087463\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7593929767608643\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 96.40763688087463\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370321\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 120\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5141615867614746\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370321\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 127\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-41\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 127\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 78.3045084476471\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5139236450195312\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 78.3045084476471\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370321\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 127\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6242556571960449\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370323\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 145\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-43\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 145\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5763461589813232\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 100.51194024085999\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.624220609664917\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 100.51194024085999\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370323\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 145\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6788661479949951\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370324\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 113\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-44\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 113\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.3486855030059814\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 80.75757551193237\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6784708499908447\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 80.75757551193237\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370324\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 113\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:38:45 (running for 00:01:45.32)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.4/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=0.00016792376118246466 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    148 |         102.548  |   3.57596     |   1666370325 |            0.6913   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    124 |          99.4273 |   0.000167924 |   1666370324 |            0.786273 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    114 |          81.3782 |   3.33674     |   1666370324 |            0.620595 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    132 |          81.2069 | nan           |   1666370324 |            0.611536 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7251975536346436\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370326\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 127\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 127\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.00015506625641137362\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 101.6515622138977\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7256069183349609\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 101.6515622138977\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370326\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 127\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6024565696716309\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370326\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 136\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 136\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 83.48603630065918\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6019697189331055\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 83.48603630065918\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370326\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 136\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6031396389007568\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370328\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 153\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-48\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 153\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.575279951095581\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 105.77063941955566\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6034181118011475\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 105.77063941955566\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370328\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 153\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7361657619476318\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370329\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 121\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-49\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 121\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.24576735496521\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 86.08166766166687\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7354791164398193\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 86.08166766166687\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370329\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 121\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:38:50 (running for 00:01:50.47)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=0.00014087502495385706 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    155 |         107.147  |   3.575       |   1666370329 |            0.635703 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    131 |         104.688  |   0.000140875 |   1666370329 |            0.689478 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    122 |          86.7022 |   3.23194     |   1666370329 |            0.620232 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    142 |          86.8078 | nan           |   1666370330 |            0.520061 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.8269665241241455\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370331\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 134\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-51\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 134\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.00013034677249379456\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 106.93502831459045\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.8269233703613281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 106.93502831459045\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370331\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 134\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6362571716308594\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370331\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 145\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-52\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 145\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 88.58553385734558\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6364598274230957\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 88.58553385734558\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370332\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 145\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6899089813232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370333\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 161\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-53\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 161\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5741727352142334\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 111.0987138748169\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6898391246795654\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 111.0987138748169\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370333\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 161\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6745285987854004\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370334\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 129\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-54\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 129\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.1301920413970947\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 91.32386875152588\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6751301288604736\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 91.32386875152588\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370334\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 129\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:38:55 (running for 00:01:55.51)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.4/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=0.00011917009396711364 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+--------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |         loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+--------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    163 |         112.444  |   3.5739     |   1666370334 |            0.694925 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    138 |         109.967  |   0.00011917 |   1666370334 |            0.763591 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    130 |          91.993  |   3.11441    |   1666370335 |            0.669689 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    150 |          91.3975 | nan          |   1666370334 |            0.563707 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+--------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6141180992126465\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370337\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 154\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-57\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 154\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 93.63050484657288\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6138968467712402\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 93.63050484657288\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370337\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 154\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7661833763122559\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370337\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 141\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-57\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 141\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.00011176833504578099\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 112.21263599395752\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.766324520111084\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 112.21263599395752\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370337\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 141\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6814455986022949\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370338\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 169\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-58\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 169\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5731000900268555\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 116.36084342002869\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6816105842590332\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 116.36084342002869\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370338\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 169\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6656825542449951\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370339\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 137\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-38-59\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 137\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.002232313156128\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 96.63581824302673\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6654362678527832\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 96.63581824302673\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370339\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 137\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:39:00 (running for 00:02:00.57)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=0.00010362904868088663 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    171 |         117.643  |   3.57282     |   1666370340 |            0.621314 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    145 |         115.3    |   0.000103629 |   1666370340 |            0.689132 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    137 |          96.6358 |   3.00223     |   1666370339 |            0.665683 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    159 |          96.4487 | nan           |   1666370339 |            0.57231  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5210375785827637\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370342\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 163\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-02\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 163\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 98.6707808971405\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5210709571838379\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 98.6707808971405\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370342\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 163\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.8324570655822754\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370342\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 148\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-02\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 148\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 9.78575917542912e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 117.52517485618591\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.8324031829833984\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 117.52517485618591\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370342\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 148\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6259150505065918\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370344\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 177\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-04\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 177\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5719950199127197\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 121.61592197418213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6244778633117676\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 121.61592197418213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370344\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 177\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7621316909790039\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370345\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 145\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 145\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 2.865165948867798\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 101.95062398910522\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7624709606170654\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 101.95062398910522\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370345\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 145\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:39:05 (running for 00:02:05.76)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.4/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=9.2535417934414e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    179 |          122.986 |   3.57171     |   1666370345 |            0.675034 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    151 |          119.731 |   9.25354e-05 |   1666370344 |            0.705476 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    145 |          101.951 |   2.86517     |   1666370345 |            0.762132 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    168 |          101.501 | nan           |   1666370344 |            0.538017 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5260818004608154\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370347\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 172\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-07\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 172\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 103.75007319450378\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5262246131896973\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 103.75007319450378\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370347\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 172\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.8158974647521973\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370347\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 155\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-07\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 155\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 8.657258149469271e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 122.82982802391052\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.8156170845031738\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 122.82982802391052\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370347\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 155\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7070045471191406\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370349\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 185\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-09\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 185\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.57086181640625\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 126.94363760948181\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7074110507965088\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 126.94363760948181\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370349\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 185\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:39:10 (running for 00:02:10.86)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=8.250628161476925e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    186 |          127.557 |   3.57072     |   1666370350 |            0.613273 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    158 |          125.082 |   8.25063e-05 |   1666370350 |            0.751684 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    152 |          106.656 |   2.73045     |   1666370349 |            0.675055 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    178 |          107.194 | nan           |   1666370350 |            0.581789 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7320706844329834\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370350\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 153\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-10\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 153\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 2.707275152206421\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 107.38800978660583\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7323646545410156\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 107.38800978660583\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370350\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 153\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5422263145446777\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370352\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 181\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-12\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 181\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 108.84269857406616\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5419447422027588\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 108.84269857406616\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370352\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 181\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.8114209175109863\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370353\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 162\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-13\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 162\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 7.756346167298034e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 128.130291223526\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.8110721111297607\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 128.130291223526\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370353\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 162\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6786088943481445\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370354\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 193\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-14\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 193\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5697367191314697\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 132.22864270210266\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6787183284759521\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 132.22864270210266\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370354\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 193\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:39:15 (running for 00:02:15.95)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.4/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=7.427154923789203e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    194 |          132.855 |   3.5696      |   1666370355 |            0.626462 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    165 |          130.267 |   7.42715e-05 |   1666370355 |            0.664602 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    160 |          112.145 |   2.56117     |   1666370355 |            0.69131  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    187 |          112.261 | nan           |   1666370355 |            0.556785 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6800022125244141\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370356\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 161\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-16\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 161\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 2.542175531387329\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 112.82453894615173\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6799590587615967\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 112.82453894615173\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370356\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 161\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5879638195037842\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370357\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 190\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-17\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 190\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 113.97091126441956\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5879769325256348\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 113.97091126441956\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370357\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 190\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7021455764770508\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370358\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 169\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-18\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 169\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 7.018759060883895e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 133.3069920539856\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7022600173950195\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 133.3069920539856\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370358\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 169\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6070156097412109\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370359\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 201\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-19\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 201\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5686187744140625\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 137.41028332710266\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6072483062744141\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 137.41028332710266\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370359\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 201\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:39:20 (running for 00:02:20.98)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=6.733991176588461e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    202 |          138.099 |   3.56848     |   1666370360 |            0.688647 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    172 |          135.621 |   6.73399e-05 |   1666370360 |            0.755806 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    167 |          116.87  |   2.41191     |   1666370360 |            0.682317 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    196 |          117.314 | nan           |   1666370360 |            0.539212 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7829935550689697\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370361\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 169\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-21\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 169\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 2.364175319671631\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 118.28010678291321\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7826838493347168\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 118.28010678291321\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370361\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 169\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5914738178253174\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370362\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 199\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-22\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 199\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 119.0663423538208\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.591900110244751\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 119.0663423538208\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370362\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 199\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7950718402862549\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370363\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 176\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-23\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 176\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 6.391871283994988e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 138.61066222190857\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7952382564544678\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 138.61066222190857\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370363\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 176\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6645808219909668\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370365\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 209\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-25\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 209\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5674984455108643\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 142.75284790992737\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6616041660308838\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 142.75284790992737\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370365\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 209\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:39:25 (running for 00:02:26.07)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.4/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=6.226520781638101e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    209 |          142.753 |   3.5675      |   1666370365 |            0.664581 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    178 |          140.126 |   6.22652e-05 |   1666370365 |            0.758995 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    175 |          122.241 |   2.22632     |   1666370365 |            0.672902 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    205 |          122.404 | nan           |   1666370365 |            0.520992 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7366142272949219\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370366\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 177\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-26\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 177\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 2.184657096862793\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 123.59903502464294\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7366943359375\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 123.59903502464294\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370366\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 177\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.585038423538208\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370367\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 208\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-27\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 208\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 124.13223767280579\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.584965705871582\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 124.13223767280579\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370367\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 208\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6955044269561768\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370368\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 183\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-28\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 183\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 5.8503737818682566e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 143.89739632606506\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6954734325408936\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 143.89739632606506\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370368\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 183\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6768910884857178\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370370\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 217\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-30\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 217\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.566385507583618\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 147.99583196640015\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.676506757736206\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 147.99583196640015\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370370\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 217\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:39:30 (running for 00:02:31.20)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=5.7379027566639706e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+--------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |         loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+--------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    217 |          147.996 |   3.56639    |   1666370370 |            0.676891 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    185 |          145.439 |   5.7379e-05 |   1666370370 |            0.685399 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    183 |          127.541 |   2.04164    |   1666370370 |            0.6208   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    214 |          127.538 | nan          |   1666370370 |            0.580521 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+--------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6744370460510254\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370372\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 185\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-32\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 185\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 1.996544361114502\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 128.90138792991638\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6747786998748779\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 128.90138792991638\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370372\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 185\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.543651819229126\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370372\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 217\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-32\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 217\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 129.24902820587158\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5438201427459717\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 129.24902820587158\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370372\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 217\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.777249813079834\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370374\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 190\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-34\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 190\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 5.4200965678319335e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 149.18707752227783\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7773196697235107\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 149.18707752227783\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370374\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 190\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6207952499389648\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370375\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 225\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-35\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 225\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5652854442596436\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 153.2970130443573\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6208205223083496\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 153.2970130443573\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370375\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 225\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:39:36 (running for 00:02:36.33)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.4/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=5.307620085659437e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    225 |          153.297 |   3.56529     |   1666370375 |            0.620795 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    192 |          150.727 |   5.30762e-05 |   1666370375 |            0.794268 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    190 |          132.23  |   1.87535     |   1666370375 |            0.676652 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    223 |          132.666 | nan           |   1666370376 |            0.58586  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7515397071838379\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370377\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 193\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-37\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 193\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 1.8113627433776855\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 134.21477508544922\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7516615390777588\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 134.21477508544922\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370377\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 193\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5253870487213135\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370377\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 226\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-37\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 226\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 134.3411464691162\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5253777503967285\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 134.3411464691162\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370377\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 226\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7229170799255371\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370379\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 197\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-39\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 197\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 5.0402104534441605e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 154.44980931282043\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7228062152862549\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 154.44980931282043\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370379\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 197\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6351852416992188\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370381\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 233\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-41\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 233\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5641775131225586\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 158.60796189308167\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6350207328796387\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 158.60796189308167\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370381\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 233\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:39:41 (running for 00:02:41.38)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=4.934685057378374e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    233 |          158.608 |   3.56418     |   1666370381 |            0.635185 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    199 |          155.973 |   4.93469e-05 |   1666370380 |            0.66084  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    198 |          137.585 |   1.70025     |   1666370380 |            0.635532 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    231 |          137.162 | nan           |   1666370380 |            0.53486  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.577136754989624\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370382\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 235\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-42\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 235\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 139.45604610443115\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5769753456115723\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 139.45604610443115\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370382\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 235\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7340836524963379\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370382\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 201\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-42\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 201\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 1.630354881286621\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 139.64383554458618\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.733417272567749\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 139.64383554458618\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370382\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 201\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7551145553588867\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370384\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 204\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-44\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 204\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 4.694337258115411e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 159.6872375011444\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7551918029785156\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 159.6872375011444\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370384\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 204\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:39:46 (running for 00:02:46.44)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.4/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=4.6533667045878246e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    240 |          163.225 |   3.56319     |   1666370385 |            0.608454 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    205 |          160.417 |   4.65337e-05 |   1666370385 |            0.730395 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    206 |          142.922 |   1.52511     |   1666370386 |            0.688962 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    240 |          142.335 | nan           |   1666370385 |            0.574632 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6892852783203125\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370386\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 241\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 241\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.563044786453247\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 163.9141652584076\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6894102096557617\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 163.9141652584076\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370386\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 241\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5627717971801758\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370387\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 244\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-47\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 244\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 144.5309636592865\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5630054473876953\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 144.5309636592865\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370387\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 244\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6726758480072021\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370388\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 209\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-48\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 209\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 1.4500794410705566\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 144.90380668640137\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6725132465362549\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 144.90380668640137\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370388\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 209\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6685476303100586\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370390\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 211\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-50\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 211\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 4.403083221404813e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 165.08520483970642\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.668104887008667\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 165.08520483970642\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370390\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 211\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:39:51 (running for 00:02:51.59)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=4.3623611418297514e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    248 |          168.518 |   3.56203     |   1666370391 |            0.620839 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    212 |          165.891 |   4.36236e-05 |   1666370390 |            0.805845 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    213 |          147.589 |   1.35257     |   1666370390 |            0.673727 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    250 |          147.928 | nan           |   1666370391 |            0.525054 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6158492565155029\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370391\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 249\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-51\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 249\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5618879795074463\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 169.13393878936768\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6157934665679932\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 169.13393878936768\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370391\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 249\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6237878799438477\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370393\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 253\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-53\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 253\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 149.67218685150146\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6236827373504639\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 149.67218685150146\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370393\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 253\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6550273895263672\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370393\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 217\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-53\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 217\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 1.2584000825881958\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 150.25357913970947\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6554806232452393\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 150.25357913970947\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370393\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 217\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7498903274536133\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370395\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-55\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 4.145095226704143e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 170.30501794815063\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7501587867736816\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 170.30501794815063\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370395\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:39:56 (running for 00:02:56.69)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=4.095435360795818e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    256 |          173.794 |   3.56087     |   1666370396 |            0.682635 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    219 |          171.018 |   4.09544e-05 |   1666370396 |            0.712835 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    221 |          152.896 |   1.17481     |   1666370396 |            0.731905 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    259 |          153.03  | nan           |   1666370396 |            0.51345  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6146113872528076\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370396\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 257\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-56\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 257\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.560724973678589\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 174.40827059745789\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.614326000213623\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 174.40827059745789\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370396\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 257\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6024203300476074\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370398\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 262\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-58\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 262\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 154.73694467544556\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6019649505615234\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 154.73694467544556\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370398\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 262\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7272989749908447\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370398\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 225\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-39-58\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 225\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 1.0881826877593994\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 155.59598970413208\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7275035381317139\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 155.59598970413208\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370398\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 225\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6681928634643555\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370400\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 225\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-00\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 225\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.8977839722065255e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 175.53431963920593\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.667900800704956\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 175.53431963920593\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370400\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 225\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:40:01 (running for 00:03:01.77)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=3.866497354465537e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+--------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |         loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+--------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    263 |          178.363 |   3.55983    |   1666370400 |            0.717631 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    226 |          176.292 |   3.8665e-05 |   1666370401 |            0.757418 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    229 |          158.258 |   1.00347    |   1666370401 |            0.726711 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    267 |          157.523 | nan          |   1666370400 |            0.525744 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+--------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6801261901855469\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370402\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 265\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-02\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 265\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5595340728759766\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 179.70812153816223\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6799840927124023\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 179.70812153816223\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370402\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 265\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5817689895629883\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370403\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 271\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-03\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 271\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 159.7964813709259\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5821733474731445\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 159.7964813709259\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370403\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 271\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6711676120758057\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370404\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 233\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-04\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 233\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.9287397265434265\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 160.84641766548157\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6705708503723145\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 160.84641766548157\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370404\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 233\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7340583801269531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370405\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 232\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 232\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.6765421100426465e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 180.8323037624359\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7338259220123291\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 180.8323037624359\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370405\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 232\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:40:06 (running for 00:03:06.82)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=3.651214865385555e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    271 |          183.698 |   3.55865     |   1666370406 |            0.710915 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    233 |          181.551 |   3.65121e-05 |   1666370406 |            0.718647 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    236 |          162.825 |   0.877198    |   1666370406 |            0.693389 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    276 |          162.588 | nan           |   1666370406 |            0.522235 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6672472953796387\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370407\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 273\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-07\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 273\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.558345079421997\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 184.98612928390503\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6670186519622803\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 184.98612928390503\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370407\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 273\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5412747859954834\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370408\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 280\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-08\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 280\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 164.86043977737427\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5411808490753174\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 164.86043977737427\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370408\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 280\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6764087677001953\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370409\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 241\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-09\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 241\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.8071966171264648\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 166.22345852851868\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6764712333679199\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 166.22345852851868\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370409\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 241\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6786799430847168\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370411\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-11\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.4850942029152066e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 186.11336088180542\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6786816120147705\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 186.11336088180542\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370411\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:40:11 (running for 00:03:11.97)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=3.4850942029152066e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    279 |          188.89  |   3.55742     |   1666370411 |            0.638982 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    239 |          186.113 |   3.48509e-05 |   1666370411 |            0.67868  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    244 |          168.213 |   0.808973    |   1666370411 |            0.637554 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    286 |          168.302 | nan           |   1666370411 |            0.615111 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6116094589233398\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370412\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-12\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5571022033691406\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 190.2533621788025\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6114370822906494\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 190.2533621788025\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370412\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5211799144744873\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370413\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 289\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-13\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 289\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 169.9869682788849\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5208303928375244\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 169.9869682788849\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370413\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 289\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7242505550384521\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370414\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 249\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-14\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 249\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.7289078831672668\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 171.57946705818176\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7243573665618896\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 171.57946705818176\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370414\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 249\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7672743797302246\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370416\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 246\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-16\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 246\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.309786188765429e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 191.41325163841248\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7674269676208496\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 191.41325163841248\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370416\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 246\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:40:16 (running for 00:03:16.99)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 4.0/4 CPUs, 4.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=3.309786188765429e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 RUNNING)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status   | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING  | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    286 |          193.602 |   3.55633     |   1666370416 |            0.667368 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING  | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    246 |          191.413 |   3.30979e-05 |   1666370416 |            0.767274 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING  | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    252 |          173.472 |   0.681951    |   1666370416 |            0.60994  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | RUNNING  | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    294 |          172.856 | nan           |   1666370416 |            0.58195  |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+----------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6717081069946289\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370418\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 289\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-18\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 289\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5558605194091797\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 195.54074811935425\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6720881462097168\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 195.54074811935425\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370418\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 289\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.5562534332275391\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370418\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 298\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-18\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 298\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 175.09038162231445\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.5561137199401855\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 175.09038162231445\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370418\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 298\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m NaN or Inf found in input tensor.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.007835149765014648\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370419\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 301\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-19\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   eval_loss: [3.6102116107940674, 3.57818341255188, 3.5612926483154297, 3.476954698562622,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.470672845840454, 3.3174149990081787, 3.3911848068237305, 3.4579379558563232, 3.621151924133301,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.449187994003296, 3.5792338848114014, 3.814288854598999, 3.8319480419158936, 4.1375837326049805,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     4.247939586639404, 6.084779262542725, 5.5567450523376465, 4.893978118896484, 6.578577041625977,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.378326416015625, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 582bd45323de44e98964e19e94ec2992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_tag: 3_batch_size=4,epochs=300,lr=0.1000,momentum=0.9000,tune_run=True\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-zr29t\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 301\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: .nan\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   model: \"Sequential(\\n  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\\n  (1):\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\\n \\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\\n  (3): MaxPool2d(kernel_size=2,\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ stride=2, padding=0, dilation=1, ceil_mode=False)\\n  (4): Flatten(start_dim=1,\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ end_dim=-1)\\n  (5): Linear(in_features=6272, out_features=128, bias=True)\\n  (6):\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ ReLU()\\n  (7): Linear(in_features=128, out_features=64, bias=True)\\n  (8): ReLU()\\n\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\  (9): Linear(in_features=64, out_features=37, bias=True)\\n)\"\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.129.4.218\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 176.3225073814392\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.1212606430053711\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 176.3225073814392\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370419\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 301\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_loss: [3.633845329284668, 3.581526517868042, 3.523130178451538, 3.4152309894561768,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.3767502307891846, 3.159223794937134, 2.9590904712677, 2.624265670776367, 2.4433701038360596,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     1.982420563697815, 1.3013262748718262, 1.0302070379257202, 0.5290725827217102, 1.1125789880752563,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.6331357359886169, 0.30023232102394104, 0.6716075539588928, 0.4203338623046875,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.7005383968353271, 1.6603585481643677, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan, .nan,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     .nan, .nan, .nan, .nan, .nan, .nan, .nan]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003767728805541992\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6714084148406982\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370420\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 257\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-20\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 257\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.6227098107337952\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 176.85978770256042\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.671757698059082\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 176.85978770256042\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370420\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 257\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.674750804901123\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370421\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 253\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-21\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 253\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.148630275973119e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 196.74378657341003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6748526096343994\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 196.74378657341003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370421\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 253\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:40:21 (running for 00:03:22.01)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 3.0/4 CPUs, 3.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=3.148630275973119e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (3 RUNNING, 1 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | RUNNING    | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    294 |          198.791 |   3.55507     |   1666370421 |          0.629871   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING    | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    253 |          196.744 |   3.14863e-05 |   1666370421 |          0.674751   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING    | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    259 |          178.176 |   0.720484    |   1666370421 |          0.623688   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | TERMINATED | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    301 |          176.323 | nan           |   1666370419 |          0.00783515 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6791141033172607\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370423\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 297\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-23\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 297\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5546047687530518\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 200.79881191253662\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6790614128112793\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 200.79881191253662\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370423\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 297\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=244, ip=10.128.4.70)\u001b[0m E1021 16:40:25.501742310     269 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6524245738983154\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370425\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 265\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-25\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 265\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.5792755484580994\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 182.19568610191345\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6526153087615967\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 182.19568610191345\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370425\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 265\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.006505012512207031\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370425\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 301\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-25\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   eval_loss: [3.617474317550659, 3.6173717975616455, 3.6172707080841064, 3.617176055908203,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.617088556289673, 3.616994857788086, 3.6169073581695557, 3.6168253421783447, 3.6167373657226562,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6166560649871826, 3.616567373275757, 3.6164772510528564, 3.6163899898529053, 3.616297721862793,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.61620831489563, 3.6161134243011475, 3.6160242557525635, 3.6159393787384033, 3.615851640701294,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.61575984954834, 3.6156704425811768, 3.615588903427124, 3.6155107021331787, 3.6154356002807617,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.615361452102661, 3.6152894496917725, 3.615215301513672, 3.6151363849639893, 3.6150569915771484,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.614975690841675, 3.6148931980133057, 3.6148087978363037, 3.614732027053833, 3.614654541015625,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.614579916000366, 3.6145031452178955, 3.6144258975982666, 3.6143481731414795, 3.614269256591797,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6141881942749023, 3.6141107082366943, 3.6140356063842773, 3.613959312438965, 3.613881826400757,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.61380934715271, 3.613732099533081, 3.6136538982391357, 3.613576650619507, 3.6135008335113525,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6134274005889893, 3.613356828689575, 3.6132867336273193, 3.6132164001464844, 3.613140344619751,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6130669116973877, 3.6129941940307617, 3.6129236221313477, 3.61285400390625, 3.6127824783325195,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6127116680145264, 3.61264705657959, 3.612583875656128, 3.6125242710113525, 3.61246657371521,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6124134063720703, 3.6123616695404053, 3.612309217453003, 3.612260103225708, 3.612210273742676,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.61216139793396, 3.6121113300323486, 3.6120574474334717, 3.6120080947875977, 3.6119604110717773,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6119155883789062, 3.6118686199188232, 3.611816644668579, 3.6117630004882812, 3.611710548400879,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6116600036621094, 3.6116106510162354, 3.611562490463257, 3.611518144607544, 3.6114721298217773,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6114273071289062, 3.611382484436035, 3.611334800720215, 3.6112899780273438, 3.6112442016601562,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.611198663711548, 3.6111536026000977, 3.6111090183258057, 3.611064910888672, 3.611021041870117,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6109745502471924, 3.610931158065796, 3.6108837127685547, 3.610841751098633, 3.610797643661499,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.610753059387207, 3.610707998275757, 3.610661268234253, 3.61061692237854, 3.610572576522827,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.610527753829956, 3.6104819774627686, 3.610438108444214, 3.61038875579834, 3.6103403568267822,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.610288381576538, 3.6102373600006104, 3.610184907913208, 3.610136032104492, 3.6100854873657227,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6100351810455322, 3.6099815368652344, 3.609927177429199, 3.609875440597534, 3.6098203659057617,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6097662448883057, 3.6097137928009033, 3.609661340713501, 3.6096103191375732, 3.6095564365386963,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.609501600265503, 3.609448194503784, 3.6093969345092773, 3.609342575073242, 3.6092910766601562,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.609234571456909, 3.6091833114624023, 3.609130859375, 3.609074592590332, 3.6090173721313477,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6089611053466797, 3.6089022159576416, 3.6088435649871826, 3.608783721923828, 3.6087253093719482,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.60866379737854, 3.6086063385009766, 3.608548879623413, 3.608488082885742, 3.6084258556365967,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.608365774154663, 3.608302116394043, 3.60823917388916, 3.6081769466400146, 3.6081132888793945,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6080477237701416, 3.607983350753784, 3.607912063598633, 3.6078367233276367, 3.607759475708008,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.607677459716797, 3.6075990200042725, 3.6075189113616943, 3.607433319091797, 3.607351064682007,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.607272148132324, 3.6071910858154297, 3.607104539871216, 3.6070163249969482, 3.606926918029785,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6068437099456787, 3.606760263442993, 3.6066770553588867, 3.60659122467041, 3.6065006256103516,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6064140796661377, 3.6063292026519775, 3.60624098777771, 3.606154441833496, 3.606064558029175,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6059796810150146, 3.605895757675171, 3.605811834335327, 3.6057233810424805, 3.6056392192840576,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6055548191070557, 3.605470657348633, 3.60538649559021, 3.605302095413208, 3.6052186489105225,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.605132818222046, 3.605046033859253, 3.6049585342407227, 3.6048707962036133, 3.6047821044921875,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6046950817108154, 3.6046066284179688, 3.6045210361480713, 3.6044342517852783,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6043500900268555, 3.604264974594116, 3.6041812896728516, 3.6040995121002197, 3.6040191650390625,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6039373874664307, 3.6038570404052734, 3.603775978088379, 3.60369873046875, 3.6036226749420166,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6035451889038086, 3.6034648418426514, 3.603384017944336, 3.6033027172088623, 3.6032216548919678,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.603142023086548, 3.6030619144439697, 3.6029818058013916, 3.602897882461548, 3.602818727493286,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.602740526199341, 3.6026594638824463, 3.602583646774292, 3.602506637573242, 3.6024296283721924,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6023550033569336, 3.6022796630859375, 3.6022071838378906, 3.602132797241211, 3.602060079574585,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6019880771636963, 3.6019134521484375, 3.6018409729003906, 3.6017675399780273,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6016952991485596, 3.601618528366089, 3.601543664932251, 3.6014671325683594, 3.6013946533203125,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.601318597793579, 3.6012465953826904, 3.6011741161346436, 3.6011009216308594, 3.601027250289917,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.600954055786133, 3.6008787155151367, 3.600804090499878, 3.600728988647461, 3.6006524562835693,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.600576400756836, 3.600501298904419, 3.6004257202148438, 3.600349187850952, 3.6002724170684814,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6001975536346436, 3.6001217365264893, 3.6000425815582275, 3.5999650955200195,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.599884033203125, 3.5998048782348633, 3.599724054336548, 3.599644422531128, 3.5995657444000244,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5994865894317627, 3.59941029548645, 3.599331855773926, 3.599254608154297, 3.599180221557617,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5991036891937256, 3.5990259647369385, 3.598952054977417, 3.5988779067993164, 3.598801374435425,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5987281799316406, 3.598653793334961, 3.5985777378082275, 3.5985050201416016, 3.5984294414520264,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5983517169952393, 3.598275899887085, 3.5981950759887695, 3.5981128215789795, 3.598031997680664,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5979490280151367, 3.5978691577911377, 3.597788095474243, 3.5977089405059814, 3.59763503074646,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.597557306289673, 3.597477912902832, 3.5973968505859375, 3.5973165035247803, 3.5972349643707275,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.597153663635254, 3.5970680713653564, 3.5969839096069336, 3.5968997478485107, 3.5968124866485596,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5967276096343994, 3.5966427326202393, 3.5965585708618164, 3.5964744091033936,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5963919162750244, 3.596308469772339, 3.596221685409546, 3.596139669418335, 3.596054792404175]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: 13a9140d1abe4aabaeda92dcc8eb612f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_tag: 0_batch_size=4,epochs=300,lr=0.0010,momentum=0.1000,tune_run=True\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-xqqcf\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 301\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.5541305541992188\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   model: \"Sequential(\\n  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\\n  (1):\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\\n \\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\\n  (3): MaxPool2d(kernel_size=2,\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ stride=2, padding=0, dilation=1, ceil_mode=False)\\n  (4): Flatten(start_dim=1,\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ end_dim=-1)\\n  (5): Linear(in_features=6272, out_features=128, bias=True)\\n  (6):\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ ReLU()\\n  (7): Linear(in_features=128, out_features=64, bias=True)\\n  (8): ReLU()\\n\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\  (9): Linear(in_features=64, out_features=37, bias=True)\\n)\"\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.4.70\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 213\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 202.8996341228485\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.10070204734802246\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 202.8996341228485\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370425\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 301\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_loss: [3.5953614711761475, 3.59516978263855, 3.594987630844116, 3.5948078632354736,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5946314334869385, 3.5944583415985107, 3.594290018081665, 3.5941219329833984, 3.5939557552337646,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5937910079956055, 3.5936222076416016, 3.593446969985962, 3.593273162841797, 3.5931012630462646,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5929343700408936, 3.592768907546997, 3.592597007751465, 3.592419385910034, 3.5922374725341797,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.592057943344116, 3.5918824672698975, 3.591726064682007, 3.5915727615356445, 3.591423988342285,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5912768840789795, 3.5911293029785156, 3.5909805297851562, 3.5908355712890625,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.590693473815918, 3.5905535221099854, 3.5904109477996826, 3.5902631282806396, 3.590118169784546,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.589977979660034, 3.5898396968841553, 3.5896975994110107, 3.5895614624023438, 3.5894272327423096,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.58929705619812, 3.589167594909668, 3.589040517807007, 3.5889174938201904, 3.5887959003448486,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.588677406311035, 3.588557481765747, 3.58843994140625, 3.5883238315582275, 3.588205575942993,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5880889892578125, 3.5879697799682617, 3.5878493785858154, 3.587728500366211, 3.5876083374023438,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5874881744384766, 3.5873677730560303, 3.587247133255005, 3.587125062942505, 3.587003469467163,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.58687686920166, 3.5867502689361572, 3.5866243839263916, 3.5864970684051514, 3.5863711833953857,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.586242914199829, 3.586115598678589, 3.5859832763671875, 3.5858547687530518, 3.585726022720337,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5855977535247803, 3.585465669631958, 3.585334539413452, 3.5852062702178955, 3.585078477859497,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.584951400756836, 3.5848217010498047, 3.5846946239471436, 3.5845701694488525, 3.584451675415039,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.584331512451172, 3.5842130184173584, 3.584096908569336, 3.5839812755584717, 3.5838658809661865,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5837461948394775, 3.5836260318756104, 3.583502769470215, 3.583381414413452, 3.583261489868164,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.583139657974243, 3.583017587661743, 3.5828964710235596, 3.5827739238739014, 3.5826549530029297,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5825369358062744, 3.5824215412139893, 3.582305908203125, 3.582188606262207, 3.5820672512054443,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5819461345672607, 3.581822395324707, 3.5816986560821533, 3.581575393676758, 3.581451416015625,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5813305377960205, 3.581210136413574, 3.581087827682495, 3.5809648036956787, 3.5808470249176025,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5807278156280518, 3.580606460571289, 3.580486297607422, 3.5803639888763428, 3.5802390575408936,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5801122188568115, 3.5799827575683594, 3.5798568725585938, 3.579730749130249, 3.5796051025390625,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.579479455947876, 3.5793545246124268, 3.579231023788452, 3.5791075229644775, 3.578986167907715,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.578864812850952, 3.5787456035614014, 3.5786283016204834, 3.5785114765167236, 3.578396797180176,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5782811641693115, 3.5781660079956055, 3.578050374984741, 3.577935218811035, 3.577816963195801,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.577697992324829, 3.5775792598724365, 3.577458620071411, 3.5773370265960693, 3.5772171020507812,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5770952701568604, 3.576972246170044, 3.5768489837646484, 3.576724052429199, 3.576596975326538,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.576470375061035, 3.5763461589813232, 3.576218605041504, 3.5760929584503174, 3.5759639739990234,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.575834274291992, 3.575698137283325, 3.5755598545074463, 3.575420379638672, 3.575279951095581,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5751407146453857, 3.575002908706665, 3.574864387512207, 3.574723243713379, 3.5745809078216553,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5744426250457764, 3.5743064880371094, 3.5741727352142334, 3.574037790298462, 3.5739030838012695,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.57376766204834, 3.5736310482025146, 3.573500871658325, 3.5733702182769775, 3.5732357501983643,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5731000900268555, 3.5729598999023438, 3.5728228092193604, 3.5726864337921143,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.572550058364868, 3.5724079608917236, 3.5722713470458984, 3.5721333026885986, 3.5719950199127197,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5718538761138916, 3.5717122554779053, 3.57157039642334, 3.571428060531616, 3.5712873935699463,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5711443424224854, 3.5710020065307617, 3.57086181640625, 3.570722818374634, 3.5705840587615967,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5704452991485596, 3.5703041553497314, 3.570161819458008, 3.5700199604034424, 3.5698776245117188,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5697367191314697, 3.5695955753326416, 3.569455862045288, 3.5693156719207764, 3.5691778659820557,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.569035768508911, 3.5688979625701904, 3.5687572956085205, 3.5686187744140625, 3.568479299545288,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5683367252349854, 3.5681943893432617, 3.568049430847168, 3.567909002304077, 3.567772150039673,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5676348209381104, 3.5674984455108643, 3.567359685897827, 3.567222833633423, 3.567084312438965,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5669467449188232, 3.5668067932128906, 3.5666658878326416, 3.566526174545288, 3.566385507583618,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5662460327148438, 3.566107988357544, 3.565969228744507, 3.5658318996429443, 3.5656940937042236,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.565556764602661, 3.5654208660125732, 3.5652854442596436, 3.5651493072509766, 3.5650107860565186,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5648727416992188, 3.56473708152771, 3.564596176147461, 3.564457893371582, 3.5643186569213867,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5641775131225586, 3.5640363693237305, 3.5638952255249023, 3.5637552738189697,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.563614845275879, 3.5634734630584717, 3.5633316040039062, 3.5631885528564453, 3.563044786453247,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5629007816314697, 3.562756299972534, 3.5626108646392822, 3.5624654293060303, 3.5623204708099365,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5621755123138428, 3.5620310306549072, 3.5618879795074463, 3.561744451522827, 3.561601400375366,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5614569187164307, 3.5613090991973877, 3.561164617538452, 3.561016798019409, 3.560872793197632,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.560724973678589, 3.5605783462524414, 3.560427665710449, 3.560276985168457, 3.5601279735565186,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.559981107711792, 3.5598318576812744, 3.559683084487915, 3.5595340728759766, 3.5593879222869873,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5592401027679443, 3.559093713760376, 3.5589473247528076, 3.5587971210479736, 3.558647871017456,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.55849552154541, 3.558345079421997, 3.558192491531372, 3.558037757873535, 3.55788254737854,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.557729482650757, 3.55757212638855, 3.557415246963501, 3.5572595596313477, 3.5571022033691406,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.556947946548462, 3.556791305541992, 3.556636095046997, 3.556481122970581, 3.556326150894165,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5561704635620117, 3.5560147762298584, 3.5558605194091797, 3.55570125579834, 3.5555460453033447,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5553877353668213, 3.555232286453247, 3.5550737380981445, 3.5549209117889404, 3.5547635555267334,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5546047687530518, 3.554450273513794, 3.554288625717163, 3.5541305541992188]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.004109382629394531\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7451417446136475\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370427\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 260\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-27\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 260\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 3.002619450853672e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 202.28288078308105\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7516255378723145\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 202.28288078308105\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370427\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 260\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:40:27 (running for 00:03:27.55)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 2.0/4 CPUs, 2.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=3.002619450853672e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (2 RUNNING, 2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING    | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    260 |          202.283 |   3.00262e-05 |   1666370427 |          0.745142   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING    | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    267 |          183.493 |   0.616035    |   1666370426 |          0.610158   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | TERMINATED | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    301 |          202.9   |   3.55413     |   1666370425 |          0.00650501 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | TERMINATED | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    301 |          176.323 | nan           |   1666370419 |          0.00783515 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7292048931121826\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370430\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 273\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-30\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 273\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.5904039144515991\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 187.53760075569153\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.728363037109375\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 187.53760075569153\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370430\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 273\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6473817825317383\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370432\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 267\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-32\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 267\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 2.87150851363549e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 207.3558464050293\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6472151279449463\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 207.3558464050293\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370432\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 267\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:40:32 (running for 00:03:32.62)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 2.0/4 CPUs, 2.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=2.87150851363549e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (2 RUNNING, 2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING    | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    267 |          207.356 |   2.87151e-05 |   1666370432 |          0.647382   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING    | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    275 |          188.842 |   0.446388    |   1666370432 |          0.691394   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | TERMINATED | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    301 |          202.9   |   3.55413     |   1666370425 |          0.00650501 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | TERMINATED | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    301 |          176.323 | nan           |   1666370419 |          0.00783515 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7289855480194092\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370436\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-36\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.4825470447540283\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 192.90094685554504\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7290239334106445\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 192.90094685554504\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370436\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:40:37 (running for 00:03:37.63)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.4/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 2.0/4 CPUs, 2.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=2.7692005460266955e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (2 RUNNING, 2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+--------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |         loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+--------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING    | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    273 |          212.081 |   2.7692e-05 |   1666370437 |          0.748539   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING    | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    283 |          194.122 |   0.505923   |   1666370437 |          0.614633   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | TERMINATED | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    301 |          202.9   |   3.55413    |   1666370425 |          0.00650501 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | TERMINATED | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    301 |          176.323 | nan          |   1666370419 |          0.00783515 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+--------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7964768409729004\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370437\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 274\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-37\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 274\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 2.7500798751134425e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 212.87069869041443\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7895240783691406\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 212.87069869041443\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370437\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 274\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.6848337650299072\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370441\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 289\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-41\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 289\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.4275762736797333\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 198.16694402694702\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.6842217445373535\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 198.16694402694702\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370441\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 289\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:40:42 (running for 00:03:43.01)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.4/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 2.0/4 CPUs, 2.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=2.652489820320625e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (2 RUNNING, 2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING    | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    280 |          217.218 |   2.65249e-05 |   1666370442 |          0.757604   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING    | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    291 |          199.496 |   0.397       |   1666370442 |          0.619226   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | TERMINATED | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    301 |          202.9   |   3.55413     |   1666370425 |          0.00650501 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | TERMINATED | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    301 |          176.323 | nan           |   1666370419 |          0.00783515 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.706779956817627\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370442\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-42\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 2.633369149407372e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 217.92519426345825\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7069323062896729\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 217.92519426345825\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370442\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.7043862342834473\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370446\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 297\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-46\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 297\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.4202697277069092\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 203.42937231063843\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.704275369644165\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 203.42937231063843\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370446\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 297\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:40:48 (running for 00:03:48.26)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 2.0/4 CPUs, 2.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=2.543228583817836e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (2 RUNNING, 2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING    | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    287 |          222.392 |   2.54323e-05 |   1666370447 |          0.677284   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | RUNNING    | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    299 |          204.744 |   0.336658    |   1666370448 |          0.679459   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | TERMINATED | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    301 |          202.9   |   3.55413     |   1666370425 |          0.00650501 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | TERMINATED | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    301 |          176.323 | nan           |   1666370419 |          0.00783515 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.8502755165100098\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370448\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 288\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-48\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 288\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 2.5310602723038755e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 223.2419981956482\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.8504517078399658\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 223.2419981956482\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370448\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 288\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.006159782409667969\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370448\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 301\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-48\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   eval_loss: [3.6176059246063232, 3.617302179336548, 3.6168792247772217, 3.6164169311523438,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6158876419067383, 3.6153182983398438, 3.614809989929199, 3.614386558532715, 3.6140146255493164,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.613718032836914, 3.61346435546875, 3.6132495403289795, 3.6130428314208984, 3.612844228744507,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6125848293304443, 3.612299919128418, 3.6119916439056396, 3.6116981506347656, 3.6114501953125,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6112022399902344, 3.6109397411346436, 3.610700845718384, 3.6104869842529297, 3.6103203296661377,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.610114097595215, 3.6099185943603516, 3.6097352504730225, 3.6095521450042725, 3.609362840652466,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.609107732772827, 3.60882830619812, 3.60856556892395, 3.6082751750946045, 3.6079580783843994,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.607616424560547, 3.607262372970581, 3.606874465942383, 3.606473684310913, 3.6060075759887695,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6055469512939453, 3.605087995529175, 3.6046206951141357, 3.6041924953460693, 3.603759527206421,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.60329270362854, 3.602874994277954, 3.602468252182007, 3.602020025253296, 3.6015841960906982,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6011459827423096, 3.6007063388824463, 3.6002614498138428, 3.5998165607452393,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5993754863739014, 3.598907709121704, 3.5984556674957275, 3.5979936122894287, 3.597426652908325,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5968568325042725, 3.5962750911712646, 3.5956926345825195, 3.5951931476593018,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5947229862213135, 3.5940358638763428, 3.5932157039642334, 3.5926246643066406,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5917389392852783, 3.5908219814300537, 3.589866876602173, 3.5888259410858154, 3.5877256393432617,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5866401195526123, 3.5855519771575928, 3.584395408630371, 3.5831851959228516, 3.581970453262329,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.580704927444458, 3.5793111324310303, 3.5778281688690186, 3.5763492584228516, 3.574726104736328,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.572995901107788, 3.571241617202759, 3.569450616836548, 3.567643165588379, 3.565730094909668,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5637271404266357, 3.5615622997283936, 3.5591564178466797, 3.5565803050994873,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5538527965545654, 3.551173210144043, 3.548516035079956, 3.545553207397461, 3.5427017211914062,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5398218631744385, 3.536992311477661, 3.534466028213501, 3.5319929122924805, 3.5292186737060547,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5260493755340576, 3.5219624042510986, 3.517435073852539, 3.5130770206451416, 3.5090272426605225,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5050182342529297, 3.500394821166992, 3.496074676513672, 3.49151349067688, 3.485926628112793,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.48028302192688, 3.4751405715942383, 3.4688539505004883, 3.4630870819091797, 3.4576141834259033,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.450929641723633, 3.4450032711029053, 3.438533067703247, 3.4322011470794678, 3.4248430728912354,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.418229103088379, 3.4112842082977295, 3.404613494873047, 3.3970000743865967, 3.3903439044952393,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.3855180740356445, 3.3802316188812256, 3.3725697994232178, 3.3656609058380127,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.360886812210083, 3.356403112411499, 3.351632833480835, 3.3465206623077393, 3.343432664871216,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.3391354084014893, 3.334216833114624, 3.3309898376464844, 3.326741933822632, 3.323723793029785,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.3211424350738525, 3.318976402282715, 3.317643404006958, 3.3143551349639893, 3.3126027584075928,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.3135321140289307, 3.3097524642944336, 3.3100602626800537, 3.306621551513672, 3.305837392807007,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.305915117263794, 3.302564859390259, 3.3040409088134766, 3.3015689849853516, 3.298513174057007,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.2981061935424805, 3.301187753677368, 3.2973251342773438, 3.299480438232422, 3.300145149230957,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.300391435623169, 3.298804521560669, 3.3009397983551025, 3.3004891872406006, 3.3005526065826416,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.303023338317871, 3.2991275787353516, 3.3078794479370117, 3.303375005722046, 3.306952714920044,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.3062496185302734, 3.310810089111328, 3.308546781539917, 3.3137600421905518, 3.3097543716430664,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.31784987449646, 3.3164970874786377, 3.3204524517059326, 3.322192907333374, 3.3220252990722656,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.3224565982818604, 3.3318097591400146, 3.3240959644317627, 3.3412935733795166,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.3298451900482178, 3.3454816341400146, 3.333502769470215, 3.34841251373291, 3.3451852798461914,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.352031707763672, 3.3520946502685547, 3.3589210510253906, 3.3578693866729736, 3.362988233566284,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.3702878952026367, 3.364503860473633, 3.3748743534088135, 3.37804913520813, 3.3775932788848877,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.3830604553222656, 3.3910939693450928, 3.394026517868042, 3.3920552730560303, 3.394327163696289,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.402315139770508, 3.3985671997070312, 3.4148104190826416, 3.403794527053833, 3.404264450073242,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.408146619796753, 3.4118480682373047, 3.4250895977020264, 3.4176523685455322, 3.413792371749878,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.4160444736480713, 3.4192864894866943, 3.4173078536987305, 3.414752244949341, 3.42069935798645,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.422137975692749, 3.419952630996704, 3.4285850524902344, 3.4240872859954834, 3.43355393409729,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.422435760498047, 3.436833143234253, 3.4361133575439453, 3.4394540786743164, 3.4355685710906982,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.4433724880218506, 3.4520740509033203, 3.449232816696167, 3.458256959915161, 3.453463554382324,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.4651553630828857, 3.4571993350982666, 3.4789602756500244, 3.4526655673980713,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.4730656147003174, 3.449618339538574, 3.482614517211914, 3.4545068740844727, 3.464350700378418,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.473269462585449, 3.4797556400299072, 3.5231688022613525, 3.579580545425415, 3.6109628677368164,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6911163330078125, 3.661217451095581, 3.6305367946624756, 3.6291539669036865, 3.5808942317962646,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5817413330078125, 3.585625410079956, 3.596447706222534, 3.6634304523468018, 3.7021961212158203,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6665165424346924, 3.761820077896118, 3.818387985229492, 3.805161476135254, 3.706510543823242,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6972579956054688, 3.7211360931396484, 3.7905895709991455, 3.8234703540802, 3.8685808181762695,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.8572113513946533, 3.775745391845703, 3.924708366394043, 4.015739440917969, 4.020811080932617,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.9065420627593994, 3.9120047092437744, 3.871569871902466, 3.9674108028411865, 3.849825859069824,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.8069188594818115, 3.8747479915618896, 4.0443806648254395, 4.2337517738342285,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     4.166871547698975, 4.123060703277588, 4.1534223556518555, 4.210752964019775, 4.423672199249268,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     4.184261798858643, 4.203718662261963, 4.287777900695801, 4.296685695648193, 4.339243412017822,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     4.324979305267334, 4.483070373535156, 4.459117412567139, 4.381925106048584, 4.3524489402771,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     4.207973957061768, 4.103523254394531, 4.24761962890625, 4.301328182220459]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: f0f3d09d6cd2441d9691bf615e009229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_tag: 2_batch_size=4,epochs=300,lr=0.0010,momentum=0.9000,tune_run=True\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-example-worker-kkqhv\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 301\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 0.28722986578941345\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   model: \"Sequential(\\n  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\\n  (1):\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\\n \\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\\n  (3): MaxPool2d(kernel_size=2,\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ stride=2, padding=0, dilation=1, ceil_mode=False)\\n  (4): Flatten(start_dim=1,\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ end_dim=-1)\\n  (5): Linear(in_features=6272, out_features=128, bias=True)\\n  (6):\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ ReLU()\\n  (7): Linear(in_features=128, out_features=64, bias=True)\\n  (8): ReLU()\\n\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\  (9): Linear(in_features=64, out_features=37, bias=True)\\n)\"\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.128.2.74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 203\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 205.46794247627258\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.10457015037536621\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 205.46794247627258\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370448\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 301\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_loss: [3.631248712539673, 3.630319595336914, 3.6290876865386963, 3.6277856826782227,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.626603364944458, 3.6256206035614014, 3.624767541885376, 3.6239712238311768, 3.623244524002075,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6225788593292236, 3.6219236850738525, 3.6212263107299805, 3.6205151081085205,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6197798252105713, 3.6190435886383057, 3.6183693408966064, 3.6177194118499756,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6171133518218994, 3.6165761947631836, 3.6160614490509033, 3.615514039993286, 3.614999771118164,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6145095825195312, 3.614046335220337, 3.613576650619507, 3.6130905151367188, 3.6125965118408203,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.61208176612854, 3.611579179763794, 3.6110622882843018, 3.610546827316284, 3.6100213527679443,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.60949444770813, 3.60893177986145, 3.608377456665039, 3.6078338623046875, 3.6072981357574463,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6067349910736084, 3.6061575412750244, 3.605567693710327, 3.6049492359161377, 3.604315996170044,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6037228107452393, 3.6031227111816406, 3.6024999618530273, 3.6018483638763428,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.601167678833008, 3.6004629135131836, 3.599773645401001, 3.599053382873535, 3.5982980728149414,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5975210666656494, 3.5967342853546143, 3.5959112644195557, 3.5950000286102295,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.594090700149536, 3.5931613445281982, 3.592153549194336, 3.5911433696746826, 3.5901362895965576,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5891196727752686, 3.588068723678589, 3.5869596004486084, 3.585693597793579, 3.5843284130096436,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5830256938934326, 3.581639051437378, 3.580169916152954, 3.578650712966919, 3.5770673751831055,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.575349807739258, 3.5735719203948975, 3.5717313289642334, 3.5698039531707764, 3.567768096923828,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5656259059906006, 3.5635032653808594, 3.56111216545105, 3.5586535930633545, 3.5560195446014404,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.553330183029175, 3.550534248352051, 3.54764723777771, 3.544550895690918, 3.541365385055542,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5379998683929443, 3.5344655513763428, 3.530761480331421, 3.526923179626465, 3.5230424404144287,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5188639163970947, 3.5145013332366943, 3.509718179702759, 3.504781484603882, 3.499661684036255,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.4940407276153564, 3.4881303310394287, 3.48122239112854, 3.4741315841674805, 3.4673454761505127,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.4601619243621826, 3.452643394470215, 3.4448368549346924, 3.4368896484375, 3.4283218383789062,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.4193875789642334, 3.410618782043457, 3.4017302989959717, 3.392155647277832, 3.382192611694336,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.371382713317871, 3.3601553440093994, 3.3486855030059814, 3.336740493774414, 3.3244311809539795,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.31194806098938, 3.299499273300171, 3.2859232425689697, 3.272934913635254, 3.259220838546753,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.24576735496521, 3.2319374084472656, 3.2176220417022705, 3.2028276920318604, 3.1881637573242188,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.173567771911621, 3.1593828201293945, 3.1441214084625244, 3.1301920413970947, 3.114408493041992,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.0992209911346436, 3.0842387676239014, 3.0660245418548584, 3.0490243434906006,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.0353620052337646, 3.0198593139648438, 3.002232313156128, 2.984668731689453, 2.966900587081909,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.950948476791382, 2.9333581924438477, 2.915985345840454, 2.8986644744873047, 2.8805723190307617,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.865165948867798, 2.84350848197937, 2.8281757831573486, 2.806324005126953, 2.787426233291626,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.7680728435516357, 2.7458059787750244, 2.730454206466675, 2.707275152206421, 2.6889591217041016,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.6648104190826416, 2.648491621017456, 2.6245696544647217, 2.60498046875, 2.583702325820923,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.5611722469329834, 2.542175531387329, 2.5195140838623047, 2.4978532791137695, 2.4762656688690186,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.4559121131896973, 2.4316701889038086, 2.411912441253662, 2.3856570720672607, 2.364175319671631,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.342669725418091, 2.319195508956909, 2.294377088546753, 2.272667646408081, 2.2514119148254395,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.226322889328003, 2.19991397857666, 2.184657096862793, 2.156050682067871, 2.1357624530792236,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.1104347705841064, 2.0955421924591064, 2.062937021255493, 2.041640043258667, 2.0185422897338867,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     1.996544361114502, 1.9701958894729614, 1.9506596326828003, 1.9203696250915527, 1.905800700187683,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     1.8753482103347778, 1.8546885251998901, 1.8263154029846191, 1.8113627433776855,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     1.7792730331420898, 1.7617064714431763, 1.7352334260940552, 1.719530701637268, 1.7002549171447754,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     1.6741946935653687, 1.6620608568191528, 1.630354881286621, 1.614394187927246, 1.5834441184997559,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     1.5705596208572388, 1.5377187728881836, 1.5251072645187378, 1.4957104921340942,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     1.4772791862487793, 1.4500794410705566, 1.4395776987075806, 1.4037669897079468,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     1.3800808191299438, 1.3525667190551758, 1.3324933052062988, 1.3055957555770874,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     1.2849388122558594, 1.2584000825881958, 1.2377642393112183, 1.2179819345474243,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     1.1870640516281128, 1.1748143434524536, 1.1452683210372925, 1.1293517351150513,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     1.1087745428085327, 1.0881826877593994, 1.0620520114898682, 1.0429788827896118,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     1.022107720375061, 1.0034691095352173, 0.9856181144714355, 0.9652147889137268, 0.9474225044250488,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.9287397265434265, 0.9115593433380127, 0.901354968547821, 0.8771976828575134, 0.8627203106880188,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.8462998270988464, 0.8334707617759705, 0.8191468119621277, 0.8071966171264648,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.7984981536865234, 0.8087043762207031, 0.8089733719825745, 0.8143470883369446,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.8072199821472168, 0.7618206143379211, 0.7474806308746338, 0.7289078831672668,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.7163675427436829, 0.7013764977455139, 0.6819510459899902, 0.6724379658699036,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.662330150604248, 0.677442729473114, 0.6610268950462341, 0.6227098107337952, 0.6648948192596436,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.7204843163490295, 0.6882535815238953, 0.6226696968078613, 0.5565047860145569,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.5803950428962708, 0.5831292271614075, 0.5792755484580994, 0.5806897282600403,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.6160352826118469, 0.5871903300285339, 0.5746813416481018, 0.6238992810249329,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.5612285733222961, 0.5758805871009827, 0.5904039144515991, 0.5126598477363586,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.4463883936405182, 0.46488332748413086, 0.4521690607070923, 0.4452557861804962,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.4730893671512604, 0.4934566915035248, 0.4825470447540283, 0.5109263062477112,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.5059234499931335, 0.47076740860939026, 0.5228945016860962, 0.46364691853523254,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.5224186778068542, 0.4998190402984619, 0.4275762736797333, 0.41842520236968994,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.3970002233982086, 0.41403183341026306, 0.4437693655490875, 0.3483794629573822,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.3937811553478241, 0.39180251955986023, 0.4202697277069092, 0.3598477840423584,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.33665814995765686, 0.28722986578941345]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.003940105438232422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.749222993850708\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370453\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 295\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-53\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 295\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 2.43371760006994e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 228.40019989013672\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.7489547729492188\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 228.40019989013672\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370453\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 295\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:40:53 (running for 00:03:53.67)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.3/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 1.0/4 CPUs, 1.0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=2.43371760006994e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (1 RUNNING, 3 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | RUNNING    | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    295 |          228.4   |   2.43372e-05 |   1666370453 |          0.749223   |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | TERMINATED | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    301 |          202.9   |   3.55413     |   1666370425 |          0.00650501 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | TERMINATED | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    301 |          205.468 |   0.28723     |   1666370448 |          0.00615978 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | TERMINATED | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    301 |          176.323 | nan           |   1666370419 |          0.00783515 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result for TorchTrainer_959ff_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _time_this_iter_s: 0.00613713264465332\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _timestamp: 1666370457\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   _training_iteration: 301\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   date: 2022-10-21_16-40-57\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   eval_loss: [3.6076581478118896, 3.6049864292144775, 3.602682113647461, 3.5996997356414795,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5961644649505615, 3.59224534034729, 3.5854053497314453, 3.579758405685425, 3.568527936935425,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.555833101272583, 3.53645396232605, 3.5024640560150146, 3.5237834453582764, 3.467219591140747,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.4428718090057373, 3.437040328979492, 3.4306719303131104, 3.38799786567688, 3.393324613571167,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.373242139816284, 3.362659215927124, 3.390883684158325, 3.393059492111206, 3.331707000732422,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.323009490966797, 3.3688714504241943, 3.3674373626708984, 3.364130735397339, 3.454437017440796,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.3575313091278076, 3.379197359085083, 3.3849689960479736, 3.487652063369751, 3.495694398880005,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.4506969451904297, 3.399152994155884, 3.4981746673583984, 3.4972705841064453, 3.6957530975341797,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5383222103118896, 3.5528764724731445, 3.538264036178589, 3.48840069770813, 3.3944692611694336,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.5489580631256104, 3.5602118968963623, 3.5409395694732666, 3.553705930709839, 3.6644484996795654,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6116459369659424, 3.705113649368286, 3.7710015773773193, 3.7822999954223633, 3.834083318710327,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     4.007410049438477, 4.093047142028809, 4.352964401245117, 4.216487884521484, 4.214015960693359,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     4.433212757110596, 4.188115119934082, 4.499176979064941, 5.1142048835754395, 4.453613758087158,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     4.774425029754639, 4.465603351593018, 5.0989251136779785, 4.940608501434326, 5.24452018737793,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     5.713540554046631, 6.009340763092041, 5.46636962890625, 5.531931400299072, 6.016973495483398,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     5.998735427856445, 6.27696418762207, 6.4588446617126465, 6.281433582305908, 7.02882194519043,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     7.093342304229736, 7.381404399871826, 7.809150695800781, 7.94288444519043, 8.100130081176758,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     8.39403247833252, 8.664393424987793, 8.817248344421387, 8.981915473937988, 9.124826431274414,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     9.26465892791748, 9.402132987976074, 9.520319938659668, 9.643158912658691, 9.744762420654297,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     9.848457336425781, 9.940577507019043, 10.034834861755371, 10.12254524230957, 10.199735641479492,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     10.285048484802246, 10.358548164367676, 10.430420875549316, 10.498151779174805,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     10.558929443359375, 10.626739501953125, 10.68355655670166, 10.745849609375, 10.794021606445312,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     10.849799156188965, 10.903426170349121, 10.947616577148438, 11.001605987548828,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     11.046993255615234, 11.096076965332031, 11.133706092834473, 11.179787635803223,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     11.223053932189941, 11.260918617248535, 11.3014554977417, 11.337065696716309, 11.37421703338623,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     11.412280082702637, 11.454195976257324, 11.485485076904297, 11.519501686096191,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     11.55307674407959, 11.58916187286377, 11.62003231048584, 11.652365684509277, 11.684218406677246,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     11.714434623718262, 11.744853019714355, 11.772018432617188, 11.801789283752441,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     11.828681945800781, 11.857773780822754, 11.883101463317871, 11.909276008605957,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     11.935099601745605, 11.962557792663574, 11.984953880310059, 12.007781982421875,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     12.036407470703125, 12.057515144348145, 12.081748008728027, 12.104517936706543,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     12.12807846069336, 12.150578498840332, 12.17162036895752, 12.194580078125, 12.215834617614746,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     12.237198829650879, 12.258885383605957, 12.277584075927734, 12.2991361618042, 12.319668769836426,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     12.338905334472656, 12.356647491455078, 12.37719440460205, 12.395792961120605, 12.41688060760498,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     12.435036659240723, 12.451905250549316, 12.470561027526855, 12.489208221435547,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     12.50732135772705, 12.523850440979004, 12.5388765335083, 12.557526588439941, 12.57651138305664,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     12.59308910369873, 12.609176635742188, 12.625717163085938, 12.64100170135498, 12.6563081741333,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     12.675057411193848, 12.688899040222168, 12.70407485961914, 12.718452453613281, 12.73635482788086,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     12.750568389892578, 12.76650333404541, 12.780200004577637, 12.794445991516113, 12.809218406677246,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     12.8242769241333, 12.83785629272461, 12.85109806060791, 12.866371154785156, 12.878874778747559,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     12.894299507141113, 12.907673835754395, 12.921489715576172, 12.935005187988281,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     12.949374198913574, 12.960888862609863, 12.974963188171387, 12.986372947692871,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.001219749450684, 13.011616706848145, 13.024517059326172, 13.037657737731934,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.05078125, 13.06265926361084, 13.075592041015625, 13.087203979492188, 13.099384307861328,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.11235523223877, 13.12283706665039, 13.134666442871094, 13.145923614501953, 13.158331871032715,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.170005798339844, 13.179859161376953, 13.193130493164062, 13.204453468322754,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.215176582336426, 13.227473258972168, 13.237462043762207, 13.249408721923828,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.2598876953125, 13.271313667297363, 13.280521392822266, 13.292889595031738, 13.302326202392578,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.314068794250488, 13.323819160461426, 13.335070610046387, 13.344818115234375,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.35582447052002, 13.365734100341797, 13.375397682189941, 13.38504695892334, 13.395686149597168,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.405314445495605, 13.415175437927246, 13.425250053405762, 13.435004234313965,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.444485664367676, 13.45512866973877, 13.463360786437988, 13.473941802978516, 13.48386001586914,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.492210388183594, 13.502922058105469, 13.511405944824219, 13.52111530303955, 13.53070068359375,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.539036750793457, 13.5483980178833, 13.557854652404785, 13.566685676574707, 13.574405670166016,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.583996772766113, 13.592826843261719, 13.601956367492676, 13.609662055969238,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.618419647216797, 13.627213478088379, 13.636597633361816, 13.644157409667969,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.65267276763916, 13.660594940185547, 13.669034004211426, 13.677230834960938, 13.687081336975098,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.694071769714355, 13.702086448669434, 13.710295677185059, 13.718955993652344,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.726250648498535, 13.734576225280762, 13.742523193359375, 13.75082015991211, 13.758421897888184,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.766095161437988, 13.773756980895996, 13.781840324401855, 13.78902816772461, 13.796347618103027,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.804574012756348, 13.811664581298828, 13.820021629333496, 13.82669734954834, 13.8341646194458,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.842440605163574, 13.848742485046387, 13.856712341308594, 13.864060401916504,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.872117042541504, 13.879618644714355, 13.88530445098877, 13.892897605895996, 13.901572227478027,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.907634735107422, 13.91440200805664, 13.921319007873535, 13.928451538085938, 13.935772895812988,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     13.94250202178955]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_id: a7aa286c85cb46a7b07903e029b4f86f\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   experiment_tag: 1_batch_size=4,epochs=300,lr=0.1000,momentum=0.1000,tune_run=True\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   hostname: octo-next-eje-ray-cluster-octo-next-eje-head-4zdvg\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   iterations_since_restore: 301\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   loss: 2.3659247744944878e-05\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   model: \"Sequential(\\n  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\\n  (1):\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\\n \\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\\n  (3): MaxPool2d(kernel_size=2,\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ stride=2, padding=0, dilation=1, ceil_mode=False)\\n  (4): Flatten(start_dim=1,\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ end_dim=-1)\\n  (5): Linear(in_features=6272, out_features=128, bias=True)\\n  (6):\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\ ReLU()\\n  (7): Linear(in_features=128, out_features=64, bias=True)\\n  (8): ReLU()\\n\\\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     \\  (9): Linear(in_features=64, out_features=37, bias=True)\\n)\"\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   node_ip: 10.131.2.239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   pid: 3300\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_since_restore: 232.40679740905762\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_this_iter_s: 0.10230398178100586\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   time_total_s: 232.40679740905762\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timestamp: 1666370457\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_iteration: 301\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   training_loss: [3.625131607055664, 3.6157867908477783, 3.6097753047943115, 3.6031076908111572,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.597736120223999, 3.5902421474456787, 3.582228660583496, 3.570711851119995, 3.5587093830108643,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.537020444869995, 3.5092151165008545, 3.4670658111572266, 3.443098783493042, 3.363072156906128,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.323641061782837, 3.3771800994873047, 3.2514865398406982, 3.201686143875122, 3.154627799987793,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.087362051010132, 3.0301132202148438, 3.0292367935180664, 2.9036357402801514, 2.8767430782318115,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.7932374477386475, 2.7178399562835693, 2.6674015522003174, 2.5829906463623047,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.4915010929107666, 2.8225886821746826, 2.3868889808654785, 2.2643206119537354,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.152777910232544, 2.0521256923675537, 2.055961847305298, 1.8853754997253418, 1.7738820314407349,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     1.6218072175979614, 1.5308762788772583, 1.5080351829528809, 1.3169845342636108,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     1.2334294319152832, 1.0923131704330444, 1.3680506944656372, 0.8693534731864929,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.7790474891662598, 0.7071215510368347, 0.6224160194396973, 0.633106529712677, 0.5802851319313049,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.453716903924942, 0.5369800925254822, 0.3948271572589874, 0.4348315894603729, 0.32225775718688965,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.38084837794303894, 0.2715679407119751, 0.3102046251296997, 0.5964787602424622,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.30575037002563477, 0.5141883492469788, 0.2688157558441162, 0.14232207834720612,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.27065834403038025, 0.48659905791282654, 0.2641623914241791, 0.10699243098497391,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.06764230132102966, 0.5292174816131592, 0.0732932910323143, 0.05147375538945198,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     1.5475716590881348, 0.1553056687116623, 0.05346320942044258, 0.019649727270007133,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.01502575259655714, 0.07483161240816116, 0.03453889861702919, 0.012024848721921444,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.009788472205400467, 0.005247452761977911, 0.00571039505302906, 0.003990244586020708,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.00340349436737597, 0.002408049302175641, 0.001999984262511134, 0.0016177479410544038,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.0013525974936783314, 0.0012271635932847857, 0.0010811444371938705, 0.0009965540375560522,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.0008143160375766456, 0.0007548881112597883, 0.0006900814478285611, 0.0006146321538835764,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.0005682625924237072, 0.0005333567969501019, 0.0004964990657754242, 0.00046240154188126326,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.0004362060863059014, 0.00041317826253362, 0.0003881746670231223, 0.0003735373029485345,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.0003548564563971013, 0.00033331799204461277, 0.00032363258651457727, 0.0003096744476351887,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.0002966497268062085, 0.00028178899083286524, 0.0002719713666010648, 0.0002604949695523828,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.00024992009275592864, 0.00024177176237571985, 0.00023324672656599432, 0.00022466857626568526,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.00021738240320701152, 0.00020968627359252423, 0.0002030619070865214, 0.0001965834671864286,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.00019063579384237528, 0.00018452928634360433, 0.00017943257989827543, 0.00017333329014945775,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.00016792376118246466, 0.00016335265536326915, 0.00015960501332301646, 0.00015506625641137362,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.00015082462050486356, 0.00014727596135344356, 0.00014350087440107018, 0.00014087502495385706,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.00013678993855137378, 0.0001337869034614414, 0.00013034677249379456, 0.00012779756798408926,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.000124675381812267, 0.00012173171126050875, 0.00011917009396711364, 0.00011705281212925911,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.00011439443187555298, 0.00011176833504578099, 0.00010950463911285624, 0.0001072953746188432,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     0.00010575880151009187, 0.00010362904868088663, 0.00010140497033717111, 9.973927080864087e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     9.78575917542912e-05, 9.600831981515512e-05, 9.439478162676096e-05, 9.2535417934414e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     9.11179231479764e-05, 8.945476292865351e-05, 8.843941031955183e-05, 8.657258149469271e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     8.511538180755451e-05, 8.40901120682247e-05, 8.250628161476925e-05, 8.13245351309888e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     8.011559111764655e-05, 7.875017035985366e-05, 7.756346167298034e-05, 7.646866288268939e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     7.557984645245597e-05, 7.427154923789203e-05, 7.319160795304924e-05, 7.230777555378154e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     7.101684605004266e-05, 7.018759060883895e-05, 6.94303453201428e-05, 6.838760600658134e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     6.733991176588461e-05, 6.655784090980887e-05, 6.574598955921829e-05, 6.48075292701833e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     6.391871283994988e-05, 6.318130908766761e-05, 6.226520781638101e-05, 6.157000461826101e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     6.0849979490740225e-05, 6.010516153764911e-05, 5.948691614321433e-05, 5.8503737818682566e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     5.7845802075462416e-05, 5.7379027566639706e-05, 5.659444650518708e-05, 5.600103395408951e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     5.530087582883425e-05, 5.467022128868848e-05, 5.4200965678319335e-05, 5.368202619138174e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     5.307620085659437e-05, 5.24083043274004e-05, 5.190428055357188e-05, 5.1434984925435856e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     5.077703463030048e-05, 5.0402104534441605e-05, 4.988815271644853e-05, 4.934685057378374e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     4.876586899627e-05, 4.82643190480303e-05, 4.786206773133017e-05, 4.7511959564872086e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     4.694337258115411e-05, 4.6533667045878246e-05, 4.609170719049871e-05, 4.571181125356816e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     4.5240038161864504e-05, 4.485517638386227e-05, 4.431388879311271e-05, 4.403083221404813e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     4.3623611418297514e-05, 4.327845817897469e-05, 4.285635441192426e-05, 4.240941416355781e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     4.205929872114211e-05, 4.171664113528095e-05, 4.145095226704143e-05, 4.095435360795818e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     4.0696115320315585e-05, 4.0346010791836306e-05, 3.996610394096933e-05, 3.962343907915056e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.926091085304506e-05, 3.8977839722065255e-05, 3.866497354465537e-05, 3.831486537819728e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.800696140388027e-05, 3.770899274968542e-05, 3.74010851373896e-05, 3.714036938617937e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.6765421100426465e-05, 3.651214865385555e-05, 3.618189657572657e-05, 3.5988210584037006e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.568527245079167e-05, 3.539474346325733e-05, 3.50918089679908e-05, 3.4850942029152066e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.4642365790205076e-05, 3.4264932764926925e-05, 3.407869371585548e-05, 3.382542126928456e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.356717206770554e-05, 3.333375934744254e-05, 3.309786188765429e-05, 3.28346504829824e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.2611165806883946e-05, 3.2405067031504586e-05, 3.2136886147782207e-05, 3.188857590430416e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.168992043356411e-05, 3.148630275973119e-05, 3.1307514291256666e-05, 3.1026913347886875e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.0845647415844724e-05, 3.0634582799393684e-05, 3.0403642085730098e-05, 3.0207476811483502e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     3.002619450853672e-05, 2.9792783607263118e-05, 2.962889448099304e-05, 2.9430242648231797e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.926882734755054e-05, 2.90329335257411e-05, 2.8891385227325372e-05, 2.87150851363549e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.849408338079229e-05, 2.8350053980830126e-05, 2.8191125238663517e-05, 2.7962678359472193e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.7793817935162224e-05, 2.7692005460266955e-05, 2.7500798751134425e-05, 2.7302143280394375e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.7120871891384013e-05, 2.697435957088601e-05, 2.6860134312300943e-05, 2.6629191779647954e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.652489820320625e-05, 2.633369149407372e-05, 2.6159867047681473e-05, 2.60034194070613e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.5891675250022672e-05, 2.5725299565237947e-05, 2.5616036509745754e-05, 2.543228583817836e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.5310602723038755e-05, 2.5141745936707594e-05, 2.498529829608742e-05, 2.4858652977854945e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.469476021360606e-05, 2.459543065924663e-05, 2.4471270080539398e-05, 2.43371760006994e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.4170798496925272e-05, 2.4054088498814963e-05, 2.3922473701532e-05, 2.37759650190128e-05,\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m     2.3659247744944878e-05]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   trial_id: 959ff_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   warmup_time: 0.0034494400024414062\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=3336)\u001b[0m E1021 16:40:57.462303904    3364 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current time: 2022-10-21 16:40:58 (running for 00:03:58.55)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Memory usage on this node: 8.2/30.9 GiB\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Resources requested: 0/4 CPUs, 0/4 GPUs, 0.0/16.8 GiB heap, 0.0/7.01 GiB objects\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Current best trial: 959ff_00001 with loss=2.3659247744944878e-05 and parameters={'train_loop_config': {'lr': 0.1, 'momentum': 0.1, 'batch_size': 4, 'epochs': 300, 'tune_run': True}}\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Result logdir: /home/ray/test_run\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m Number of trials: 4/4 (4 TERMINATED)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | Trial name               | status     | loc               |   train_loop_config... |   train_loop_config... |   train_loop_config/lr |   train_loop_config... | train_loop_config...   |   iter |   total time (s) |          loss |   _timestamp |   _time_this_iter_s |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m |--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------|\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00000 | TERMINATED | 10.128.4.70:213   |                      4 |                    300 |                  0.001 |                    0.1 | True                   |    301 |          202.9   |   3.55413     |   1666370425 |          0.00650501 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00001 | TERMINATED | 10.131.2.239:3300 |                      4 |                    300 |                  0.1   |                    0.1 | True                   |    301 |          232.407 |   2.36592e-05 |   1666370457 |          0.00613713 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00002 | TERMINATED | 10.128.2.74:203   |                      4 |                    300 |                  0.001 |                    0.9 | True                   |    301 |          205.468 |   0.28723     |   1666370448 |          0.00615978 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m | TorchTrainer_959ff_00003 | TERMINATED | 10.129.4.218:203  |                      4 |                    300 |                  0.1   |                    0.9 | True                   |    301 |          176.323 | nan           |   1666370419 |          0.00783515 |\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m +--------------------------+------------+-------------------+------------------------+------------------------+------------------------+------------------------+------------------------+--------+------------------+---------------+--------------+---------------------+\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=3234)\u001b[0m 2022-10-21 16:40:58,411\tINFO tune.py:758 -- Total run time: 238.68 seconds (237.78 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "result_grid = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa6e0ef6-0e23-4e95-b382-8eec8e995c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = result_grid.get_best_result()\n",
    "best_model = best_result.metrics[\"model\"]\n",
    "model_scripted = torch.jit.script(best_model)\n",
    "model_scripted.save('models/best_model_scripted.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff6893b8-d5ed-4822-a175-baca00e4defc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(best_result.metrics[\"training_loss\"])\n",
    "plt.plot(best_result.metrics[\"eval_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c79cdfe-76ec-4353-acb2-63f26146fc6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=Sequential\n",
       "  (0): RecursiveScriptModule(original_name=Conv2d)\n",
       "  (1): RecursiveScriptModule(original_name=MaxPool2d)\n",
       "  (2): RecursiveScriptModule(original_name=Conv2d)\n",
       "  (3): RecursiveScriptModule(original_name=MaxPool2d)\n",
       "  (4): RecursiveScriptModule(original_name=Flatten)\n",
       "  (5): RecursiveScriptModule(original_name=Linear)\n",
       "  (6): RecursiveScriptModule(original_name=ReLU)\n",
       "  (7): RecursiveScriptModule(original_name=Linear)\n",
       "  (8): RecursiveScriptModule(original_name=ReLU)\n",
       "  (9): RecursiveScriptModule(original_name=Linear)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.jit.load(\"models/best_model_scripted.pt\") \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c587d6b-2c52-4e7b-b1f5-71ab89c74cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:0\n",
      "prediction: 0\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(data_loader))\n",
    "make = ToPILImage()\n",
    "make(train_features[0]).show()\n",
    "print(f'label:{train_labels[0]}')\n",
    "logits = model(train_features[0].reshape(1,3,64,64).to(device))\n",
    "print(f\"prediction: {torch.argmax(logits).item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2e9df11-84a1-4600-a2fb-e3c614629706",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "y_pred = []\n",
    "\n",
    "for data in valid_dataset.iter_rows():\n",
    "    X.append(data[0])\n",
    "    y.append(data[1])\n",
    "    logit = model(data[0].reshape(1,3,64,64))\n",
    "    y_pred.append(torch.argmax(logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4bea5b8-197b-4c8e-a63a-2b74472889eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.02      0.02        52\n",
      "           1       0.07      0.06      0.07        47\n",
      "           2       0.02      0.02      0.02        46\n",
      "           3       0.11      0.09      0.10        53\n",
      "           4       0.04      0.04      0.04        51\n",
      "           5       0.04      0.04      0.04        54\n",
      "           6       0.10      0.08      0.09        51\n",
      "           7       0.23      0.18      0.20        50\n",
      "           8       0.06      0.05      0.06        56\n",
      "           9       0.04      0.04      0.04        46\n",
      "          10       0.06      0.06      0.06        48\n",
      "          11       0.15      0.12      0.13        50\n",
      "          12       0.02      0.02      0.02        44\n",
      "          13       0.05      0.10      0.07        40\n",
      "          14       0.12      0.19      0.14        43\n",
      "          15       0.08      0.05      0.06        61\n",
      "          16       0.00      0.00      0.00        50\n",
      "          17       0.07      0.05      0.06        59\n",
      "          18       0.10      0.07      0.08        54\n",
      "          19       0.09      0.12      0.11        48\n",
      "          20       0.07      0.08      0.08        48\n",
      "          21       0.08      0.06      0.07        54\n",
      "          22       0.17      0.15      0.16        53\n",
      "          23       0.15      0.15      0.15        55\n",
      "          24       0.08      0.13      0.10        39\n",
      "          25       0.04      0.09      0.06        46\n",
      "          26       0.00      0.00      0.00        52\n",
      "          27       0.04      0.04      0.04        45\n",
      "          28       0.11      0.10      0.11        50\n",
      "          29       0.15      0.11      0.13        55\n",
      "          30       0.14      0.13      0.13        47\n",
      "          31       0.08      0.06      0.07        51\n",
      "          32       0.08      0.06      0.07        51\n",
      "          33       0.00      0.00      0.00        46\n",
      "          34       0.02      0.02      0.02        47\n",
      "          35       0.10      0.10      0.10        48\n",
      "          36       0.12      0.12      0.12        50\n",
      "\n",
      "    accuracy                           0.08      1840\n",
      "   macro avg       0.08      0.08      0.08      1840\n",
      "weighted avg       0.08      0.08      0.08      1840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a89e32c3-4e21-411a-9ded-ff04be4aa456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(confusion_matrix(y_pred,y), cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c807e572-428a-436e-99d5-a73a19943a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 7.6%\n",
      "Random guess would yield 2.7%\n",
      "Model outperforms Random chance by a factor of 2.80\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {np.sum(np.array(y_pred)==np.array(y))/(len(y))*100:.1f}%\")\n",
    "print(f\"Random guess would yield {(1/37)*100:.1f}%\")\n",
    "print(f\"Model outperforms Random chance by a factor of {(np.sum(np.array(y_pred)==np.array(y))/len(y))/(1/37):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48739528-a5a4-4ba1-b3fa-c8e7ad669bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_ray_cluster()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
