{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "780e098e-f3e5-4333-bbe5-e0e9652084a7",
   "metadata": {},
   "source": [
    "adapted from:\n",
    "https://docs.ray.io/en/latest/train/examples/train_fashion_mnist_example.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7f8d42c-b410-4474-8b4d-0f5b7604ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture pip_outputs\n",
    "%pip install --upgrade python-dotenv openshift-client\n",
    "%pip uninstall --yes pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aebd3b6-35c5-4ec3-91c4-11937731c895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Minimal\n"
     ]
    }
   ],
   "source": [
    "%xmode Minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21c545ec-efa1-4414-a70a-60c188b1876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.modules.utils import consume_prefix_in_state_dict_if_present\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Resize,Compose, ToPILImage\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import ray\n",
    "from ray import train\n",
    "from ray import tune\n",
    "import ray.train.torch\n",
    "from ray.train import Trainer\n",
    "from ray.train import CheckpointStrategy\n",
    "from ray.data.datasource import SimpleTorchDatasource\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ray_cluster_control import start_ray_cluster, stop_ray_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a964830-20ac-495d-bde2-7789058b40e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RayCluster octo-next-2022 has started\n"
     ]
    }
   ],
   "source": [
    "start_ray_cluster(cluster_name = 'octo-next-2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da37bdab-4c2c-488d-8358-9791bbe78866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'octo-next-2022'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv('RAY_CLUSTER_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12c98cef-f712-460a-a012-e49c07c9bff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-11 00:24:33,935\tWARNING dataclient.py:363 -- Encountered connection issues in the data channel. Attempting to reconnect.\n",
      "2022-09-11 00:24:40,012\tERROR dataclient.py:290 -- Unrecoverable error in data channel.\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "Request can't be sent because the Ray client has already been disconnected due to an error. Last exception: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"Attempted to reconnect a session that has already been cleaned up\"\n\tdebug_error_string = \"{\"created\":\"@1662855880.012452796\",\"description\":\"Error received from peer ipv4:172.30.148.144:10001\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1074,\"grpc_message\":\"Attempted to reconnect a session that has already been cleaned up\",\"grpc_status\":5}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31mConnectionError\u001b[0m\u001b[0;31m:\u001b[0m Request can't be sent because the Ray client has already been disconnected due to an error. Last exception: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"Attempted to reconnect a session that has already been cleaned up\"\n\tdebug_error_string = \"{\"created\":\"@1662855880.012452796\",\"description\":\"Error received from peer ipv4:172.30.148.144:10001\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1074,\"grpc_message\":\"Attempted to reconnect a session that has already been cleaned up\",\"grpc_status\":5}\"\n>\n"
     ]
    }
   ],
   "source": [
    "ray.init('ray://{ray_head}-ray-head:10001'.format(ray_head=os.environ['RAY_CLUSTER_NAME']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd59423b-a089-4375-b60a-0370be835b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_ray_cluster(cluster_name = 'octo-next-2022')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "408890d9-bee1-4045-8fe6-c8aea4a1119b",
   "metadata": {},
   "source": [
    "transforms = Compose([Resize((64,64)), ToTensor()])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "049bd7a8-9703-4f72-89dc-40f204af3c3b",
   "metadata": {},
   "source": [
    "pet_data = torchvision.datasets.OxfordIIITPet(\n",
    "    \"data/\",\n",
    "    download = True,\n",
    "    target_types = \"category\",\n",
    "    transform = transforms,\n",
    "    split = \"trainval\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c90710a-eed2-4bd2-894b-543a9e42cd57",
   "metadata": {},
   "source": [
    "data_loader = torch.utils.data.DataLoader(pet_data, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d38dc-8c47-4bad-914a-848d7253e278",
   "metadata": {},
   "source": [
    "This data set is only 3K and not the full 7k since we read in dataset with the `split` parameters that pulls in the files based on the corresponding txt file in `data/data/oxford-iiit-pet/annotations`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd73a209-750f-4bfc-b53e-e7ac3efdb119",
   "metadata": {},
   "source": [
    "len(pet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6556aa-a289-4362-b1f3-cd6b475bed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "dafb5a67-5366-476e-bacb-140fab9ebd15",
   "metadata": {},
   "source": [
    "train_features, train_labels = next(iter(data_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "make = ToPILImage()\n",
    "make(train_features[0]).show()\n",
    "print(f'label:{train_labels[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f12df06-28d4-434a-b26e-9e7ea19a1f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3,1 )\n",
    "        \n",
    "        self.fc1 = nn.Linear(6272 , 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 37)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool((self.conv1(x)))\n",
    "        x = self.pool((self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        y_pred = self.fc3(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0018d8ea-40bb-410e-9002-50a40d80de20",
   "metadata": {},
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0fae8a3-33c3-4399-b1ba-17d068a60cc5",
   "metadata": {},
   "source": [
    "def train_x(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e90ff7-b3f0-4bcc-8488-e09e7839f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now with Ray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15475bd5-e2f1-4a9b-894e-f7e238a72928",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_factory = lambda: torchvision.datasets.OxfordIIITPet(\n",
    "    \"data/\",\n",
    "    download = True,\n",
    "    target_types = \"category\",\n",
    "    transform = transforms,\n",
    "    split = \"trainval\")\n",
    "\n",
    "dataset = ray.data.read_datasource(\n",
    "    SimpleTorchDatasource(),\n",
    "    parallelism=1,\n",
    "    dataset_factory=dataset_factory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cfb5e4-95b3-4e85-be75-53a2bd317cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.random_shuffle().repartition(2).split(2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b3572-75e5-48ac-b1ef-8e3c474c5ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = x[0]\n",
    "test_data = x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6c5c42-ece5-4198-8eb3-970d2d0e0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, loss_fn, optim):\n",
    "    model.train()\n",
    "    model.to(\"cuda\")\n",
    "    for batch_idx, data in enumerate(dataloader.iter_batches()):\n",
    "        X = [x[0] for x in data]\n",
    "        X = torch.stack(X)\n",
    "        X = X.to(\"cuda\")\n",
    "        y = [torch.tensor(x[1]) for x in data]\n",
    "        y = torch.stack(y)\n",
    "        y = y.to(\"cuda\") \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        #backprop\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3567ad82-a201-47a6-a961-a2a8b029771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader.iter_batches():\n",
    "            X = [x[0] for x in data]\n",
    "            X = torch.stack(X)\n",
    "            X = X.to(\"cuda\")\n",
    "            y = [torch.tensor(x[1]) for x in data]\n",
    "            y = torch.stack(y)\n",
    "            y = y.to(\"cuda\")\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()  \n",
    "    \n",
    "    return test_loss/dataloader.num_blocks() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c256a8bb-c418-44de-9831-7498b775ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a search space.\n",
    "search_space = {\n",
    "    \"lr\": tune.grid_search([0.001, 0.1]),\n",
    "    \"momentum\": tune.grid_search([0.1, 0.9]),\n",
    "    \"batch_size\": tune.grid_search([4]), \n",
    "    \"epochs\": tune.grid_search([300]),\n",
    "    \"tune_run\": tune.grid_search([True])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa741303-79e6-4cfe-9813-9d58dbc5e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(config):\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    lr = config[\"lr\"]\n",
    "    epochs = config[\"epochs\"]\n",
    "    momentum = config[\"momentum\"]\n",
    "    tune_run = config[\"tune_run\"]\n",
    "    \n",
    "    train_dataloader = train_data\n",
    "    test_dataloader = test_data\n",
    "    model = ConvNet()\n",
    "    #model = train.torch.prepare_model(model)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr,  momentum=momentum)\n",
    "    \n",
    "    loss_results = []\n",
    "    eval_results = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        loss = train_epoch(train_dataloader, model, loss_fn, optimizer)\n",
    "        val_loss = validate_epoch(test_dataloader, model, loss_fn)\n",
    "        #train.report(loss=val_loss)\n",
    "        loss_results.append(loss)\n",
    "        eval_results.append(val_loss)\n",
    "        if not tune_run:\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"epoch:{epoch}  loss {loss:>7f}\")\n",
    "                print(f\"eval loss: {val_loss:>7f}\")    \n",
    "\n",
    "            if epoch == epochs-1:\n",
    "                state_dict = model.state_dict()\n",
    "                consume_prefix_in_state_dict_if_present(state_dict, \"module.\")\n",
    "                train.save_checkpoint(epoch=epochs, model_weights=state_dict)\n",
    "    \n",
    "    if tune_run:\n",
    "        tune.report(loss=loss)\n",
    "    \n",
    "    return loss_results, eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255b7e0e-ce32-4476-9eec-efec7db4a32f",
   "metadata": {},
   "source": [
    "### Tune! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1336b4f7-96e0-4ff7-8353-d57a332dee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    tune.with_parameters(train_func),\n",
    "    config=search_space,\n",
    "    resources_per_trial={'gpu': 1})\n",
    "\n",
    "print(analysis.get_best_config(metric=\"loss\", mode=\"min\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c186af47-a33d-4d43-b171-1c846f568d8e",
   "metadata": {},
   "source": [
    "### Now that we know best param, we'll train and save our model. This prevents us from saving N model trails that we'll need to deleted later.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a347f13-53b5-4edf-b9b5-ee8cdac5e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if os.environ.get('RAY_CLUSTER_NAME') is not None:\n",
    "    num_workers = 2\n",
    "else:\n",
    "    num_workers = 1\n",
    "    \n",
    "\n",
    "trainer = Trainer(backend=\"torch\", num_workers=num_workers, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6e0ef6-0e23-4e95-b382-8eec8e995c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.start()# This keeps starting new workers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac9f3b5-e95b-4323-9ae8-cc2f7f1b4ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = analysis.get_best_config(metric=\"loss\", mode=\"min\")\n",
    "config[\"tune_run\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaed035-27fc-4f2d-9237-e60dcda0a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loss, eval_ = trainer.run(train_func=train_func,\n",
    "                          config = config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d20ebc9-52bc-4829-8975-a61c0cd0b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.latest_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a594aa05-62f0-4c75-b2ef-736f6506c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811062b5-6b6a-4a70-9670-3795691abc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss[0])\n",
    "plt.plot(eval_[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ccf2dc-732c-49a8-a13d-d48981fc397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "model.load_state_dict(results[\"model_weights\"])\n",
    "model_scripted = torch.jit.script(model)\n",
    "model_scripted.save('models/ray_model_scripted.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a92050-5beb-448e-b79f-2d8d52f22d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.load(\"models/ray_model_scripted.pt\", map_location=torch.device('cpu')).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c587d6b-2c52-4e7b-b1f5-71ab89c74cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(data_loader))\n",
    "make = ToPILImage()\n",
    "make(train_features[0]).show()\n",
    "print(f'label:{train_labels[0]}')\n",
    "logits = model(train_features[0].reshape(1,3,64,64).to(device))\n",
    "print(f\"prediction: {torch.argmax(logits).item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372a595e-2e12-4caf-a3d1-b0e2d05beba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "gt = []\n",
    "for X,y in data_loader:\n",
    "    logits = model(X[0].reshape(1,3,64,64).to(device))\n",
    "    y_pred = torch.argmax(logits).item()\n",
    "    y_preds.append(y_pred)\n",
    "    gt.append(y[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e9df11-84a1-4600-a2fb-e3c614629706",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in test_data.iter_batches():\n",
    "    X = [x[0] for x in data]\n",
    "    X = torch.stack(X)\n",
    "    X = X.to(\"cpu\")\n",
    "    y = [torch.tensor(x[1]) for x in data]\n",
    "    y = torch.stack(y)\n",
    "    logits = model(X.to(device))\n",
    "    y_preds = torch.argmax(logits, dim=1)\n",
    "    y_preds = y_preds.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bea5b8-197b-4c8e-a63a-2b74472889eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_preds,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89e32c3-4e21-411a-9ded-ff04be4aa456",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(confusion_matrix(y_preds,y), cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c807e572-428a-436e-99d5-a73a19943a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {np.sum(np.array(y_preds)==np.array(y))/(len(y))*100:.1f}%\")\n",
    "print(f\"Random guess would yield {(1/37)*100:.1f}%\")\n",
    "print(f\"Model outperforms Random chance by a factor of {(np.sum(np.array(y_preds)==np.array(y))/len(y))/(1/37):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48739528-a5a4-4ba1-b3fa-c8e7ad669bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_ray_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1d8c1b-1205-4913-a4cf-34c53403e31a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
